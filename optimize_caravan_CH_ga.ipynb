{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "95vm9FxGQ7KK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import math\n",
        "\n",
        "import time\n",
        "\n",
        "import dataloader\n",
        "import models\n",
        "import training_fun\n",
        "\n",
        "import optuna\n",
        "\n",
        "import joblib\n",
        "\n",
        "import pygad\n",
        "\n",
        "import HydroErr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oJcpZUdpp9K3"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SEQ_LENGTH = 365 * 2\n",
        "TARGET_SEQ_LENGTH = 365\n",
        "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
        "\n",
        "FORCING_DIM = 3\n",
        "\n",
        "N_CATCHMENTS = 270\n",
        "\n",
        "# training hyperparameters\n",
        "\n",
        "use_amp = True\n",
        "compile_model = False\n",
        "\n",
        "if compile_model:\n",
        "    torch.set_float32_matmul_precision(\"high\")\n",
        "\n",
        "memory_saving = False\n",
        "if memory_saving:\n",
        "    storge_device = \"cpu\"\n",
        "    computing_device = DEVICE\n",
        "    VAL_STEPS = 500\n",
        "else:\n",
        "    storge_device = DEVICE\n",
        "    computing_device = DEVICE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ceCEmnygRmye"
      },
      "outputs": [],
      "source": [
        "embedding = torch.load(\"data/final_lstm_embedding2.pt\", map_location=torch.device('cpu')).to(computing_device)\n",
        "decoder = torch.load(\"data/final_lstm_decoder2.pt\", map_location=torch.device('cpu')).to(computing_device)\n",
        "\n",
        "embedding.eval()\n",
        "decoder.eval()\n",
        "\n",
        "# dimension of embedding\n",
        "catchment_embeddings=[x.data for x in embedding.parameters()][0]\n",
        "LATENT_dim = catchment_embeddings.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nGxVHBn3p9K4"
      },
      "outputs": [],
      "source": [
        "dtrain_val = dataloader.Forcing_Data(\n",
        "    \"data/data_train_val_CARAVAN_CH.csv\",\n",
        "    record_length=10957,\n",
        "    storge_device=storge_device,\n",
        "    seq_length=SEQ_LENGTH,\n",
        "    target_seq_length=TARGET_SEQ_LENGTH,\n",
        "    base_length=BASE_LENGTH,\n",
        ")\n",
        "\n",
        "# dtrain = dataloader.Forcing_Data(\n",
        "#     \"camels_train.csv\",\n",
        "#     record_length=2922,\n",
        "#     storge_device=storge_device,\n",
        "#     seq_length=SEQ_LENGTH,\n",
        "#     target_seq_length=TARGET_SEQ_LENGTH,\n",
        "#     base_length=BASE_LENGTH,\n",
        "# )\n",
        "\n",
        "# dval = dataloader.Forcing_Data(\n",
        "#     \"camels_val.csv\",\n",
        "#     record_length=1095,\n",
        "#     storge_device=storge_device,\n",
        "#     seq_length=SEQ_LENGTH,\n",
        "#     target_seq_length=TARGET_SEQ_LENGTH,\n",
        "#     base_length=BASE_LENGTH,\n",
        "# )\n",
        "\n",
        "dtest = dataloader.Forcing_Data(\n",
        "    \"data/data_test_CARAVAN_CH.csv\",\n",
        "    record_length=4018,\n",
        "    storge_device=storge_device,\n",
        "    seq_length=SEQ_LENGTH,\n",
        "    target_seq_length=TARGET_SEQ_LENGTH,\n",
        "    base_length=BASE_LENGTH,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "dw8xH6sT3qQN"
      },
      "outputs": [],
      "source": [
        "class Objective_builder:\n",
        "    def __init__(self, x, y, eval_fun):\n",
        "        self.eval_fun = eval_fun\n",
        "        self.x = x.contiguous()\n",
        "        self.y = y.contiguous()\n",
        "    \n",
        "    def eval(self, code, return_summary = True):\n",
        "        \n",
        "        # numpy to torch tensor\n",
        "        code = torch.from_numpy(code).unsqueeze(0).to(dtype=torch.float32).to(computing_device)\n",
        "        code = code.expand(self.x.shape[0], -1)\n",
        "        \n",
        "        # BASE_LENGTH is from global\n",
        "        pred = decoder.decode(code, self.x).view(-1).detach().cpu().numpy()\n",
        "\n",
        "        ob = self.y.view(-1).detach().cpu().numpy()\n",
        "        \n",
        "        if return_summary:\n",
        "          gof = self.eval_fun(simulated_array=pred, observed_array=ob)\n",
        "          return gof\n",
        "        else:\n",
        "          return pred, ob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Nm0X9u8sp9K7"
      },
      "outputs": [],
      "source": [
        "num_generations = 200\n",
        "num_parents_mating = 10\n",
        "\n",
        "sol_per_pop = 100\n",
        "num_genes = LATENT_dim\n",
        "\n",
        "init_range_low = catchment_embeddings.detach().cpu().min().numpy().tolist()\n",
        "init_range_high = catchment_embeddings.detach().cpu().max().numpy().tolist()\n",
        "\n",
        "parent_selection_type = \"sss\"\n",
        "\n",
        "crossover_type = \"single_point\"\n",
        "\n",
        "mutation_type = \"random\"\n",
        "mutation_probability = 0.25\n",
        "\n",
        "x_batch_train_val, y_batch_train_val = dtrain_val.get_val_batch()\n",
        "x_batch_test, y_batch_test = dtest.get_val_batch()\n",
        "\n",
        "def evaluate_calibration(selected_catchment=0):\n",
        "    \n",
        "    x = x_batch_train_val[:,selected_catchment,:,:]\n",
        "    y = y_batch_train_val[:,selected_catchment,:]\n",
        "\n",
        "    x, y = x.to(computing_device), y.to(computing_device)\n",
        "\n",
        "    fn = Objective_builder(x,y,HydroErr.kge_2009)\n",
        "\n",
        "    def fitness_func(ga_instance, solution, solution_idx):\n",
        "        return fn.eval(solution)\n",
        "\n",
        "    ga_instance = pygad.GA(num_generations=num_generations,\n",
        "                        num_parents_mating=num_parents_mating,\n",
        "                        fitness_func=fitness_func,\n",
        "                        sol_per_pop=sol_per_pop,\n",
        "                        num_genes=num_genes,\n",
        "                        init_range_low=init_range_low,\n",
        "                        init_range_high=init_range_high,\n",
        "                        parent_selection_type=parent_selection_type,\n",
        "                        crossover_type=crossover_type,\n",
        "                        mutation_type=mutation_type,\n",
        "                        mutation_probability = mutation_probability,\n",
        "                        stop_criteria=[\"saturate_10\"])\n",
        "\n",
        "    ga_instance.run()\n",
        "\n",
        "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
        "    \n",
        "    # evaluate on test dataset\n",
        "    x = x_batch_test[:,selected_catchment,:,:]\n",
        "    y = y_batch_test[:,selected_catchment,:]\n",
        "\n",
        "    x, y = x.to(computing_device), y.to(computing_device)\n",
        "\n",
        "    fn = Objective_builder(x,y,HydroErr.kge_2009)\n",
        "\n",
        "    return fn.eval(solution), solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RoScuihK-7QO",
        "outputId": "76bab91f-81fa-4fa0-cd25-39e38a80534e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i=0 starts\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/yang/opt/anaconda3/envs/pytorch2/lib/python3.11/site-packages/HydroErr/HydroErr.py:6248: UserWarning: Row(s) [10592 10593 10594 10595 10596 10597 10598 10599 10600 10601 10602 10603\n",
            " 10604 10605 10606 10607 10608 10609 10610 10611 10612 10613 10614 10615\n",
            " 10616 10617 10618 10619 10620 10621 10622 10623 10624 10625 10626 10627\n",
            " 10628 10629 10630 10631 10632 10633 10634 10635 10636 10637 10638 10639\n",
            " 10640 10641 10642 10643 10644 10645 10646 10647 10648 10649 10650 10651\n",
            " 10652 10653 10654 10655 10656 10657 10658 10659 10660 10661 10662 10663\n",
            " 10664 10665 10666 10667 10668 10669 10670 10671 10672 10673 10674 10675\n",
            " 10676 10677 10678 10679 10680 10681 10682 10683 10684 10685 10686 10687\n",
            " 10688 10689 10690 10691 10692 10693 10694 10695 10696 10697 10698 10699\n",
            " 10700 10701 10702 10703 10704 10705 10706 10707 10708 10709 10710 10711\n",
            " 10712 10713 10714 10715 10716 10717 10718 10719 10720 10721 10722 10723\n",
            " 10724 10725 10726 10727 10728 10729 10730 10731 10732 10733 10734 10735\n",
            " 10736 10737 10738 10739 10740 10741 10742 10743 10744 10745 10746 10747\n",
            " 10748 10749 10750 10751 10752 10753 10754 10755 10756 10757 10758 10759\n",
            " 10760 10761 10762 10763 10764 10765 10766 10767 10768 10769 10770 10771\n",
            " 10772 10773 10774 10775 10776 10777 10778 10779 10780 10781 10782 10783\n",
            " 10784 10785 10786 10787 10788 10789 10790 10791 10792 10793 10794 10795\n",
            " 10796 10797 10798 10799 10800 10801 10802 10803 10804 10805 10806 10807\n",
            " 10808 10809 10810 10811 10812 10813 10814 10815 10816 10817 10818 10819\n",
            " 10820 10821 10822 10823 10824 10825 10826 10827 10828 10829 10830 10831\n",
            " 10832 10833 10834 10835 10836 10837 10838 10839 10840 10841 10842 10843\n",
            " 10844 10845 10846 10847 10848 10849 10850 10851 10852 10853 10854 10855\n",
            " 10856 10857 10858 10859 10860 10861 10862 10863 10864 10865 10866 10867\n",
            " 10868 10869 10870 10871 10872 10873 10874 10875 10876 10877 10878 10879\n",
            " 10880 10881 10882 10883 10884 10885 10886 10887 10888 10889 10890 10891\n",
            " 10892 10893 10894 10895 10896 10897 10898 10899 10900 10901 10902 10903\n",
            " 10904 10905 10906 10907 10908 10909 10910 10911 10912 10913 10914 10915\n",
            " 10916 10917 10918 10919 10920 10921 10922 10923 10924 10925 10926 10927\n",
            " 10928 10929 10930 10931 10932 10933 10934 10935 10936 10937 10938 10939\n",
            " 10940 10941 10942 10943 10944 10945 10946 10947 10948 10949] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
            "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n",
            "/Users/yang/opt/anaconda3/envs/pytorch2/lib/python3.11/site-packages/HydroErr/HydroErr.py:6248: UserWarning: Row(s) [3653 3654 3655 3656 3657 3658 3659 3660 3661 3662 3663 3664 3665 3666\n",
            " 3667 3668 3669 3670 3671 3672 3673 3674 3675 3676 3677 3678 3679 3680\n",
            " 3681 3682 3683 3684 3685 3686 3687 3688 3689 3690 3691 3692 3693 3694\n",
            " 3695 3696 3697 3698 3699 3700 3701 3702 3703 3704 3705 3706 3707 3708\n",
            " 3709 3710 3711 3712 3713 3714 3715 3716 3717 3718 3719 3720 3721 3722\n",
            " 3723 3724 3725 3726 3727 3728 3729 3730 3731 3732 3733 3734 3735 3736\n",
            " 3737 3738 3739 3740 3741 3742 3743 3744 3745 3746 3747 3748 3749 3750\n",
            " 3751 3752 3753 3754 3755 3756 3757 3758 3759 3760 3761 3762 3763 3764\n",
            " 3765 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777 3778\n",
            " 3779 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791 3792\n",
            " 3793 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805 3806\n",
            " 3807 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819 3820\n",
            " 3821 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833 3834\n",
            " 3835 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847 3848\n",
            " 3849 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861 3862\n",
            " 3863 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875 3876\n",
            " 3877 3878 3879 3880 3881 3882 3883 3884 3885 3886 3887 3888 3889 3890\n",
            " 3891 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903 3904\n",
            " 3905 3906 3907 3908 3909 3910 3911 3912 3913 3914 3915 3916 3917 3918\n",
            " 3919 3920 3921 3922 3923 3924 3925 3926 3927 3928 3929 3930 3931 3932\n",
            " 3933 3934 3935 3936 3937 3938 3939 3940 3941 3942 3943 3944 3945 3946\n",
            " 3947 3948 3949 3950 3951 3952 3953 3954 3955 3956 3957 3958 3959 3960\n",
            " 3961 3962 3963 3964 3965 3966 3967 3968 3969 3970 3971 3972 3973 3974\n",
            " 3975 3976 3977 3978 3979 3980 3981 3982 3983 3984 3985 3986 3987 3988\n",
            " 3989 3990 3991 3992 3993 3994 3995 3996 3997 3998 3999 4000 4001 4002\n",
            " 4003 4004 4005 4006 4007 4008 4009 4010 4011 4012 4013 4014] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
            "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fit=0.8913450879031081\n",
            "i=1 starts\n",
            "fit=0.905073536458958\n",
            "i=2 starts\n",
            "fit=0.8886014414868508\n",
            "i=3 starts\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(N_CATCHMENTS):\n\u001b[1;32m      5\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mi=\u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m starts\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     calibrated_KGES[i], camels_embeddings[i,:]  \u001b[39m=\u001b[39m evaluate_calibration(i)\n\u001b[1;32m      7\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mfit=\u001b[39m\u001b[39m{\u001b[39;00mcalibrated_KGES[i]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "Cell \u001b[0;32mIn[11], line 45\u001b[0m, in \u001b[0;36mevaluate_calibration\u001b[0;34m(selected_catchment)\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[39mreturn\u001b[39;00m fn\u001b[39m.\u001b[39meval(solution)\n\u001b[1;32m     32\u001b[0m ga_instance \u001b[39m=\u001b[39m pygad\u001b[39m.\u001b[39mGA(num_generations\u001b[39m=\u001b[39mnum_generations,\n\u001b[1;32m     33\u001b[0m                     num_parents_mating\u001b[39m=\u001b[39mnum_parents_mating,\n\u001b[1;32m     34\u001b[0m                     fitness_func\u001b[39m=\u001b[39mfitness_func,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     42\u001b[0m                     mutation_probability \u001b[39m=\u001b[39m mutation_probability,\n\u001b[1;32m     43\u001b[0m                     stop_criteria\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39msaturate_10\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m---> 45\u001b[0m ga_instance\u001b[39m.\u001b[39;49mrun()\n\u001b[1;32m     47\u001b[0m solution, solution_fitness, solution_idx \u001b[39m=\u001b[39m ga_instance\u001b[39m.\u001b[39mbest_solution()\n\u001b[1;32m     49\u001b[0m \u001b[39m# evaluate on test dataset\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/pytorch2/lib/python3.11/site-packages/pygad/pygad.py:2073\u001b[0m, in \u001b[0;36mGA.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2071\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprevious_generation_fitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_generation_fitness\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m   2072\u001b[0m \u001b[39m# Measuring the fitness of each chromosome in the population. Save the fitness in the last_generation_fitness attribute.\u001b[39;00m\n\u001b[0;32m-> 2073\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_generation_fitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcal_pop_fitness()\n\u001b[1;32m   2075\u001b[0m best_solution, best_solution_fitness, best_match_idx \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbest_solution(\n\u001b[1;32m   2076\u001b[0m     pop_fitness\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlast_generation_fitness)\n\u001b[1;32m   2078\u001b[0m \u001b[39m# Appending the best solution in the current generation to the best_solutions list.\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/pytorch2/lib/python3.11/site-packages/pygad/pygad.py:1669\u001b[0m, in \u001b[0;36mGA.cal_pop_fitness\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1666\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1667\u001b[0m     \u001b[39m# Check if batch processing is used. If not, then calculate this missing fitness value.\u001b[39;00m\n\u001b[1;32m   1668\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfitness_batch_size \u001b[39min\u001b[39;00m [\u001b[39m1\u001b[39m, \u001b[39mNone\u001b[39;00m]:\n\u001b[0;32m-> 1669\u001b[0m         fitness \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfitness_func(\u001b[39mself\u001b[39;49m, sol, sol_idx)\n\u001b[1;32m   1670\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(fitness) \u001b[39min\u001b[39;00m GA\u001b[39m.\u001b[39msupported_int_float_types:\n\u001b[1;32m   1671\u001b[0m             \u001b[39mpass\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[11], line 30\u001b[0m, in \u001b[0;36mevaluate_calibration.<locals>.fitness_func\u001b[0;34m(ga_instance, solution, solution_idx)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfitness_func\u001b[39m(ga_instance, solution, solution_idx):\n\u001b[0;32m---> 30\u001b[0m     \u001b[39mreturn\u001b[39;00m fn\u001b[39m.\u001b[39;49meval(solution)\n",
            "Cell \u001b[0;32mIn[10], line 14\u001b[0m, in \u001b[0;36mObjective_builder.eval\u001b[0;34m(self, code, return_summary)\u001b[0m\n\u001b[1;32m     11\u001b[0m code \u001b[39m=\u001b[39m code\u001b[39m.\u001b[39mexpand(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mx\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# BASE_LENGTH is from global\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m pred \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(code, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mx)\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     16\u001b[0m ob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\n\u001b[1;32m     18\u001b[0m \u001b[39mif\u001b[39;00m return_summary:\n",
            "File \u001b[0;32m~/Documents/projects/deep_lumped/models.py:92\u001b[0m, in \u001b[0;36mLSTM_decoder.decode\u001b[0;34m(self, code, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m code \u001b[39m=\u001b[39m code\u001b[39m.\u001b[39mexpand(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((code, x), \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/Documents/projects/deep_lumped/models.py:82\u001b[0m, in \u001b[0;36mLSTM_decoder.forward\u001b[0;34m(self, inputs, base_length)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, base_length\u001b[39m=\u001b[39m\u001b[39m365\u001b[39m):\n\u001b[0;32m---> 82\u001b[0m     out, (_, _) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlstm(inputs)\n\u001b[1;32m     83\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfc_layers(out[:, base_length:, :])\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/pytorch2/lib/python3.11/site-packages/torch/nn/modules/rnn.py:812\u001b[0m, in \u001b[0;36mLSTM.forward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_forward_args(\u001b[39minput\u001b[39m, hx, batch_sizes)\n\u001b[1;32m    811\u001b[0m \u001b[39mif\u001b[39;00m batch_sizes \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 812\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39;49mlstm(\u001b[39minput\u001b[39;49m, hx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_flat_weights, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_layers,\n\u001b[1;32m    813\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdropout, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbidirectional, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_first)\n\u001b[1;32m    814\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    815\u001b[0m     result \u001b[39m=\u001b[39m _VF\u001b[39m.\u001b[39mlstm(\u001b[39minput\u001b[39m, batch_sizes, hx, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_flat_weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias,\n\u001b[1;32m    816\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_layers, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdropout, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbidirectional)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "calibrated_KGES = np.ones(N_CATCHMENTS)\n",
        "camels_embeddings = np.ones([N_CATCHMENTS, LATENT_dim])\n",
        "\n",
        "for i in range(N_CATCHMENTS):\n",
        "    print(f'i={i} starts')\n",
        "    calibrated_KGES[i], camels_embeddings[i,:]  = evaluate_calibration(i)\n",
        "    print(f'fit={calibrated_KGES[i]}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VzoYzMSXDLtm"
      },
      "outputs": [],
      "source": [
        "np.savetxt(\"data/ga_KGEs.csv\", calibrated_KGES, delimiter=\",\")\n",
        "np.savetxt(\"data/ga_camels_embeddings.csv\", camels_embeddings, delimiter=\",\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "5dla3EMJDzFA"
      },
      "source": [
        "# Result check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.91941096,  0.85682169,  0.91637485,  0.88217712,  0.88228154,\n",
              "        0.88692423,  0.74929147,  0.78510157,  0.86397878,  0.84344607,\n",
              "        0.76471023,  0.83853438,  0.83633127,  0.78910078,  0.84521933,\n",
              "        0.81248433,  0.80268453,  0.84948467,  0.74234173,  0.76419514,\n",
              "        0.76399213,  0.83128169,  0.76749481,  0.7045009 ,  0.78371101,\n",
              "        0.50837783,  0.77227529,  0.26538183,  0.57192447,  0.6664474 ,\n",
              "        0.62655947,  0.76148306,  0.71783067,  0.76387803,  0.79151405,\n",
              "        0.80246345,  0.75337292,  0.78052573,  0.83671804,  0.80459067,\n",
              "        0.81376294,  0.4992642 ,  0.7323576 ,  0.54922338,  0.80322473,\n",
              "        0.80011686,  0.86071515,  0.8383424 ,  0.77542572,  0.71476613,\n",
              "        0.68841337,  0.77964997,  0.51909695,  0.58665682,  0.75903779,\n",
              "        0.79007346,  0.70983101,  0.58668493,  0.79720012,  0.69344743,\n",
              "        0.65657411,  0.58694882,  0.69307331,  0.72728967,  0.79509138,\n",
              "        0.71894977,  0.75483379,  0.68432546,  0.55662402,  0.76278659,\n",
              "        0.39593781,  0.65615555,  0.74794464,  0.68333587,  0.70178364,\n",
              "        0.40697932,  0.61528125,  0.82687356,  0.65255826,  0.82787613,\n",
              "        0.63362776,  0.74538318,  0.73447039,  0.7825076 ,  0.68140171,\n",
              "        0.77140607,  0.6380635 ,  0.20024766,  0.42963008,  0.52971751,\n",
              "        0.6719701 ,  0.60099438,  0.80752196,  0.72892372,  0.69117261,\n",
              "        0.69611122,  0.76547868,  0.63872182, -0.11519627,  0.4860116 ,\n",
              "        0.800024  ,  0.78789842,  0.6612794 ,  0.44902973,  0.74939338,\n",
              "        0.51798368,  0.41078897,  0.58069804,  0.76383509,  0.69565273,\n",
              "        0.74485204,  0.64750086,  0.805574  ,  0.71960594,  0.62877262,\n",
              "        0.5836393 ,  0.67657159,  0.76312647,  0.73282007,  0.69718688,\n",
              "        0.7761632 ,  0.60193611,  0.7059993 ,  0.7715166 ,  0.59769292,\n",
              "        0.3441966 ,  0.51040031,  0.24102388,  0.64247312,  0.57392257,\n",
              "        0.38786003,  0.6611121 ,  0.37198241,  0.74592679,  0.59846122,\n",
              "        0.70251622,  0.73492927,  0.67689356,  0.71690588,  0.59795736,\n",
              "        0.73300535,  0.40050024,  0.66473986,  0.62052494,  0.77961191,\n",
              "        0.76834316,  0.71230815,  0.7280521 ,  0.72004147,  0.76340558,\n",
              "        0.71374059,  0.82062759,  0.74521085,  0.8669458 ,  0.82252881,\n",
              "        0.7336983 ,  0.75425873,  0.70288106,  0.84010339,  0.68098926,\n",
              "        0.7201963 ,  0.82231133,  0.7994239 ,  0.79321425,  0.83145289,\n",
              "        0.8515744 ,  0.85055076,  0.8052184 ,  0.83548787,  0.73452006,\n",
              "        0.80122317,  0.82810313,  0.70573904,  0.42361549,  0.84942962,\n",
              "        0.84081893,  0.81121902,  0.67205209,  0.7845977 ,  0.7212419 ,\n",
              "        0.77314804,  0.72063559,  0.85554111,  0.80042074,  0.78176203,\n",
              "        0.68695959,  0.8132754 ,  0.84377055,  0.8177617 ,  0.81214913,\n",
              "        0.82246987,  0.53969286,  0.66687526,  0.7458828 ,  0.74793674,\n",
              "        0.79191592,  0.64567794,  0.6469284 ,  0.82163772,  0.66315604,\n",
              "        0.83273323,  0.80931477,  0.72716919,  0.770134  ,  0.57770304,\n",
              "        0.77183441,  0.79923023,  0.79479594,  0.69940441,  0.68663195,\n",
              "        0.80398073,  0.62653959,  0.76841969,  0.78728059,  0.7310606 ,\n",
              "        0.80408147,  0.82308273,  0.65653169,  0.87923794,  0.7808387 ,\n",
              "        0.63723231,  0.7177967 ,  0.80920951,  0.87298911,  0.77234718,\n",
              "        0.78699512,  0.8540085 ,  0.66328523,  0.61134755,  0.71422559,\n",
              "        0.59235529,  0.52435937,  0.70486377,  0.71723667,  0.36131162,\n",
              "        0.75021068,  0.64943309,  0.81305739,  0.73621462,  0.4362296 ,\n",
              "        0.71317615,  0.7736917 ,  0.81945665,  0.77322614,  0.81510141,\n",
              "        0.58788488,  0.7880409 ,  0.84235667,  0.7342695 ,  0.79974474,\n",
              "        0.86163299,  0.85753881,  0.29171516,  0.61868524,  0.28944174,\n",
              "        0.67046013,  0.75092808,  0.17034675,  0.6858873 ,  0.67057141,\n",
              "        0.78353178,  0.6593783 ,  0.72854327,  0.72969661,  0.60647781,\n",
              "        0.46324869,  0.5986977 ,  0.75862397,  0.78650734,  0.56274371,\n",
              "        0.70876318,  0.71402015,  0.84328325,  0.65059414,  0.66794822,\n",
              "        0.37370717,  0.77020333,  0.72474588,  0.74934765,  0.84116089,\n",
              "        0.7195804 ,  0.73674984,  0.71969591,  0.72739284,  0.66451058,\n",
              "        0.62813259,  0.80259202,  0.79903452,  0.84866589,  0.78279906,\n",
              "        0.89923192,  0.914948  ,  0.9137207 ,  0.82258443,  0.86115085,\n",
              "        0.77165027,  0.88986706,  0.79083062,  0.69386732,  0.69214525,\n",
              "        0.1221648 ,  0.67361741,  0.39800786,  0.45627447,  0.52819251,\n",
              "        0.60182398,  0.61420173,  0.73701324,  0.32324371,  0.32032418,\n",
              "        0.3338584 ,  0.57983593,  0.66467604, -0.53347539, -0.77916522,\n",
              "        0.49231771,  0.24596427,  0.17699822,  0.58668613,  0.479291  ,\n",
              "        0.6221163 ,  0.69209199,  0.4790768 ,  0.7383808 , -0.15451924,\n",
              "       -0.29396229,  0.38796394,  0.83557095,  0.9029518 ,  0.81982132,\n",
              "        0.88559738,  0.06042302,  0.05468455,  0.40803702,  0.63159649,\n",
              "       -3.21306982, -0.42124001,  0.33627795,  0.70906647,  0.19768644,\n",
              "        0.76387015,  0.55994912,  0.50294428,  0.66834091,  0.70103322,\n",
              "        0.40526508,  0.73992273,  0.76987355,  0.69867323,  0.69825273,\n",
              "        0.4624396 ,  0.81352287,  0.47299275,  0.75578586,  0.73324486,\n",
              "        0.85506525,  0.67403278,  0.70994717,  0.69812294,  0.89670899,\n",
              "        0.79907003,  0.92885066, -0.81278593,  0.61655241,  0.57911228,\n",
              "        0.13960474,  0.80853184,  0.66676686,  0.51376719,  0.72713499,\n",
              "        0.51769168,  0.66470911,  0.78874377,  0.13556319, -0.07324176,\n",
              "        0.74368356,  0.67438866,  0.89954279,  0.64772151,  0.7213874 ,\n",
              "        0.67899435,  0.16287941,  0.23592526,  0.41262948, -0.76162158,\n",
              "       -0.59042373,  0.40076877,  0.7731125 ,  0.75390234,  0.77999434,\n",
              "        0.81311815,  0.67826166,  0.63984392,  0.56275195,  0.8047991 ,\n",
              "        0.81619315,  0.73642421, -0.16109983,  0.52173931,  0.59457149,\n",
              "        0.35685496,  0.42213994,  0.31439609,  0.41240864, -0.04470742,\n",
              "        0.47810438,  0.61220637,  0.36593469,  0.27405874,  0.5797445 ,\n",
              "        0.63725465,  0.59190753,  0.55982766,  0.56417574,  0.48744129,\n",
              "        0.78964921,  0.40404145,  0.6873886 ,  0.52958862,  0.66173348,\n",
              "        0.3022803 ,  0.71956229,  0.59604024, -1.52422093,  0.13413323,\n",
              "        0.5203036 ,  0.34086044,  0.32677319,  0.44044134,  0.40508588,\n",
              "        0.73027592,  0.75014598,  0.79458861,  0.62235415,  0.79674646,\n",
              "        0.71427114,  0.73907256,  0.92849822,  0.62132847,  0.91527526,\n",
              "        0.92204264,  0.81502002,  0.85546758,  0.94949747,  0.92836226,\n",
              "        0.71526301,  0.85665105, -0.31446978,  0.88272819,  0.91022162,\n",
              "        0.61967056, -0.93347162,  0.52861445,  0.50401264,  0.29982149,\n",
              "        0.01182777,  0.2302663 , -0.00489074,  0.60811637,  0.53904763,\n",
              "        0.60491536,  0.65143804,  0.55451037,  0.5805563 ,  0.6226916 ,\n",
              "        0.72562412, -0.05955173,  0.73620334,  0.84192303,  0.74433085,\n",
              "        0.65168561,  0.78386373,  0.80307725,  0.53566598,  0.70342163,\n",
              "        0.56503604,  0.81244425,  0.02801929,  0.6630147 ,  0.30617911,\n",
              "        0.66248627,  0.78174409,  0.83717879,  0.86448875,  0.7400771 ,\n",
              "        0.74108488,  0.81301268,  0.7423835 ,  0.89087058,  0.80904241,\n",
              "        0.78308961,  0.65669813,  0.5887841 ,  0.81898816,  0.59213189,\n",
              "        0.48059431,  0.69839707,  0.64962555,  0.69277236,  0.93228245,\n",
              "        0.90869752,  0.84480855,  0.62216996,  0.93397444,  0.62347771,\n",
              "        0.74147842,  0.64449642,  0.8960605 ,  0.87572828,  0.88802278,\n",
              "        0.84582648,  0.81432098,  0.85065143,  0.92631717,  0.81182305,\n",
              "        0.90836883,  0.60153123,  0.8002772 ,  0.84273776,  0.72939165,\n",
              "        0.64054561,  0.81267633,  0.75303366,  0.84359061,  0.80120621,\n",
              "        0.9228345 ,  0.88222069,  0.87602614,  0.887157  ,  0.87362374,\n",
              "        0.94694415,  0.93311091,  0.94540468,  0.80507133,  0.77788528,\n",
              "        0.87413583,  0.91948687,  0.86261909,  0.90104465,  0.915395  ,\n",
              "        0.8767495 ,  0.7805991 ,  0.80691232,  0.8109702 ,  0.88317847,\n",
              "        0.89530966,  0.90155368,  0.91312674,  0.90371858,  0.85219745,\n",
              "        0.87097784,  0.87296341,  0.90480454,  0.90352674,  0.7921505 ,\n",
              "        0.91245779,  0.86514961,  0.89443528,  0.89847546])"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calibrated_KGES"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KcwBoioFp9K9",
        "outputId": "e9aa9d7e-2972-4b4e-f519-4e10ab766559"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.hist(calibrated_KGES[calibrated_KGES>0], bins = 30)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "fBoQkf-Cp9K9",
        "outputId": "4856c289-13ec-4e46-d43d-559f73f757df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6511377478097157"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calibrated_KGES.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "TNPOIEy_p9K-",
        "outputId": "dac5fcb6-05dd-456b-89b1-4018cffaa686"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7165318169791439"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.median(calibrated_KGES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "t5aRLriip9K7",
        "outputId": "83c37e57-c570-4994-b0e2-39ae8c766cb7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.93864914,  0.81139841,  0.90589687,  0.85936885,  0.88780411,\n",
              "        0.81618644,  0.78298278,  0.79292717,  0.86002109,  0.88580952,\n",
              "        0.79435137,  0.83446906,  0.83976704,  0.78880728,  0.83806702,\n",
              "        0.80829967,  0.82921377,  0.88030742,  0.67890756,  0.73124126,\n",
              "        0.74209071,  0.84994678,  0.82068269,  0.7262751 ,  0.80621568,\n",
              "        0.24722365,  0.7512313 ,  0.54888737,  0.62498752,  0.75104824,\n",
              "        0.71824046,  0.76699311,  0.74987942,  0.70922746,  0.75042409,\n",
              "        0.7886949 ,  0.70949958,  0.76904734,  0.83663774,  0.75796622,\n",
              "        0.83484634,  0.4460498 ,  0.72880369,  0.5812842 ,  0.73906844,\n",
              "        0.79976755,  0.86431163,  0.85086532,  0.75620529,  0.75563354,\n",
              "        0.68497464,  0.75356664,  0.51069772,  0.57106986,  0.81610585,\n",
              "        0.7689098 ,  0.73952573,  0.66851425,  0.80474854,  0.70714314,\n",
              "        0.63099561,  0.59506833,  0.61608368,  0.7378529 ,  0.81673325,\n",
              "        0.66710605,  0.76420138,  0.70263208,  0.55858068,  0.6621399 ,\n",
              "        0.57251261,  0.64022925,  0.76509997,  0.67588678,  0.7090668 ,\n",
              "        0.56358097,  0.5640736 ,  0.73861709,  0.46203217,  0.77388735,\n",
              "        0.70993432,  0.69937483,  0.72823769,  0.77152979,  0.65652361,\n",
              "        0.74424498,  0.64086604,  0.40147363,  0.5708167 ,  0.45468463,\n",
              "        0.57863278,  0.48139996,  0.77185593,  0.61155112,  0.72954607,\n",
              "        0.60097851,  0.70117764,  0.73313769,  0.09558722,  0.34824298,\n",
              "        0.69405876,  0.77894888,  0.70942399,  0.31216377,  0.78322903,\n",
              "        0.41634184,  0.50335207,  0.59226717,  0.71764501,  0.58677674,\n",
              "        0.63326599,  0.6504726 ,  0.62062014,  0.69817992,  0.68374765,\n",
              "        0.58388329,  0.63168171,  0.73089813,  0.72010065,  0.69863541,\n",
              "        0.74995359,  0.50970279,  0.73387507,  0.73334764,  0.6699046 ,\n",
              "        0.20891924,  0.41309791,  0.19321773,  0.58142784,  0.5221763 ,\n",
              "        0.41307444,  0.62160929,  0.5365218 ,  0.71860784,  0.59182246,\n",
              "        0.58707666,  0.7260618 ,  0.62470846,  0.70372866,  0.59221185,\n",
              "        0.70333896,  0.34433342,  0.55459869,  0.412698  ,  0.73745929,\n",
              "        0.74585375,  0.70842375,  0.75975907,  0.66637051,  0.71447696,\n",
              "        0.58845565,  0.77122243,  0.73684791,  0.87107661,  0.78015863,\n",
              "        0.70386783,  0.75993437,  0.61943965,  0.84344803,  0.69417799,\n",
              "        0.82654267,  0.80652465,  0.83052578,  0.77472056,  0.81974572,\n",
              "        0.77086545,  0.86168578,  0.82975632,  0.83581566,  0.69993045,\n",
              "        0.74228747,  0.82669166,  0.71957183,  0.41019292,  0.84485792,\n",
              "        0.88201862,  0.80250853,  0.52137199,  0.7528558 ,  0.76406456,\n",
              "        0.67506024,  0.73793807,  0.81960864,  0.75474422,  0.77631864,\n",
              "        0.78226587,  0.8043628 ,  0.76407509,  0.82911888,  0.81290137,\n",
              "        0.78389257,  0.53847523,  0.73009003,  0.78632609,  0.7888757 ,\n",
              "        0.76940334,  0.57555074,  0.73854367,  0.85368783,  0.57772613,\n",
              "        0.73589915,  0.8065579 ,  0.74495566,  0.86544504,  0.63772724,\n",
              "        0.79659447,  0.71266343,  0.71452014,  0.71199216,  0.68358783,\n",
              "        0.79602594,  0.58854919,  0.76230667,  0.80818836,  0.71486226,\n",
              "        0.79955929,  0.82967924,  0.70251604,  0.80838938,  0.80249429,\n",
              "        0.66912121,  0.69734135,  0.81698841,  0.8457474 ,  0.79784731,\n",
              "        0.77241126,  0.89858992,  0.67155399,  0.64909753,  0.71167962,\n",
              "        0.65695106,  0.58549681,  0.77245337,  0.74650764,  0.50622611,\n",
              "        0.76031404,  0.70216258,  0.78338814,  0.72479046,  0.60575148,\n",
              "        0.66750802,  0.83403664,  0.79859014,  0.79015628,  0.83620935,\n",
              "        0.5270133 ,  0.78864489,  0.82897958,  0.66390717,  0.8088081 ,\n",
              "        0.86484311,  0.84906692,  0.58421041,  0.62350381,  0.32453314,\n",
              "        0.78586   ,  0.84524875,  0.38998717,  0.68790891,  0.62841536,\n",
              "        0.74041637,  0.57234491,  0.71078321,  0.65203003,  0.58290363,\n",
              "        0.54944927,  0.65451382,  0.79654354,  0.62329908,  0.69284912,\n",
              "        0.69351572,  0.74475938,  0.7398544 ,  0.71653182,  0.67582585,\n",
              "        0.32218785,  0.81640952,  0.81174997,  0.69738766,  0.77270503,\n",
              "        0.53956615,  0.79074211,  0.56746852,  0.79142484,  0.58370637,\n",
              "        0.56252578,  0.82904161,  0.8464638 ,  0.84632492,  0.615032  ,\n",
              "        0.90345976,  0.87868478,  0.88472392,  0.73886134,  0.7970138 ,\n",
              "        0.73637494,  0.88633515,  0.76567974,  0.56787085,  0.79410253,\n",
              "        0.26623787,  0.55882059,  0.45241653,  0.54205281,  0.5089099 ,\n",
              "        0.51017096,  0.5566763 ,  0.51316421,  0.45582757,  0.5659688 ,\n",
              "        0.43500312,  0.25733023,  0.66708632, -0.20908492, -0.39773798,\n",
              "        0.55995103,  0.35788569,  0.5149959 ,  0.56127424,  0.52852217,\n",
              "        0.61037368,  0.57401655,  0.62948896,  0.65416989,  0.48124004,\n",
              "       -0.24158173,  0.40318631,  0.70714702,  0.84782142,  0.89004059,\n",
              "        0.88974987, -0.30642782,  0.42333525,  0.35097882,  0.57399796,\n",
              "       -0.82952336,  0.07745183,  0.46530269,  0.70790529,  0.11089426,\n",
              "        0.76290496,  0.48805777,  0.4763303 ,  0.73343913,  0.853699  ,\n",
              "        0.44017223,  0.79750036,  0.76330837,  0.71005496,  0.69092678,\n",
              "        0.36375656,  0.77261926,  0.51019051,  0.59328173,  0.63661235,\n",
              "        0.84795141,  0.44556363,  0.63801219,  0.6436894 ,  0.78359095,\n",
              "        0.54343467,  0.92644629, -0.89728881,  0.78013683, -0.03882279,\n",
              "        0.01394437,  0.75113915,  0.70514026,  0.71052989,  0.76180761,\n",
              "        0.55445846,  0.64534406,  0.70358408,  0.3346331 , -0.21883927,\n",
              "        0.75577475,  0.64686276,  0.86978972,  0.67568867,  0.73930833,\n",
              "        0.65626961,  0.34469944,  0.31494421,  0.45683835, -0.72920984,\n",
              "       -0.48341791,  0.39327402,  0.77735309,  0.54747003,  0.74747756,\n",
              "        0.76585683,  0.72142751,  0.52107926,  0.5260505 ,  0.74727542,\n",
              "        0.847125  ,  0.72109815, -0.25129447,  0.58304766,  0.58422108,\n",
              "        0.37331518,  0.30964202,  0.40609576,  0.07855451, -0.40561155,\n",
              "        0.62829188,  0.50754806,  0.31046898,  0.27460217,  0.54838864,\n",
              "        0.65342334,  0.60197162,  0.67655259,  0.59092161,  0.57369504,\n",
              "        0.76845809,  0.33797251,  0.76487408,  0.64027471,  0.57714319,\n",
              "        0.05563809,  0.69066029,  0.50894599, -1.73950769,  0.01468503,\n",
              "        0.44115382,  0.38433955,  0.45190297,  0.45457597,  0.38888017,\n",
              "        0.7677304 ,  0.74697185,  0.76733349,  0.70826695,  0.50830748,\n",
              "        0.44476369,  0.67996341,  0.84903665,  0.60891116,  0.93279419,\n",
              "        0.88529194,  0.91378017,  0.83849078,  0.93831357,  0.93898675,\n",
              "        0.7468959 ,  0.81418822, -0.37049685,  0.93135794,  0.90304964,\n",
              "        0.57685813, -0.09840185,  0.69539497,  0.67896194,  0.25892509,\n",
              "       -0.83330461,  0.20670734,  0.11495046,  0.39365011,  0.59585643,\n",
              "        0.62701958,  0.62474457,  0.61002694,  0.58663966,  0.67670069,\n",
              "        0.7648149 ,  0.06953746,  0.48625153,  0.69054085,  0.77902   ,\n",
              "        0.68220064,  0.78878173,  0.7984223 ,  0.41378631,  0.73729002,\n",
              "        0.78732165,  0.80851654,  0.42018163,  0.80220936,  0.40390253,\n",
              "        0.58469575,  0.68517578,  0.88190104,  0.87523879,  0.81830904,\n",
              "        0.66022568,  0.81449337,  0.60664868,  0.82553204,  0.82974414,\n",
              "        0.83378261,  0.77238758,  0.58098668,  0.84874906,  0.67751844,\n",
              "        0.58223201,  0.65954095,  0.83207219,  0.81284647,  0.91577475,\n",
              "        0.91449452,  0.84570597,  0.66109591,  0.93889266,  0.62052714,\n",
              "        0.80593911,  0.631403  ,  0.8269103 ,  0.80180608,  0.84620153,\n",
              "        0.82440412,  0.81809046,  0.84411432,  0.95136735,  0.83541121,\n",
              "        0.85701296,  0.56169138,  0.82346337,  0.85381481,  0.65305499,\n",
              "        0.59239777,  0.8641195 ,  0.80169882,  0.89958304,  0.79231765,\n",
              "        0.91344467,  0.84400998,  0.911293  ,  0.88495366,  0.79155062,\n",
              "        0.88982236,  0.88537941,  0.94711784,  0.86735936,  0.73352381,\n",
              "        0.89585944,  0.87512816,  0.91326488,  0.91250806,  0.92806882,\n",
              "        0.89536648,  0.83398657,  0.79585652,  0.79495248,  0.87256002,\n",
              "        0.87028041,  0.90548447,  0.89726293,  0.90939361,  0.82983706,\n",
              "        0.88868625,  0.89061122,  0.8867263 ,  0.87273047,  0.85226533,\n",
              "        0.90573037,  0.87222642,  0.87857728,  0.92819958])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "calibrated_KGES"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "pytorch-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "1ddfd6d42648f68c476c776315986cac60a18b45e56ba9b8a233e8441d39da2b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
