{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 3\n",
    "\n",
    "N_CATCHMENTS = 671\n",
    "\n",
    "# training hyperparameters\n",
    "EPOCHS = 500\n",
    "TRAIN_YEAR = 7\n",
    "PATIENCE = 20\n",
    "\n",
    "use_amp = True\n",
    "compile_model = False\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = False\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_val = dataloader.Forcing_Data(\n",
    "    \"data/all_camels_train_val.csv\",\n",
    "    record_length=3652,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dtrain = dataloader.Forcing_Data(\n",
    "    \"data/all_camels_train.csv\",\n",
    "    record_length=2922,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dval = dataloader.Forcing_Data(\n",
    "    \"data/all_camels_val.csv\",\n",
    "    record_length=1095,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dtest = dataloader.Forcing_Data(\n",
    "    \"data/all_camels_test.csv\",\n",
    "    record_length=4383,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self, model_builder):\n",
    "        self.model_builder = model_builder\n",
    "\n",
    "    def objective(self, trial):\n",
    "\n",
    "        # prepare early stopper\n",
    "        early_stopper = training_fun.EarlyStopper(patience=PATIENCE, min_delta=0)\n",
    "\n",
    "        # define model\n",
    "        embedding, decoder = self.model_builder.define_model(trial)\n",
    "        embedding, decoder = embedding.to(computing_device), decoder.to(\n",
    "            computing_device\n",
    "        )\n",
    "\n",
    "        if compile_model:\n",
    "            # pytorch2.0 new feature, complile model for fast training\n",
    "            embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "        # define optimizers\n",
    "        lr_embedding = trial.suggest_float(\"lr_embedding\", 5e-5, 1e-2, log=True)\n",
    "        embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "\n",
    "        lr_decoder = trial.suggest_float(\"lr_decoder\", 5e-5, 1e-2, log=True)\n",
    "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "        # define batch size\n",
    "        batch_size_power = trial.suggest_int(\"batch_size_power\", 4, 8)\n",
    "        batch_size = 2**batch_size_power\n",
    "\n",
    "        # steps per epoch\n",
    "        steps = round(N_CATCHMENTS * TRAIN_YEAR / batch_size)\n",
    "\n",
    "        # train model\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "            # repeat TRAIN_YEAR times to finish an epoch\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            for step in range(steps):\n",
    "\n",
    "                decoder_optimizer.zero_grad()\n",
    "                embedding_optimizer.zero_grad()\n",
    "\n",
    "                # put the models into training mode\n",
    "                decoder.train()\n",
    "                embedding.train()\n",
    "\n",
    "                # get training batch and pass to device\n",
    "                (x_batch, y_batch, selected_catchments) = dtrain.get_random_batch(\n",
    "                    batch_size\n",
    "                )\n",
    "\n",
    "                x_batch, y_batch, selected_catchments = (\n",
    "                    x_batch.to(computing_device),\n",
    "                    y_batch.to(computing_device),\n",
    "                    selected_catchments.to(computing_device),\n",
    "                )\n",
    "\n",
    "                # slice batch for training\n",
    "                with torch.autocast(\n",
    "                    device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "                ):\n",
    "                    code = embedding(selected_catchments)\n",
    "\n",
    "                    # pass through decoder\n",
    "                    out = decoder.decode(code, x_batch)\n",
    "\n",
    "                    # compute loss\n",
    "                    loss = training_fun.mse_loss_with_nans(out, y_batch)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(embedding_optimizer)\n",
    "                scaler.step(decoder_optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            # validate model after each epochs\n",
    "            decoder.eval()\n",
    "            embedding.eval()\n",
    "\n",
    "            # Handle pruning based on the intermediate value\n",
    "            if memory_saving:\n",
    "                val_loss = training_fun.val_model_mem_saving(\n",
    "                    embedding=embedding,\n",
    "                    decoder=decoder,\n",
    "                    dataset=dval,\n",
    "                    storge_device=storge_device,\n",
    "                    computing_device=computing_device,\n",
    "                    use_amp=use_amp,\n",
    "                    val_metric=training_fun.mse_loss_with_nans,\n",
    "                    return_summary=True,\n",
    "                    val_steps=VAL_STEPS,\n",
    "                )\n",
    "            else:\n",
    "                val_loss = (\n",
    "                    training_fun.val_model(\n",
    "                        embedding=embedding,\n",
    "                        decoder=decoder,\n",
    "                        dataset=dval,\n",
    "                        storge_device=storge_device,\n",
    "                        computing_device=computing_device,\n",
    "                        use_amp=use_amp,\n",
    "                        val_metric=training_fun.mse_loss_with_nans,\n",
    "                        return_summary=True,\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                torch.cuda.empty_cache()\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            # Early stop using early_stopper, break for loop\n",
    "            if early_stopper.early_stop(val_loss):\n",
    "                break\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return early_stopper.min_validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_builder = training_fun.LSTM_model_builder(\n",
    "    n_catchments=N_CATCHMENTS, base_length=BASE_LENGTH, forcing_dim=FORCING_DIM\n",
    ")\n",
    "\n",
    "LSTM_objective = Objective(LSTM_model_builder).objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-03-15 20:26:06,492]\u001b[0m A new study created in memory with name: base_model\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 20:31:44,264]\u001b[0m Trial 0 finished with value: 3.302379608154297 and parameters: {'lstm_hidden_dim': 25, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 2, 'fc_dim1': 9, 'lr_embedding': 0.00042104024329163697, 'lr_decoder': 0.0002046799971008731, 'batch_size_power': 5}. Best is trial 0 with value: 3.302379608154297.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 20:38:57,507]\u001b[0m Trial 1 finished with value: 2.9541544914245605 and parameters: {'lstm_hidden_dim': 34, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 13, 'lr_embedding': 0.00044561786877839687, 'lr_decoder': 0.00016977894222212109, 'batch_size_power': 5}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 20:41:24,465]\u001b[0m Trial 2 finished with value: 4.055758476257324 and parameters: {'lstm_hidden_dim': 88, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.29998184643859244, 'fc_dim0': 6, 'fc_dim1': 16, 'lr_embedding': 0.0003416610946069384, 'lr_decoder': 0.0001621094826922967, 'batch_size_power': 6}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 20:52:49,814]\u001b[0m Trial 3 finished with value: 3.8821966648101807 and parameters: {'lstm_hidden_dim': 191, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.2109566445897942, 'fc_dim0': 4, 'lr_embedding': 0.0002852257383877342, 'lr_decoder': 0.0008274693178254166, 'batch_size_power': 5}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 20:58:11,962]\u001b[0m Trial 4 finished with value: 3.7493093013763428 and parameters: {'lstm_hidden_dim': 230, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 1, 'drop_out_flag': True, 'dropout_rate': 0.2570939596338227, 'fc_dim0': 9, 'fc_dim1': 16, 'fc_dim2': 9, 'lr_embedding': 0.0022986732768665993, 'lr_decoder': 0.00033943276456455617, 'batch_size_power': 4}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:00:27,703]\u001b[0m Trial 5 finished with value: 8.287434577941895 and parameters: {'lstm_hidden_dim': 222, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.4199394504877495, 'fc_dim0': 7, 'fc_dim1': 13, 'fc_dim2': 3, 'lr_embedding': 0.0024587228092788557, 'lr_decoder': 0.000215030307911398, 'batch_size_power': 8}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:13:59,894]\u001b[0m Trial 6 finished with value: 3.067934274673462 and parameters: {'lstm_hidden_dim': 203, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.4677745290485971, 'fc_dim0': 14, 'fc_dim1': 11, 'lr_embedding': 0.002234134959818155, 'lr_decoder': 0.0001377053790796822, 'batch_size_power': 4}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:21:32,403]\u001b[0m Trial 7 finished with value: 3.055466413497925 and parameters: {'lstm_hidden_dim': 138, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.2866582895768084, 'fc_dim0': 15, 'lr_embedding': 0.0015510606649665885, 'lr_decoder': 0.0009607767109048978, 'batch_size_power': 4}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:24:28,957]\u001b[0m Trial 8 finished with value: 4.1532464027404785 and parameters: {'lstm_hidden_dim': 19, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 3, 'lr_embedding': 9.12418069064331e-05, 'lr_decoder': 0.0004453551160916528, 'batch_size_power': 7}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:25:03,643]\u001b[0m Trial 9 finished with value: 3.9670610427856445 and parameters: {'lstm_hidden_dim': 29, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.3049070603141611, 'fc_dim0': 12, 'fc_dim1': 16, 'lr_embedding': 0.00023251087804441512, 'lr_decoder': 0.0029560505508138216, 'batch_size_power': 8}. Best is trial 1 with value: 2.9541544914245605.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:26:22,839]\u001b[0m Trial 10 finished with value: 2.9375646114349365 and parameters: {'lstm_hidden_dim': 88, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.00568957949664743, 'lr_decoder': 0.008835555204171553, 'batch_size_power': 6}. Best is trial 10 with value: 2.9375646114349365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:27:36,104]\u001b[0m Trial 11 finished with value: 3.0025227069854736 and parameters: {'lstm_hidden_dim': 82, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.00855561607537417, 'lr_decoder': 0.007744087059382524, 'batch_size_power': 6}. Best is trial 10 with value: 2.9375646114349365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:32:33,643]\u001b[0m Trial 12 finished with value: 2.9388792514801025 and parameters: {'lstm_hidden_dim': 81, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.00954193268298918, 'lr_decoder': 5.817207210884175e-05, 'batch_size_power': 5}. Best is trial 10 with value: 2.9375646114349365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:43:25,213]\u001b[0m Trial 13 finished with value: 3.2033936977386475 and parameters: {'lstm_hidden_dim': 115, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.009832687763022584, 'lr_decoder': 6.706498478660165e-05, 'batch_size_power': 7}. Best is trial 10 with value: 2.9375646114349365.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:49:37,673]\u001b[0m Trial 14 finished with value: 2.8728604316711426 and parameters: {'lstm_hidden_dim': 154, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 16, 'lr_embedding': 0.005531844383742335, 'lr_decoder': 0.0022438096899827934, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 21:57:39,033]\u001b[0m Trial 15 finished with value: 3.0280847549438477 and parameters: {'lstm_hidden_dim': 142, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 2, 'lr_embedding': 0.003641472631981003, 'lr_decoder': 0.00890872149746464, 'batch_size_power': 7}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:16:44,820]\u001b[0m Trial 16 finished with value: 3.137794017791748 and parameters: {'lstm_hidden_dim': 173, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 16, 'lr_embedding': 0.0009938198271942698, 'lr_decoder': 0.002727802879389269, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:24:48,535]\u001b[0m Trial 17 finished with value: 3.0790157318115234 and parameters: {'lstm_hidden_dim': 165, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'fc_dim1': 2, 'fc_dim2': 16, 'lr_embedding': 0.004421006854249928, 'lr_decoder': 0.0035651326504735877, 'batch_size_power': 7}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:26:47,651]\u001b[0m Trial 18 finished with value: 2.948960781097412 and parameters: {'lstm_hidden_dim': 106, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 7, 'lr_embedding': 0.005006576939236714, 'lr_decoder': 0.0018688015246706242, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:28:12,549]\u001b[0m Trial 19 finished with value: 3.5580544471740723 and parameters: {'lstm_hidden_dim': 59, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 6, 'lr_embedding': 0.0009771532803561707, 'lr_decoder': 0.0062182289112123834, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:36:25,982]\u001b[0m Trial 20 finished with value: 2.9602584838867188 and parameters: {'lstm_hidden_dim': 150, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 14, 'lr_embedding': 0.005614716490771756, 'lr_decoder': 0.0013491412150140397, 'batch_size_power': 7}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:37:35,610]\u001b[0m Trial 21 finished with value: 3.009504795074463 and parameters: {'lstm_hidden_dim': 60, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.007225426817562618, 'lr_decoder': 0.004473202789284179, 'batch_size_power': 5}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:45:39,234]\u001b[0m Trial 22 finished with value: 2.964669704437256 and parameters: {'lstm_hidden_dim': 115, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.003755628584930942, 'lr_decoder': 5.040651219969185e-05, 'batch_size_power': 5}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:48:15,672]\u001b[0m Trial 23 finished with value: 3.4707720279693604 and parameters: {'lstm_hidden_dim': 69, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 5.4059443236121266e-05, 'lr_decoder': 0.0016600734238846834, 'batch_size_power': 5}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:51:36,376]\u001b[0m Trial 24 finished with value: 2.9182214736938477 and parameters: {'lstm_hidden_dim': 98, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.006508343138321759, 'lr_decoder': 0.0005231967806680782, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:55:05,697]\u001b[0m Trial 25 finished with value: 3.1785380840301514 and parameters: {'lstm_hidden_dim': 97, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 8, 'fc_dim1': 6, 'lr_embedding': 0.0014573034925584255, 'lr_decoder': 0.0005806183220486434, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 22:58:27,392]\u001b[0m Trial 26 finished with value: 3.032247304916382 and parameters: {'lstm_hidden_dim': 121, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 6, 'lr_embedding': 0.0030960400399169664, 'lr_decoder': 0.005308533001325106, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:07:53,373]\u001b[0m Trial 27 finished with value: 2.9749608039855957 and parameters: {'lstm_hidden_dim': 166, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.005440172165098421, 'lr_decoder': 0.001171214533492021, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:09:14,712]\u001b[0m Trial 28 finished with value: 3.015138864517212 and parameters: {'lstm_hidden_dim': 51, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 5, 'fc_dim1': 6, 'lr_embedding': 0.006512459489495771, 'lr_decoder': 0.002269401009352664, 'batch_size_power': 7}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:12:24,263]\u001b[0m Trial 29 finished with value: 3.278994083404541 and parameters: {'lstm_hidden_dim': 6, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 2, 'fc_dim1': 9, 'lr_embedding': 0.0014940472086251966, 'lr_decoder': 0.000641245660421196, 'batch_size_power': 6}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:27:56,988]\u001b[0m Trial 30 finished with value: 3.352879524230957 and parameters: {'lstm_hidden_dim': 130, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.0005634982729258753, 'lr_decoder': 0.00035860887623781983, 'batch_size_power': 7}. Best is trial 14 with value: 2.8728604316711426.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:30:16,447]\u001b[0m Trial 31 finished with value: 2.8714022636413574 and parameters: {'lstm_hidden_dim': 79, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.009129787642437324, 'lr_decoder': 0.00025840166356290575, 'batch_size_power': 5}. Best is trial 31 with value: 2.8714022636413574.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:32:46,551]\u001b[0m Trial 32 finished with value: 2.7657430171966553 and parameters: {'lstm_hidden_dim': 96, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.007296445297483424, 'lr_decoder': 0.00029215160573276363, 'batch_size_power': 5}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:36:20,188]\u001b[0m Trial 33 finished with value: 2.877379894256592 and parameters: {'lstm_hidden_dim': 102, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 8, 'lr_embedding': 0.007563415736635208, 'lr_decoder': 0.0002600025316520462, 'batch_size_power': 5}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:40:26,589]\u001b[0m Trial 34 finished with value: 2.949115514755249 and parameters: {'lstm_hidden_dim': 37, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 8, 'lr_embedding': 0.009112304046987388, 'lr_decoder': 0.00010118975693013218, 'batch_size_power': 5}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-15 23:52:02,459]\u001b[0m Trial 35 finished with value: 2.9240500926971436 and parameters: {'lstm_hidden_dim': 153, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.002980262382932316, 'lr_decoder': 0.0002487642213512681, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:08:29,947]\u001b[0m Trial 36 finished with value: 2.9122042655944824 and parameters: {'lstm_hidden_dim': 182, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 7, 'fc_dim1': 13, 'lr_embedding': 0.004238875835913978, 'lr_decoder': 0.0002753726246232017, 'batch_size_power': 5}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:18:29,453]\u001b[0m Trial 37 finished with value: 2.8102850914001465 and parameters: {'lstm_hidden_dim': 204, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3865704614066886, 'fc_dim0': 13, 'lr_embedding': 0.007242241012993068, 'lr_decoder': 0.0001446251616478975, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:24:44,964]\u001b[0m Trial 38 finished with value: 4.832458019256592 and parameters: {'lstm_hidden_dim': 254, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.38534237323468656, 'fc_dim0': 13, 'fc_dim1': 4, 'fc_dim2': 16, 'lr_embedding': 0.0020337509992739426, 'lr_decoder': 8.223643010616764e-05, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:35:14,173]\u001b[0m Trial 39 finished with value: 2.801041603088379 and parameters: {'lstm_hidden_dim': 212, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.47166525342225996, 'fc_dim0': 15, 'lr_embedding': 0.0034644918381038737, 'lr_decoder': 0.0001484416690963873, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:44:57,497]\u001b[0m Trial 40 finished with value: 2.773158073425293 and parameters: {'lstm_hidden_dim': 210, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.47707687993714193, 'fc_dim0': 13, 'lr_embedding': 0.002720968001454533, 'lr_decoder': 0.000154545747237226, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 00:52:21,093]\u001b[0m Trial 41 finished with value: 2.864287853240967 and parameters: {'lstm_hidden_dim': 210, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4939168106568707, 'fc_dim0': 13, 'lr_embedding': 0.003426134741118462, 'lr_decoder': 0.0001449123824189118, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:01:15,306]\u001b[0m Trial 42 finished with value: 2.8611302375793457 and parameters: {'lstm_hidden_dim': 210, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.48992613889866526, 'fc_dim0': 15, 'lr_embedding': 0.003046492114890182, 'lr_decoder': 0.00014077478993948563, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:09:10,835]\u001b[0m Trial 43 finished with value: 2.874061107635498 and parameters: {'lstm_hidden_dim': 232, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.44777204038694035, 'fc_dim0': 15, 'lr_embedding': 0.0025395767112015638, 'lr_decoder': 0.00018595126580805724, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:20:01,344]\u001b[0m Trial 44 finished with value: 2.8710620403289795 and parameters: {'lstm_hidden_dim': 195, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.49025959818148634, 'fc_dim0': 15, 'lr_embedding': 0.002087990429863679, 'lr_decoder': 0.0001173660219544434, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:29:12,449]\u001b[0m Trial 45 finished with value: 2.9374895095825195 and parameters: {'lstm_hidden_dim': 218, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4224735301128273, 'fc_dim0': 14, 'lr_embedding': 0.0011085633647057887, 'lr_decoder': 0.00018303267632173963, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 01:40:22,677]\u001b[0m Trial 46 finished with value: 2.9004244804382324 and parameters: {'lstm_hidden_dim': 240, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3582430916224238, 'fc_dim0': 15, 'lr_embedding': 0.0017805552099470164, 'lr_decoder': 0.00010983728881719496, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:04:15,892]\u001b[0m Trial 47 finished with value: 3.264632225036621 and parameters: {'lstm_hidden_dim': 198, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.45096508367621957, 'fc_dim0': 13, 'lr_embedding': 0.000190077919518094, 'lr_decoder': 8.471694714484246e-05, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:19:03,583]\u001b[0m Trial 48 finished with value: 2.874798536300659 and parameters: {'lstm_hidden_dim': 209, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4945471635260511, 'fc_dim0': 13, 'lr_embedding': 0.0025782521015813285, 'lr_decoder': 0.00015090147488196434, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:31:03,270]\u001b[0m Trial 49 finished with value: 2.8513336181640625 and parameters: {'lstm_hidden_dim': 186, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.407269034863472, 'fc_dim0': 15, 'fc_dim1': 12, 'lr_embedding': 0.00437161502596822, 'lr_decoder': 0.00044743692214192034, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 02:52:53,671]\u001b[0m Trial 50 finished with value: 13.359613418579102 and parameters: {'lstm_hidden_dim': 179, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.39208011456531944, 'fc_dim0': 14, 'fc_dim1': 13, 'fc_dim2': 3, 'lr_embedding': 0.004451635438624418, 'lr_decoder': 0.0003914581887064841, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:03:42,416]\u001b[0m Trial 51 finished with value: 2.843395233154297 and parameters: {'lstm_hidden_dim': 222, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.429920143689293, 'fc_dim0': 15, 'fc_dim1': 11, 'lr_embedding': 0.002871088979638391, 'lr_decoder': 0.00020304591278150387, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:13:53,573]\u001b[0m Trial 52 finished with value: 3.0394325256347656 and parameters: {'lstm_hidden_dim': 227, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.42498702069307237, 'fc_dim0': 16, 'fc_dim1': 11, 'lr_embedding': 0.00417449242642924, 'lr_decoder': 0.00021005524241909143, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:21:29,061]\u001b[0m Trial 53 finished with value: 2.8932201862335205 and parameters: {'lstm_hidden_dim': 243, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3922334652346379, 'fc_dim0': 15, 'fc_dim1': 11, 'lr_embedding': 0.006575662909487978, 'lr_decoder': 0.0003040344667641634, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:27:29,961]\u001b[0m Trial 54 finished with value: 2.920222759246826 and parameters: {'lstm_hidden_dim': 218, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4530440242102863, 'fc_dim0': 14, 'fc_dim1': 8, 'lr_embedding': 0.0050009015607099016, 'lr_decoder': 0.0008611243322347741, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:36:38,712]\u001b[0m Trial 55 finished with value: 2.893624782562256 and parameters: {'lstm_hidden_dim': 187, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3656851201691387, 'fc_dim0': 16, 'fc_dim1': 14, 'lr_embedding': 0.0035607728503994126, 'lr_decoder': 0.00048710167244960277, 'batch_size_power': 5}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 03:45:05,206]\u001b[0m Trial 56 finished with value: 3.2763187885284424 and parameters: {'lstm_hidden_dim': 202, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.41018685997069704, 'fc_dim0': 13, 'fc_dim1': 11, 'fc_dim2': 10, 'lr_embedding': 0.007771246931281964, 'lr_decoder': 0.00021224696944783253, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:02:40,859]\u001b[0m Trial 57 finished with value: 3.7450335025787354 and parameters: {'lstm_hidden_dim': 239, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4626667654726357, 'fc_dim0': 12, 'fc_dim1': 8, 'lr_embedding': 0.0003322461968482824, 'lr_decoder': 0.00033290267557937493, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:13:17,010]\u001b[0m Trial 58 finished with value: 3.2096073627471924 and parameters: {'lstm_hidden_dim': 189, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4363408043255547, 'fc_dim0': 15, 'fc_dim1': 14, 'lr_embedding': 0.0007425748505684662, 'lr_decoder': 0.0004368762344485661, 'batch_size_power': 5}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:26:44,545]\u001b[0m Trial 59 finished with value: 2.952138900756836 and parameters: {'lstm_hidden_dim': 254, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.34227952978203025, 'fc_dim0': 14, 'fc_dim1': 10, 'lr_embedding': 0.0024572831473810993, 'lr_decoder': 7.452517647630054e-05, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:33:35,006]\u001b[0m Trial 60 finished with value: 4.131000518798828 and parameters: {'lstm_hidden_dim': 227, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.4717858738524372, 'fc_dim0': 16, 'fc_dim1': 12, 'fc_dim2': 9, 'lr_embedding': 0.0012898795161667643, 'lr_decoder': 0.00016397466745292184, 'batch_size_power': 5}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:46:27,977]\u001b[0m Trial 61 finished with value: 2.839900016784668 and parameters: {'lstm_hidden_dim': 211, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.48081985610243566, 'fc_dim0': 15, 'lr_embedding': 0.0028772326417093193, 'lr_decoder': 0.00012859282502637626, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 04:59:03,939]\u001b[0m Trial 62 finished with value: 2.863833427429199 and parameters: {'lstm_hidden_dim': 220, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4757626563014241, 'fc_dim0': 16, 'lr_embedding': 0.0019550786649786306, 'lr_decoder': 0.00012719756358330856, 'batch_size_power': 4}. Best is trial 32 with value: 2.7657430171966553.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:09:03,283]\u001b[0m Trial 63 finished with value: 2.759395122528076 and parameters: {'lstm_hidden_dim': 208, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4059475198045948, 'fc_dim0': 15, 'lr_embedding': 0.00591884461823432, 'lr_decoder': 0.00010644585428777933, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:18:04,384]\u001b[0m Trial 64 finished with value: 2.90913987159729 and parameters: {'lstm_hidden_dim': 206, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.442136069286368, 'fc_dim0': 14, 'lr_embedding': 0.005756299506606981, 'lr_decoder': 0.00012219289782476172, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:34:02,182]\u001b[0m Trial 65 finished with value: 2.862211227416992 and parameters: {'lstm_hidden_dim': 167, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3707419114244046, 'fc_dim0': 11, 'lr_embedding': 0.007746306653348412, 'lr_decoder': 9.480000686285512e-05, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:45:57,825]\u001b[0m Trial 66 finished with value: 3.110921859741211 and parameters: {'lstm_hidden_dim': 235, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4336452317629819, 'fc_dim0': 12, 'lr_embedding': 0.00499669408195303, 'lr_decoder': 6.571226428983627e-05, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 05:54:08,773]\u001b[0m Trial 67 finished with value: 2.896906614303589 and parameters: {'lstm_hidden_dim': 196, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.47653815871326766, 'fc_dim0': 14, 'lr_embedding': 0.0027731121987080447, 'lr_decoder': 0.00017179272227455916, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:01:09,539]\u001b[0m Trial 68 finished with value: 2.892528533935547 and parameters: {'lstm_hidden_dim': 247, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.34246097238541934, 'fc_dim0': 16, 'lr_embedding': 0.009906021829023202, 'lr_decoder': 9.265356362280423e-05, 'batch_size_power': 5}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:06:46,570]\u001b[0m Trial 69 finished with value: 3.009922742843628 and parameters: {'lstm_hidden_dim': 217, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.41141501767854305, 'fc_dim0': 15, 'lr_embedding': 0.0033076781591010428, 'lr_decoder': 0.00021968481277844878, 'batch_size_power': 8}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:17:59,688]\u001b[0m Trial 70 finished with value: 2.9183430671691895 and parameters: {'lstm_hidden_dim': 229, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4681567987082303, 'fc_dim0': 13, 'lr_embedding': 0.006094986216937271, 'lr_decoder': 5.4066282894200084e-05, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:30:45,794]\u001b[0m Trial 71 finished with value: 2.7972187995910645 and parameters: {'lstm_hidden_dim': 175, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3826298722673051, 'fc_dim0': 15, 'lr_embedding': 0.003997715317670987, 'lr_decoder': 0.0002369368999461228, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 06:47:36,132]\u001b[0m Trial 72 finished with value: 2.785978078842163 and parameters: {'lstm_hidden_dim': 175, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3887650622938401, 'fc_dim0': 15, 'lr_embedding': 0.004070764233188402, 'lr_decoder': 0.00013364835698108536, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:01:45,416]\u001b[0m Trial 73 finished with value: 2.8726909160614014 and parameters: {'lstm_hidden_dim': 173, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3778316364618904, 'fc_dim0': 14, 'lr_embedding': 0.00390849110057665, 'lr_decoder': 0.00013013050093133125, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:10:51,197]\u001b[0m Trial 74 finished with value: 2.899263381958008 and parameters: {'lstm_hidden_dim': 140, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.31215009029201246, 'fc_dim0': 16, 'lr_embedding': 0.0048445385287360565, 'lr_decoder': 0.00010613478798190971, 'batch_size_power': 5}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:24:33,386]\u001b[0m Trial 75 finished with value: 2.7959165573120117 and parameters: {'lstm_hidden_dim': 175, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.2135373810876654, 'fc_dim0': 12, 'lr_embedding': 0.006742953379438166, 'lr_decoder': 0.00016472553660291898, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:33:27,565]\u001b[0m Trial 76 finished with value: 2.8213324546813965 and parameters: {'lstm_hidden_dim': 159, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.27103270378523614, 'fc_dim0': 12, 'lr_embedding': 0.007028302863962025, 'lr_decoder': 0.00015683764098245952, 'batch_size_power': 5}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 07:44:56,377]\u001b[0m Trial 77 finished with value: 3.2922375202178955 and parameters: {'lstm_hidden_dim': 174, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.40051561441917655, 'fc_dim0': 10, 'lr_embedding': 0.008337392942291005, 'lr_decoder': 0.00024684439693143284, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:00:36,971]\u001b[0m Trial 78 finished with value: 2.944040298461914 and parameters: {'lstm_hidden_dim': 179, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3130525468020112, 'fc_dim0': 11, 'lr_embedding': 0.006013190239735612, 'lr_decoder': 6.30510305746486e-05, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:05:20,166]\u001b[0m Trial 79 finished with value: 2.9585371017456055 and parameters: {'lstm_hidden_dim': 128, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.25519913545013456, 'fc_dim0': 13, 'lr_embedding': 0.006957837696913809, 'lr_decoder': 7.951203019904637e-05, 'batch_size_power': 5}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:17:57,193]\u001b[0m Trial 80 finished with value: 3.8653578758239746 and parameters: {'lstm_hidden_dim': 193, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 1, 'drop_out_flag': True, 'dropout_rate': 0.23917708973352633, 'fc_dim0': 12, 'lr_embedding': 0.00014639420310897869, 'lr_decoder': 0.00029190255667047195, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:26:35,461]\u001b[0m Trial 81 finished with value: 2.812835931777954 and parameters: {'lstm_hidden_dim': 151, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.20231462707773962, 'fc_dim0': 11, 'lr_embedding': 0.006923265800355887, 'lr_decoder': 0.00016592944972948146, 'batch_size_power': 5}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:35:39,022]\u001b[0m Trial 82 finished with value: 2.8224289417266846 and parameters: {'lstm_hidden_dim': 148, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.2234029397827118, 'fc_dim0': 11, 'lr_embedding': 0.0054742820140619465, 'lr_decoder': 0.00015340928124162878, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:44:30,761]\u001b[0m Trial 83 finished with value: 2.8067879676818848 and parameters: {'lstm_hidden_dim': 160, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.20216583228762236, 'fc_dim0': 10, 'lr_embedding': 0.008358200180167662, 'lr_decoder': 0.0001872174239512506, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 08:55:03,379]\u001b[0m Trial 84 finished with value: 2.815448760986328 and parameters: {'lstm_hidden_dim': 162, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3822481496910897, 'fc_dim0': 10, 'lr_embedding': 0.008688923046065736, 'lr_decoder': 0.00023411206708593053, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:08:22,268]\u001b[0m Trial 85 finished with value: 2.8423664569854736 and parameters: {'lstm_hidden_dim': 203, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.22144959519958657, 'fc_dim0': 9, 'lr_embedding': 0.004775187113025449, 'lr_decoder': 0.00010565273827165609, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:19:46,080]\u001b[0m Trial 86 finished with value: 2.7795112133026123 and parameters: {'lstm_hidden_dim': 171, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3532154857917542, 'fc_dim0': 9, 'lr_embedding': 0.009907070180349536, 'lr_decoder': 0.00018695278478561136, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:29:14,698]\u001b[0m Trial 87 finished with value: 3.09074068069458 and parameters: {'lstm_hidden_dim': 172, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.32611173701641943, 'fc_dim0': 9, 'lr_embedding': 0.008368994379206943, 'lr_decoder': 0.0001853875433833293, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:36:47,309]\u001b[0m Trial 88 finished with value: 2.87402606010437 and parameters: {'lstm_hidden_dim': 158, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.35676561459803485, 'fc_dim0': 9, 'lr_embedding': 0.00990465823622658, 'lr_decoder': 0.00032318508677641356, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:48:18,189]\u001b[0m Trial 89 finished with value: 2.762491464614868 and parameters: {'lstm_hidden_dim': 145, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.2894321559472538, 'fc_dim0': 8, 'lr_embedding': 0.0038452786929791126, 'lr_decoder': 0.00019437416472769216, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 09:55:00,671]\u001b[0m Trial 90 finished with value: 2.7980334758758545 and parameters: {'lstm_hidden_dim': 112, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3337076461286206, 'fc_dim0': 8, 'lr_embedding': 0.003875594490993787, 'lr_decoder': 0.00011612158294044905, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:02:08,046]\u001b[0m Trial 91 finished with value: 2.9298927783966064 and parameters: {'lstm_hidden_dim': 115, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.28091899265641257, 'fc_dim0': 8, 'lr_embedding': 0.0035335037425538707, 'lr_decoder': 0.00011859318760678377, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:06:52,255]\u001b[0m Trial 92 finished with value: 2.933572292327881 and parameters: {'lstm_hidden_dim': 91, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3319467119950647, 'fc_dim0': 7, 'lr_embedding': 0.0037293475403753647, 'lr_decoder': 9.461200791831968e-05, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:12:15,607]\u001b[0m Trial 93 finished with value: 2.951188087463379 and parameters: {'lstm_hidden_dim': 107, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.29977180760921296, 'fc_dim0': 6, 'lr_embedding': 0.004159061569870323, 'lr_decoder': 0.0001394299221025974, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:17:51,830]\u001b[0m Trial 94 finished with value: 2.9470300674438477 and parameters: {'lstm_hidden_dim': 122, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.36842493038236335, 'fc_dim0': 8, 'lr_embedding': 0.0032802415343944746, 'lr_decoder': 0.00022366257205945063, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:26:27,212]\u001b[0m Trial 95 finished with value: 2.967674970626831 and parameters: {'lstm_hidden_dim': 146, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.35181291725164676, 'fc_dim0': 7, 'lr_embedding': 0.0017389246898258618, 'lr_decoder': 0.00019654743819674925, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:38:51,126]\u001b[0m Trial 96 finished with value: 5.137027740478516 and parameters: {'lstm_hidden_dim': 137, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4993268706288989, 'fc_dim0': 8, 'lr_embedding': 0.005404508468891348, 'lr_decoder': 0.00036943381313402323, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 10:44:33,331]\u001b[0m Trial 97 finished with value: 2.8493058681488037 and parameters: {'lstm_hidden_dim': 77, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 7, 'lr_embedding': 0.004422124784373523, 'lr_decoder': 0.0001124499344860534, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:00:41,952]\u001b[0m Trial 98 finished with value: 2.889230489730835 and parameters: {'lstm_hidden_dim': 185, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3936432590238364, 'fc_dim0': 9, 'lr_embedding': 0.00237852594505143, 'lr_decoder': 0.00017044696019307578, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:07:39,479]\u001b[0m Trial 99 finished with value: 3.028212547302246 and parameters: {'lstm_hidden_dim': 107, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3274219878222021, 'fc_dim0': 8, 'lr_embedding': 0.006404070104660873, 'lr_decoder': 8.58073121605093e-05, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:21:51,452]\u001b[0m Trial 100 finished with value: 2.9104526042938232 and parameters: {'lstm_hidden_dim': 168, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.34290119348227993, 'fc_dim0': 4, 'lr_embedding': 0.0038761767838895065, 'lr_decoder': 0.0002721649970154407, 'batch_size_power': 4}. Best is trial 63 with value: 2.759395122528076.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:34:22,307]\u001b[0m Trial 101 finished with value: 2.673198699951172 and parameters: {'lstm_hidden_dim': 180, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.2065547491896385, 'fc_dim0': 9, 'lr_embedding': 0.005323495245336534, 'lr_decoder': 0.00018734375719828823, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:45:04,848]\u001b[0m Trial 102 finished with value: 2.8615379333496094 and parameters: {'lstm_hidden_dim': 180, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.22147786185535667, 'fc_dim0': 8, 'lr_embedding': 0.0051161817915499905, 'lr_decoder': 0.00013611312866115138, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:51:04,620]\u001b[0m Trial 103 finished with value: 2.7201170921325684 and parameters: {'lstm_hidden_dim': 134, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.2127374080798907, 'fc_dim0': 9, 'lr_embedding': 0.005977970799077346, 'lr_decoder': 0.0002357884906610054, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 11:56:47,003]\u001b[0m Trial 104 finished with value: 2.762451648712158 and parameters: {'lstm_hidden_dim': 134, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.23709947452008556, 'fc_dim0': 9, 'lr_embedding': 0.005992544984567039, 'lr_decoder': 0.0002549631853413982, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:02:57,943]\u001b[0m Trial 105 finished with value: 2.7547430992126465 and parameters: {'lstm_hidden_dim': 132, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.00591773989072595, 'lr_decoder': 0.0002406090124062628, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:09:32,734]\u001b[0m Trial 106 finished with value: 2.777693748474121 and parameters: {'lstm_hidden_dim': 135, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.00599596383634106, 'lr_decoder': 0.00020279754481906037, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:16:03,011]\u001b[0m Trial 107 finished with value: 2.73761248588562 and parameters: {'lstm_hidden_dim': 135, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.005961965669285809, 'lr_decoder': 0.0003931224228113727, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:22:57,656]\u001b[0m Trial 108 finished with value: 2.696120500564575 and parameters: {'lstm_hidden_dim': 134, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.005987349916335, 'lr_decoder': 0.0002812197740237423, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:29:31,030]\u001b[0m Trial 109 finished with value: 2.7550010681152344 and parameters: {'lstm_hidden_dim': 133, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.005915111469829164, 'lr_decoder': 0.00039485057211014786, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:32:53,623]\u001b[0m Trial 110 finished with value: 2.792738199234009 and parameters: {'lstm_hidden_dim': 128, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.007607542769090985, 'lr_decoder': 0.0007072193931038484, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:38:44,571]\u001b[0m Trial 111 finished with value: 2.811208963394165 and parameters: {'lstm_hidden_dim': 134, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.005781795009597069, 'lr_decoder': 0.0003800335854188839, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:46:56,578]\u001b[0m Trial 112 finished with value: 2.745495319366455 and parameters: {'lstm_hidden_dim': 133, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006154643913111437, 'lr_decoder': 0.00031189836251034294, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:53:44,064]\u001b[0m Trial 113 finished with value: 2.743051052093506 and parameters: {'lstm_hidden_dim': 144, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.005418486286680545, 'lr_decoder': 0.0004296914591379093, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 12:59:34,395]\u001b[0m Trial 114 finished with value: 2.7308647632598877 and parameters: {'lstm_hidden_dim': 144, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.005344115275188464, 'lr_decoder': 0.0005401688408027334, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:05:59,066]\u001b[0m Trial 115 finished with value: 2.7999463081359863 and parameters: {'lstm_hidden_dim': 143, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.004615603754793547, 'lr_decoder': 0.0006087685877240966, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:09:10,830]\u001b[0m Trial 116 finished with value: 2.77107310295105 and parameters: {'lstm_hidden_dim': 123, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.00532241713799222, 'lr_decoder': 0.0005299080102783463, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:17:12,953]\u001b[0m Trial 117 finished with value: 2.750311851501465 and parameters: {'lstm_hidden_dim': 131, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006260864153790787, 'lr_decoder': 0.0004099777685103403, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:24:13,104]\u001b[0m Trial 118 finished with value: 2.7756638526916504 and parameters: {'lstm_hidden_dim': 130, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006214279279550867, 'lr_decoder': 0.00042933715391939965, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:26:37,506]\u001b[0m Trial 119 finished with value: 2.841266393661499 and parameters: {'lstm_hidden_dim': 118, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.0077729043657130854, 'lr_decoder': 0.0004956597963995916, 'batch_size_power': 8}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:33:05,866]\u001b[0m Trial 120 finished with value: 2.7557289600372314 and parameters: {'lstm_hidden_dim': 141, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.005359958079149327, 'lr_decoder': 0.0003358076533702365, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:39:34,960]\u001b[0m Trial 121 finished with value: 2.7734687328338623 and parameters: {'lstm_hidden_dim': 140, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.004911286665894768, 'lr_decoder': 0.0003326938344417494, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:42:34,643]\u001b[0m Trial 122 finished with value: 2.7133469581604004 and parameters: {'lstm_hidden_dim': 125, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.0055818820798551666, 'lr_decoder': 0.00039830226977942467, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:45:21,313]\u001b[0m Trial 123 finished with value: 2.783555507659912 and parameters: {'lstm_hidden_dim': 126, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.005376406182433498, 'lr_decoder': 0.0006914038800940471, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 13:52:27,476]\u001b[0m Trial 124 finished with value: 2.7037501335144043 and parameters: {'lstm_hidden_dim': 155, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006486969915773924, 'lr_decoder': 0.0004538539162045761, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:05:07,988]\u001b[0m Trial 125 finished with value: 3.0487968921661377 and parameters: {'lstm_hidden_dim': 149, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.0004479941613881888, 'lr_decoder': 0.00040074832327392887, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:10:30,157]\u001b[0m Trial 126 finished with value: 2.7139947414398193 and parameters: {'lstm_hidden_dim': 132, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006508115679482762, 'lr_decoder': 0.000559333665424636, 'batch_size_power': 4}. Best is trial 101 with value: 2.673198699951172.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:16:43,332]\u001b[0m Trial 127 finished with value: 2.6659860610961914 and parameters: {'lstm_hidden_dim': 156, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.006894249265605383, 'lr_decoder': 0.0005493147421580531, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:22:03,402]\u001b[0m Trial 128 finished with value: 2.749210834503174 and parameters: {'lstm_hidden_dim': 139, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.006713004227700249, 'lr_decoder': 0.0005304892851645367, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:29:00,351]\u001b[0m Trial 129 finished with value: 2.7552783489227295 and parameters: {'lstm_hidden_dim': 155, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.0069996162923901956, 'lr_decoder': 0.0005546795709639683, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:34:39,402]\u001b[0m Trial 130 finished with value: 2.7815139293670654 and parameters: {'lstm_hidden_dim': 154, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.007966216930472489, 'lr_decoder': 0.0009992067606605264, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:37:34,445]\u001b[0m Trial 131 finished with value: 2.7246875762939453 and parameters: {'lstm_hidden_dim': 125, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006593666522432126, 'lr_decoder': 0.0004436023690136979, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:40:14,360]\u001b[0m Trial 132 finished with value: 2.799198627471924 and parameters: {'lstm_hidden_dim': 119, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.00660905345485647, 'lr_decoder': 0.0004730144422524503, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:42:19,468]\u001b[0m Trial 133 finished with value: 2.745147705078125 and parameters: {'lstm_hidden_dim': 111, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.00910714699298031, 'lr_decoder': 0.0007410691673585142, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:44:51,830]\u001b[0m Trial 134 finished with value: 2.7055139541625977 and parameters: {'lstm_hidden_dim': 126, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.009026085443541883, 'lr_decoder': 0.0006921826292339208, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:46:43,044]\u001b[0m Trial 135 finished with value: 2.7989745140075684 and parameters: {'lstm_hidden_dim': 111, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.008803034044839808, 'lr_decoder': 0.0007854590982127891, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:48:48,921]\u001b[0m Trial 136 finished with value: 2.719115734100342 and parameters: {'lstm_hidden_dim': 125, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.00869759550763244, 'lr_decoder': 0.0006482791353219097, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:51:12,322]\u001b[0m Trial 137 finished with value: 2.7585442066192627 and parameters: {'lstm_hidden_dim': 125, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.009102337420919569, 'lr_decoder': 0.0006667930467324706, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:53:55,876]\u001b[0m Trial 138 finished with value: 2.805021047592163 and parameters: {'lstm_hidden_dim': 100, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.007442521977219675, 'lr_decoder': 0.0007735120084745589, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 14:56:04,663]\u001b[0m Trial 139 finished with value: 2.7936837673187256 and parameters: {'lstm_hidden_dim': 117, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.008812795414676845, 'lr_decoder': 0.0009975804137334584, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:00:51,642]\u001b[0m Trial 140 finished with value: 2.880439281463623 and parameters: {'lstm_hidden_dim': 144, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.007962652535742885, 'lr_decoder': 0.0006194111899310606, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:03:10,938]\u001b[0m Trial 141 finished with value: 2.7403552532196045 and parameters: {'lstm_hidden_dim': 123, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.0071598432160002, 'lr_decoder': 0.0005782910140970605, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:05:12,981]\u001b[0m Trial 142 finished with value: 2.7465457916259766 and parameters: {'lstm_hidden_dim': 126, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.007284013297815967, 'lr_decoder': 0.0008597033446279884, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:08:06,656]\u001b[0m Trial 143 finished with value: 2.6994528770446777 and parameters: {'lstm_hidden_dim': 112, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.008767191890892877, 'lr_decoder': 0.0005745193872888858, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:13:46,792]\u001b[0m Trial 144 finished with value: 3.366001844406128 and parameters: {'lstm_hidden_dim': 121, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 5.754257800811447e-05, 'lr_decoder': 0.00046049501272548527, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:18:18,335]\u001b[0m Trial 145 finished with value: 2.7589199542999268 and parameters: {'lstm_hidden_dim': 139, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.0071519689617840325, 'lr_decoder': 0.0005811739458454444, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:20:50,594]\u001b[0m Trial 146 finished with value: 2.722139358520508 and parameters: {'lstm_hidden_dim': 104, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.00461590121730706, 'lr_decoder': 0.0005701959867118591, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:23:02,094]\u001b[0m Trial 147 finished with value: 2.7751662731170654 and parameters: {'lstm_hidden_dim': 105, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.0081961792931765, 'lr_decoder': 0.000495707313214737, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:25:16,776]\u001b[0m Trial 148 finished with value: 2.754042863845825 and parameters: {'lstm_hidden_dim': 114, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.00953854944255629, 'lr_decoder': 0.000583129571710101, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:27:09,033]\u001b[0m Trial 149 finished with value: 2.787261962890625 and parameters: {'lstm_hidden_dim': 94, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.004716314052210457, 'lr_decoder': 0.000663993509394831, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:28:10,695]\u001b[0m Trial 150 finished with value: 2.8204593658447266 and parameters: {'lstm_hidden_dim': 86, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006850306711566097, 'lr_decoder': 0.0005384845600049527, 'batch_size_power': 7}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:30:37,201]\u001b[0m Trial 151 finished with value: 2.6977884769439697 and parameters: {'lstm_hidden_dim': 121, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.004968846932485005, 'lr_decoder': 0.0004453718765050534, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:32:56,643]\u001b[0m Trial 152 finished with value: 2.771202564239502 and parameters: {'lstm_hidden_dim': 123, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.004421790617321299, 'lr_decoder': 0.0006269535840175714, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:35:53,750]\u001b[0m Trial 153 finished with value: 2.7163422107696533 and parameters: {'lstm_hidden_dim': 119, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.005022040622862503, 'lr_decoder': 0.00047325761923589806, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:38:56,170]\u001b[0m Trial 154 finished with value: 2.7180516719818115 and parameters: {'lstm_hidden_dim': 109, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.004946266050096525, 'lr_decoder': 0.00036298061446248783, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:41:18,946]\u001b[0m Trial 155 finished with value: 2.735166549682617 and parameters: {'lstm_hidden_dim': 104, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.004908208401377668, 'lr_decoder': 0.0004730762961738913, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:44:12,141]\u001b[0m Trial 156 finished with value: 2.775991916656494 and parameters: {'lstm_hidden_dim': 109, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.004551692629892644, 'lr_decoder': 0.0003598921095098944, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:47:45,370]\u001b[0m Trial 157 finished with value: 2.741349697113037 and parameters: {'lstm_hidden_dim': 115, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.0052081895728535825, 'lr_decoder': 0.000285097126749088, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:52:05,800]\u001b[0m Trial 158 finished with value: 3.0464138984680176 and parameters: {'lstm_hidden_dim': 100, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.0007714840219745585, 'lr_decoder': 0.00044596372918517823, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:54:37,793]\u001b[0m Trial 159 finished with value: 2.795502185821533 and parameters: {'lstm_hidden_dim': 119, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.0079883194615652, 'lr_decoder': 0.0005214960824868232, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 15:59:16,688]\u001b[0m Trial 160 finished with value: 2.7068772315979004 and parameters: {'lstm_hidden_dim': 129, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.005557606933227634, 'lr_decoder': 0.0003632190639664812, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:01:49,924]\u001b[0m Trial 161 finished with value: 2.766125440597534 and parameters: {'lstm_hidden_dim': 127, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.005609650316293044, 'lr_decoder': 0.0003423352673572935, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:05:58,503]\u001b[0m Trial 162 finished with value: 2.77567458152771 and parameters: {'lstm_hidden_dim': 129, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.00485261563724901, 'lr_decoder': 0.0008929930981863102, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:08:10,688]\u001b[0m Trial 163 finished with value: 2.7883124351501465 and parameters: {'lstm_hidden_dim': 115, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.006491400678605476, 'lr_decoder': 0.0004870265826129996, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:11:31,373]\u001b[0m Trial 164 finished with value: 2.685309886932373 and parameters: {'lstm_hidden_dim': 121, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.004386306176347624, 'lr_decoder': 0.00037066807528187724, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:14:29,361]\u001b[0m Trial 165 finished with value: 2.725261688232422 and parameters: {'lstm_hidden_dim': 110, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.004446755518090528, 'lr_decoder': 0.00029702527596103145, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:16:54,989]\u001b[0m Trial 166 finished with value: 2.711374521255493 and parameters: {'lstm_hidden_dim': 120, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.006477301640729249, 'lr_decoder': 0.000422217030953285, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:21:27,887]\u001b[0m Trial 167 finished with value: 2.6766562461853027 and parameters: {'lstm_hidden_dim': 120, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.004158739638676279, 'lr_decoder': 0.00037423957979151103, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:25:38,385]\u001b[0m Trial 168 finished with value: 2.7464327812194824 and parameters: {'lstm_hidden_dim': 121, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.0041461199859517415, 'lr_decoder': 0.00037622872162907745, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:29:06,149]\u001b[0m Trial 169 finished with value: 2.7413268089294434 and parameters: {'lstm_hidden_dim': 119, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.005679669376775908, 'lr_decoder': 0.00031553965740146865, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:34:31,928]\u001b[0m Trial 170 finished with value: 2.7598533630371094 and parameters: {'lstm_hidden_dim': 130, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.007612531521116692, 'lr_decoder': 0.00036488672635096503, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:37:33,778]\u001b[0m Trial 171 finished with value: 2.7707033157348633 and parameters: {'lstm_hidden_dim': 107, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.004974263235964963, 'lr_decoder': 0.00039375719166675913, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:40:59,653]\u001b[0m Trial 172 finished with value: 2.8416833877563477 and parameters: {'lstm_hidden_dim': 114, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.004296817681469343, 'lr_decoder': 0.00027377146329224345, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:45:00,542]\u001b[0m Trial 173 finished with value: 2.7575864791870117 and parameters: {'lstm_hidden_dim': 102, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 13, 'lr_embedding': 0.003532253258925864, 'lr_decoder': 0.00043397856705842264, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:48:10,434]\u001b[0m Trial 174 finished with value: 2.7655882835388184 and parameters: {'lstm_hidden_dim': 118, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.006410805936964281, 'lr_decoder': 0.0003542561131117471, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:49:59,828]\u001b[0m Trial 175 finished with value: 2.754729747772217 and parameters: {'lstm_hidden_dim': 95, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.009937239941185068, 'lr_decoder': 0.0007050932635025307, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:53:10,778]\u001b[0m Trial 176 finished with value: 2.7357590198516846 and parameters: {'lstm_hidden_dim': 124, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.005554908248448753, 'lr_decoder': 0.00042226159474226444, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 16:58:25,592]\u001b[0m Trial 177 finished with value: 2.740732192993164 and parameters: {'lstm_hidden_dim': 136, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 13, 'lr_embedding': 0.008370538451158227, 'lr_decoder': 0.000487068142027386, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:01:27,687]\u001b[0m Trial 178 finished with value: 2.820974588394165 and parameters: {'lstm_hidden_dim': 111, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.006277333445035701, 'lr_decoder': 0.0006287897278850287, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:14:22,437]\u001b[0m Trial 179 finished with value: 3.1546990871429443 and parameters: {'lstm_hidden_dim': 130, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.00023347906973160786, 'lr_decoder': 0.00030595655947809343, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:17:20,985]\u001b[0m Trial 180 finished with value: 2.820228338241577 and parameters: {'lstm_hidden_dim': 119, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 9, 'lr_embedding': 0.0031474935823026452, 'lr_decoder': 0.0005522582360564106, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:20:57,659]\u001b[0m Trial 181 finished with value: 2.732933759689331 and parameters: {'lstm_hidden_dim': 123, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.006664785690554747, 'lr_decoder': 0.00042811621481613675, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:24:33,113]\u001b[0m Trial 182 finished with value: 2.825228452682495 and parameters: {'lstm_hidden_dim': 126, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 10, 'lr_embedding': 0.0049115972805092185, 'lr_decoder': 0.0004910801838891645, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:31:08,758]\u001b[0m Trial 183 finished with value: 2.7074787616729736 and parameters: {'lstm_hidden_dim': 136, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.007311134567972864, 'lr_decoder': 0.0004408587472076568, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:38:06,357]\u001b[0m Trial 184 finished with value: 2.7343575954437256 and parameters: {'lstm_hidden_dim': 132, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.007470848358911439, 'lr_decoder': 0.00036790137298080213, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 17:44:54,638]\u001b[0m Trial 185 finished with value: 2.720240592956543 and parameters: {'lstm_hidden_dim': 138, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.005691591815902917, 'lr_decoder': 0.00033784288388043085, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:00:34,062]\u001b[0m Trial 186 finished with value: 3.0345938205718994 and parameters: {'lstm_hidden_dim': 139, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'fc_dim1': 3, 'fc_dim2': 12, 'lr_embedding': 0.005815911371535354, 'lr_decoder': 0.00033066365776629724, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:08:01,050]\u001b[0m Trial 187 finished with value: 2.7099554538726807 and parameters: {'lstm_hidden_dim': 151, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.008532015378568621, 'lr_decoder': 0.0002589305516046942, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:15:07,839]\u001b[0m Trial 188 finished with value: 2.7139480113983154 and parameters: {'lstm_hidden_dim': 162, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.009140423460905923, 'lr_decoder': 0.00025772823051276907, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:22:40,513]\u001b[0m Trial 189 finished with value: 2.726242780685425 and parameters: {'lstm_hidden_dim': 164, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 13, 'lr_embedding': 0.009042285616951532, 'lr_decoder': 0.0002680803651288547, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:28:15,503]\u001b[0m Trial 190 finished with value: 2.7277297973632812 and parameters: {'lstm_hidden_dim': 150, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.009020029949502545, 'lr_decoder': 0.0004022418856593254, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:36:17,476]\u001b[0m Trial 191 finished with value: 2.753838300704956 and parameters: {'lstm_hidden_dim': 166, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.008230005543507824, 'lr_decoder': 0.0002305021150198277, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:42:29,526]\u001b[0m Trial 192 finished with value: 2.825288772583008 and parameters: {'lstm_hidden_dim': 155, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.007360519290815612, 'lr_decoder': 0.0002575261819677026, 'batch_size_power': 6}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:49:32,134]\u001b[0m Trial 193 finished with value: 2.8062307834625244 and parameters: {'lstm_hidden_dim': 161, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.008408499292700995, 'lr_decoder': 0.00031140476176864625, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 18:57:10,321]\u001b[0m Trial 194 finished with value: 2.7308173179626465 and parameters: {'lstm_hidden_dim': 147, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 13, 'lr_embedding': 0.007124229018871113, 'lr_decoder': 0.0002101534999525933, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 19:04:32,120]\u001b[0m Trial 195 finished with value: 2.722148895263672 and parameters: {'lstm_hidden_dim': 129, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.009381392785125018, 'lr_decoder': 0.00045853370563143036, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 19:12:19,730]\u001b[0m Trial 196 finished with value: 2.770949602127075 and parameters: {'lstm_hidden_dim': 159, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 11, 'lr_embedding': 0.007815193439731452, 'lr_decoder': 0.000244987570559224, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 19:17:56,923]\u001b[0m Trial 197 finished with value: 2.7165026664733887 and parameters: {'lstm_hidden_dim': 152, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.0064758945187141535, 'lr_decoder': 0.0003885390394203827, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 19:23:47,522]\u001b[0m Trial 198 finished with value: 2.708065986633301 and parameters: {'lstm_hidden_dim': 151, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.006768219605453526, 'lr_decoder': 0.0003974231799684366, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n",
      "\u001b[32m[I 2023-03-16 19:29:18,578]\u001b[0m Trial 199 finished with value: 2.6991546154022217 and parameters: {'lstm_hidden_dim': 154, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 12, 'lr_embedding': 0.0066196491693663205, 'lr_decoder': 0.00039844186388865904, 'batch_size_power': 4}. Best is trial 127 with value: 2.6659860610961914.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"base_model\", direction=\"minimize\", pruner=optuna.pruners.NopPruner()\n",
    ")\n",
    "study.optimize(LSTM_objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/camels_lstm_study.pkl']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, \"data/camels_lstm_study.pkl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import HydroErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.load(\"data/camles_final_lstm_embedding.pt\").to(computing_device)\n",
    "decoder = torch.load(\"data/camels_final_lstm_decoder.pt\", map_location=torch.device('cpu')).to(computing_device)\n",
    "\n",
    "embedding.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# dimension of embedding\n",
    "catchment_embeddings=[x.data for x in embedding.parameters()][0]\n",
    "LATENT_dim = catchment_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective_builder:\n",
    "    def __init__(self, x, y, eval_fun):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.x = x.contiguous()\n",
    "        self.y = y.contiguous()\n",
    "    \n",
    "    def eval(self, code, return_summary = True):\n",
    "        \n",
    "        # numpy to torch tensor\n",
    "        code = torch.from_numpy(code).unsqueeze(0).to(dtype=torch.float32).to(computing_device)\n",
    "        code = code.expand(self.x.shape[0], -1)\n",
    "        \n",
    "        # BASE_LENGTH is from global\n",
    "        pred = decoder.decode(code, self.x).view(-1).detach().cpu().numpy()\n",
    "\n",
    "        ob = self.y.view(-1).detach().cpu().numpy()\n",
    "        \n",
    "        if return_summary:\n",
    "          gof = self.eval_fun(simulated_array=pred, observed_array=ob)\n",
    "          return gof\n",
    "        else:\n",
    "          return pred, ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12, 671, 730, 3]), torch.Size([12, 671, 365]))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_test, y_batch_test = dtest.get_val_batch()\n",
    "x_batch_test.shape, y_batch_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_catchment(selected_catchment):\n",
    "    \n",
    "    x = x_batch_test[:,selected_catchment,:,:]\n",
    "    y = y_batch_test[:,selected_catchment,:]\n",
    "\n",
    "    x, y = x.to(computing_device), y.to(computing_device)\n",
    "\n",
    "    fn = Objective_builder(x,y,HydroErr.kge_2009)\n",
    "    \n",
    "    return  fn.eval(catchment_embeddings[selected_catchment,:].cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 starts\n",
      "fit=0.8687170787801656\n",
      "i=1 starts\n",
      "fit=0.8371521851326341\n",
      "i=2 starts\n",
      "fit=0.9051235081523311\n",
      "i=3 starts\n",
      "fit=0.8390723383853963\n",
      "i=4 starts\n",
      "fit=0.859567029785115\n",
      "i=5 starts\n",
      "fit=0.8646708550217062\n",
      "i=6 starts\n",
      "fit=0.802400781609818\n",
      "i=7 starts\n",
      "fit=0.8687138077569931\n",
      "i=8 starts\n",
      "fit=0.8984770421914342\n",
      "i=9 starts\n",
      "fit=0.860916368880254\n",
      "i=10 starts\n",
      "fit=0.8423421603354113\n",
      "i=11 starts\n",
      "fit=0.8966246170852397\n",
      "i=12 starts\n",
      "fit=0.775447578691478\n",
      "i=13 starts\n",
      "fit=0.8691187440387788\n",
      "i=14 starts\n",
      "fit=0.8593866044759391\n",
      "i=15 starts\n",
      "fit=0.7906844081501059\n",
      "i=16 starts\n",
      "fit=0.8443428016169615\n",
      "i=17 starts\n",
      "fit=0.8034755506781535\n",
      "i=18 starts\n",
      "fit=0.8980398430718806\n",
      "i=19 starts\n",
      "fit=0.8658526336226324\n",
      "i=20 starts\n",
      "fit=0.8535560590291359\n",
      "i=21 starts\n",
      "fit=0.6762228095369869\n",
      "i=22 starts\n",
      "fit=0.7323229588861392\n",
      "i=23 starts\n",
      "fit=0.6940077389548709\n",
      "i=24 starts\n",
      "fit=0.7525920890985042\n",
      "i=25 starts\n",
      "fit=0.837864131003953\n",
      "i=26 starts\n",
      "fit=0.7262686592450402\n",
      "i=27 starts\n",
      "fit=0.8510317003676728\n",
      "i=28 starts\n",
      "fit=0.6641448150704689\n",
      "i=29 starts\n",
      "fit=0.7216377460991684\n",
      "i=30 starts\n",
      "fit=0.7856007148840822\n",
      "i=31 starts\n",
      "fit=0.6625110053297736\n",
      "i=32 starts\n",
      "fit=0.7069815828856174\n",
      "i=33 starts\n",
      "fit=0.7938231738771079\n",
      "i=34 starts\n",
      "fit=0.73780545191205\n",
      "i=35 starts\n",
      "fit=0.820527646433678\n",
      "i=36 starts\n",
      "fit=0.7523493276702189\n",
      "i=37 starts\n",
      "fit=0.832088524073558\n",
      "i=38 starts\n",
      "fit=0.8920351667699188\n",
      "i=39 starts\n",
      "fit=0.8586247752389673\n",
      "i=40 starts\n",
      "fit=0.8460687910326399\n",
      "i=41 starts\n",
      "fit=0.8535694242613082\n",
      "i=42 starts\n",
      "fit=0.3747710668806933\n",
      "i=43 starts\n",
      "fit=0.7156987493059653\n",
      "i=44 starts\n",
      "fit=0.7533476003993254\n",
      "i=45 starts\n",
      "fit=0.808908695720006\n",
      "i=46 starts\n",
      "fit=0.8303829076670096\n",
      "i=47 starts\n",
      "fit=0.5119417440611709\n",
      "i=48 starts\n",
      "fit=0.7485758445966357\n",
      "i=49 starts\n",
      "fit=0.489066035690341\n",
      "i=50 starts\n",
      "fit=0.8077827806838827\n",
      "i=51 starts\n",
      "fit=0.7429435623582532\n",
      "i=52 starts\n",
      "fit=0.9366433314005607\n",
      "i=53 starts\n",
      "fit=0.816362760736441\n",
      "i=54 starts\n",
      "fit=0.8948820833816744\n",
      "i=55 starts\n",
      "fit=0.9165741535269255\n",
      "i=56 starts\n",
      "fit=0.8289815474086022\n",
      "i=57 starts\n",
      "fit=0.6626830417214278\n",
      "i=58 starts\n",
      "fit=0.8677037472920796\n",
      "i=59 starts\n",
      "fit=0.7888184457093942\n",
      "i=60 starts\n",
      "fit=0.7143680040774352\n",
      "i=61 starts\n",
      "fit=0.805148080209402\n",
      "i=62 starts\n",
      "fit=0.788717775291859\n",
      "i=63 starts\n",
      "fit=0.8617003647777122\n",
      "i=64 starts\n",
      "fit=0.8316593686780042\n",
      "i=65 starts\n",
      "fit=0.8028251954320449\n",
      "i=66 starts\n",
      "fit=0.8677691480880874\n",
      "i=67 starts\n",
      "fit=0.6845953945770691\n",
      "i=68 starts\n",
      "fit=0.7479993591622404\n",
      "i=69 starts\n",
      "fit=0.5779190968796677\n",
      "i=70 starts\n",
      "fit=0.7181426052318647\n",
      "i=71 starts\n",
      "fit=0.7753026887389535\n",
      "i=72 starts\n",
      "fit=0.851735397270164\n",
      "i=73 starts\n",
      "fit=0.7155112141944577\n",
      "i=74 starts\n",
      "fit=0.802702324359428\n",
      "i=75 starts\n",
      "fit=0.7682166722366212\n",
      "i=76 starts\n",
      "fit=0.7418704117374506\n",
      "i=77 starts\n",
      "fit=0.5991222123056346\n",
      "i=78 starts\n",
      "fit=0.7570256413012937\n",
      "i=79 starts\n",
      "fit=0.5789264473206095\n",
      "i=80 starts\n",
      "fit=0.697093416521487\n",
      "i=81 starts\n",
      "fit=0.7557938898049119\n",
      "i=82 starts\n",
      "fit=0.7867825585195177\n",
      "i=83 starts\n",
      "fit=0.7426490288909615\n",
      "i=84 starts\n",
      "fit=0.8237392298607766\n",
      "i=85 starts\n",
      "fit=0.542751772906826\n",
      "i=86 starts\n",
      "fit=0.7677870691887534\n",
      "i=87 starts\n",
      "fit=0.7362829309853175\n",
      "i=88 starts\n",
      "fit=0.7809951811655155\n",
      "i=89 starts\n",
      "fit=0.828521748996591\n",
      "i=90 starts\n",
      "fit=0.7692891291583536\n",
      "i=91 starts\n",
      "fit=0.7152966270784265\n",
      "i=92 starts\n",
      "fit=0.6802570409995968\n",
      "i=93 starts\n",
      "fit=0.7625935831339089\n",
      "i=94 starts\n",
      "fit=0.6753498199752659\n",
      "i=95 starts\n",
      "fit=0.7371428997742419\n",
      "i=96 starts\n",
      "fit=0.8205901140620694\n",
      "i=97 starts\n",
      "fit=0.6524597045377105\n",
      "i=98 starts\n",
      "fit=0.51632763898487\n",
      "i=99 starts\n",
      "fit=0.5169622248694536\n",
      "i=100 starts\n",
      "fit=0.5390186047130645\n",
      "i=101 starts\n",
      "fit=0.833582331345987\n",
      "i=102 starts\n",
      "fit=0.5308038657211519\n",
      "i=103 starts\n",
      "fit=0.84565127427855\n",
      "i=104 starts\n",
      "fit=0.5437257421250392\n",
      "i=105 starts\n",
      "fit=0.6828464131200347\n",
      "i=106 starts\n",
      "fit=0.6546672262732406\n",
      "i=107 starts\n",
      "fit=0.7678245632182796\n",
      "i=108 starts\n",
      "fit=0.6437532928245764\n",
      "i=109 starts\n",
      "fit=0.20588278673140947\n",
      "i=110 starts\n",
      "fit=0.6313344495105643\n",
      "i=111 starts\n",
      "fit=0.7961865590226219\n",
      "i=112 starts\n",
      "fit=0.7145550354385091\n",
      "i=113 starts\n",
      "fit=0.7526063195715074\n",
      "i=114 starts\n",
      "fit=0.6624733342334511\n",
      "i=115 starts\n",
      "fit=0.8047797751002539\n",
      "i=116 starts\n",
      "fit=0.8635404582105243\n",
      "i=117 starts\n",
      "fit=0.7714051820094003\n",
      "i=118 starts\n",
      "fit=0.4393606860416245\n",
      "i=119 starts\n",
      "fit=0.5527191549908357\n",
      "i=120 starts\n",
      "fit=0.7319070314722302\n",
      "i=121 starts\n",
      "fit=0.7235687568811556\n",
      "i=122 starts\n",
      "fit=0.7809441126772462\n",
      "i=123 starts\n",
      "fit=0.7014802891232923\n",
      "i=124 starts\n",
      "fit=0.7331677702974118\n",
      "i=125 starts\n",
      "fit=0.7914975265978299\n",
      "i=126 starts\n",
      "fit=0.6755455741739969\n",
      "i=127 starts\n",
      "fit=0.5790856026528404\n",
      "i=128 starts\n",
      "fit=0.8490005185551985\n",
      "i=129 starts\n",
      "fit=0.865561733497746\n",
      "i=130 starts\n",
      "fit=0.83241905418588\n",
      "i=131 starts\n",
      "fit=0.8293177202993733\n",
      "i=132 starts\n",
      "fit=0.5757079504717681\n",
      "i=133 starts\n",
      "fit=0.785659239804445\n",
      "i=134 starts\n",
      "fit=0.8504374619332197\n",
      "i=135 starts\n",
      "fit=0.8809645513655655\n",
      "i=136 starts\n",
      "fit=0.6687466955511991\n",
      "i=137 starts\n",
      "fit=0.5642795697525509\n",
      "i=138 starts\n",
      "fit=0.6392144306309286\n",
      "i=139 starts\n",
      "fit=0.2591601148277526\n",
      "i=140 starts\n",
      "fit=0.24796469622072437\n",
      "i=141 starts\n",
      "fit=0.5229195364852504\n",
      "i=142 starts\n",
      "fit=0.28199688249184396\n",
      "i=143 starts\n",
      "fit=0.6953905545569866\n",
      "i=144 starts\n",
      "fit=0.3494153881869103\n",
      "i=145 starts\n",
      "fit=0.5443899263900277\n",
      "i=146 starts\n",
      "fit=0.687320818964574\n",
      "i=147 starts\n",
      "fit=0.654094006296815\n",
      "i=148 starts\n",
      "fit=0.48749155504749553\n",
      "i=149 starts\n",
      "fit=0.7759262902127483\n",
      "i=150 starts\n",
      "fit=0.5577806581494804\n",
      "i=151 starts\n",
      "fit=0.621681088132066\n",
      "i=152 starts\n",
      "fit=0.6828924356089807\n",
      "i=153 starts\n",
      "fit=0.6892901196239485\n",
      "i=154 starts\n",
      "fit=0.6382416533310571\n",
      "i=155 starts\n",
      "fit=0.6821504780654504\n",
      "i=156 starts\n",
      "fit=0.1677585148871007\n",
      "i=157 starts\n",
      "fit=0.5727099060471751\n",
      "i=158 starts\n",
      "fit=0.30178359800248067\n",
      "i=159 starts\n",
      "fit=0.3870604658423552\n",
      "i=160 starts\n",
      "fit=0.5866814914365892\n",
      "i=161 starts\n",
      "fit=0.6722568425552897\n",
      "i=162 starts\n",
      "fit=0.6861886566534949\n",
      "i=163 starts\n",
      "fit=0.27583287419017677\n",
      "i=164 starts\n",
      "fit=0.6867077484528834\n",
      "i=165 starts\n",
      "fit=0.817889844237143\n",
      "i=166 starts\n",
      "fit=0.7452949059349547\n",
      "i=167 starts\n",
      "fit=0.7408876007273311\n",
      "i=168 starts\n",
      "fit=0.7046188078350384\n",
      "i=169 starts\n",
      "fit=0.7131555321750767\n",
      "i=170 starts\n",
      "fit=0.7673290991181411\n",
      "i=171 starts\n",
      "fit=0.5439507191367465\n",
      "i=172 starts\n",
      "fit=0.7270612427055716\n",
      "i=173 starts\n",
      "fit=0.6832544759208321\n",
      "i=174 starts\n",
      "fit=0.6189526897151185\n",
      "i=175 starts\n",
      "fit=0.5290351605301994\n",
      "i=176 starts\n",
      "fit=0.6333248546816405\n",
      "i=177 starts\n",
      "fit=0.8077723189351216\n",
      "i=178 starts\n",
      "fit=0.7566031423492657\n",
      "i=179 starts\n",
      "fit=0.44662504319033736\n",
      "i=180 starts\n",
      "fit=0.8032749238996539\n",
      "i=181 starts\n",
      "fit=0.7759110579504227\n",
      "i=182 starts\n",
      "fit=0.618960276108989\n",
      "i=183 starts\n",
      "fit=0.7712941019577958\n",
      "i=184 starts\n",
      "fit=0.6737997303697647\n",
      "i=185 starts\n",
      "fit=0.7659411050045102\n",
      "i=186 starts\n",
      "fit=0.6975630096732783\n",
      "i=187 starts\n",
      "fit=0.8232147763448983\n",
      "i=188 starts\n",
      "fit=0.8459151466288755\n",
      "i=189 starts\n",
      "fit=0.8379872290130598\n",
      "i=190 starts\n",
      "fit=0.7681111552366676\n",
      "i=191 starts\n",
      "fit=0.7580820187418137\n",
      "i=192 starts\n",
      "fit=0.8076407773240859\n",
      "i=193 starts\n",
      "fit=0.8821792647708329\n",
      "i=194 starts\n",
      "fit=0.7664692229679053\n",
      "i=195 starts\n",
      "fit=0.8568347334032318\n",
      "i=196 starts\n",
      "fit=0.6654806196168689\n",
      "i=197 starts\n",
      "fit=0.7569707030634321\n",
      "i=198 starts\n",
      "fit=0.777118757261154\n",
      "i=199 starts\n",
      "fit=0.853260597977069\n",
      "i=200 starts\n",
      "fit=0.39866977022702876\n",
      "i=201 starts\n",
      "fit=0.8747906193739026\n",
      "i=202 starts\n",
      "fit=0.8904208401796703\n",
      "i=203 starts\n",
      "fit=0.919185008238627\n",
      "i=204 starts\n",
      "fit=0.84480420967983\n",
      "i=205 starts\n",
      "fit=0.7809082215653143\n",
      "i=206 starts\n",
      "fit=0.8448920016066315\n",
      "i=207 starts\n",
      "fit=0.7617139376623524\n",
      "i=208 starts\n",
      "fit=0.7969628032975566\n",
      "i=209 starts\n",
      "fit=0.7411025902985025\n",
      "i=210 starts\n",
      "fit=0.9198385735710564\n",
      "i=211 starts\n",
      "fit=0.854531359115962\n",
      "i=212 starts\n",
      "fit=0.7365895269906902\n",
      "i=213 starts\n",
      "fit=0.7947513634546525\n",
      "i=214 starts\n",
      "fit=0.8989166237348525\n",
      "i=215 starts\n",
      "fit=0.8074034464817182\n",
      "i=216 starts\n",
      "fit=0.8108413401402892\n",
      "i=217 starts\n",
      "fit=0.828546121688915\n",
      "i=218 starts\n",
      "fit=0.8208904497243812\n",
      "i=219 starts\n",
      "fit=0.8274034091434053\n",
      "i=220 starts\n",
      "fit=0.5184064314421077\n",
      "i=221 starts\n",
      "fit=0.8169266267711132\n",
      "i=222 starts\n",
      "fit=0.8178556059517217\n",
      "i=223 starts\n",
      "fit=0.8035350469127178\n",
      "i=224 starts\n",
      "fit=0.5960660608600725\n",
      "i=225 starts\n",
      "fit=0.8183740445365998\n",
      "i=226 starts\n",
      "fit=0.7619736721955981\n",
      "i=227 starts\n",
      "fit=0.8321941420282281\n",
      "i=228 starts\n",
      "fit=0.7693388249372904\n",
      "i=229 starts\n",
      "fit=0.7544059980393664\n",
      "i=230 starts\n",
      "fit=0.8458441589480548\n",
      "i=231 starts\n",
      "fit=0.8211756983927396\n",
      "i=232 starts\n",
      "fit=0.840382690531232\n",
      "i=233 starts\n",
      "fit=0.6765102124959588\n",
      "i=234 starts\n",
      "fit=0.7717196262080239\n",
      "i=235 starts\n",
      "fit=0.8154321809385003\n",
      "i=236 starts\n",
      "fit=0.6931767920968415\n",
      "i=237 starts\n",
      "fit=0.7292805942633649\n",
      "i=238 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [ 639  640  641 ... 4377 4378 4379] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit=0.7436378385961884\n",
      "i=239 starts\n",
      "fit=0.7734569040985402\n",
      "i=240 starts\n",
      "fit=0.740314914489627\n",
      "i=241 starts\n",
      "fit=0.8499799915056946\n",
      "i=242 starts\n",
      "fit=0.7757905487105196\n",
      "i=243 starts\n",
      "fit=0.7034718664175983\n",
      "i=244 starts\n",
      "fit=0.8249288397811146\n",
      "i=245 starts\n",
      "fit=0.9031497320680072\n",
      "i=246 starts\n",
      "fit=0.8433072694312447\n",
      "i=247 starts\n",
      "fit=0.8562109559155717\n",
      "i=248 starts\n",
      "fit=0.8934912265940744\n",
      "i=249 starts\n",
      "fit=0.8869517329779535\n",
      "i=250 starts\n",
      "fit=0.8105919173535464\n",
      "i=251 starts\n",
      "fit=0.8013639199835465\n",
      "i=252 starts\n",
      "fit=0.8549654622401773\n",
      "i=253 starts\n",
      "fit=0.7679201944998864\n",
      "i=254 starts\n",
      "fit=0.7737484768912757\n",
      "i=255 starts\n",
      "fit=0.7714532242765801\n",
      "i=256 starts\n",
      "fit=0.8628684903427228\n",
      "i=257 starts\n",
      "fit=0.8535247145931578\n",
      "i=258 starts\n",
      "fit=0.906588566255435\n",
      "i=259 starts\n",
      "fit=0.7332769614323966\n",
      "i=260 starts\n",
      "fit=0.854923296858623\n",
      "i=261 starts\n",
      "fit=0.8095050736577691\n",
      "i=262 starts\n",
      "fit=0.8262283568515654\n",
      "i=263 starts\n",
      "fit=0.8689701557275336\n",
      "i=264 starts\n",
      "fit=0.7973743500195501\n",
      "i=265 starts\n",
      "fit=0.6203394500132914\n",
      "i=266 starts\n",
      "fit=0.6646279185563375\n",
      "i=267 starts\n",
      "fit=0.6369107904112494\n",
      "i=268 starts\n",
      "fit=0.7207897861764418\n",
      "i=269 starts\n",
      "fit=0.7700581122149668\n",
      "i=270 starts\n",
      "fit=0.7775762051764257\n",
      "i=271 starts\n",
      "fit=0.7343823919969954\n",
      "i=272 starts\n",
      "fit=0.8234323017816709\n",
      "i=273 starts\n",
      "fit=0.7151064728370796\n",
      "i=274 starts\n",
      "fit=0.29463578248362277\n",
      "i=275 starts\n",
      "fit=0.8102157502405382\n",
      "i=276 starts\n",
      "fit=0.8633720848610619\n",
      "i=277 starts\n",
      "fit=0.7870762326056577\n",
      "i=278 starts\n",
      "fit=0.7404847169029717\n",
      "i=279 starts\n",
      "fit=0.7572936528281082\n",
      "i=280 starts\n",
      "fit=0.5339592282473122\n",
      "i=281 starts\n",
      "fit=0.8224448423961965\n",
      "i=282 starts\n",
      "fit=0.9023137848232492\n",
      "i=283 starts\n",
      "fit=0.776067487421606\n",
      "i=284 starts\n",
      "fit=0.7966833573159375\n",
      "i=285 starts\n",
      "fit=0.8780784981223426\n",
      "i=286 starts\n",
      "fit=0.804924886004622\n",
      "i=287 starts\n",
      "fit=0.4741400833236209\n",
      "i=288 starts\n",
      "fit=0.6661470247241366\n",
      "i=289 starts\n",
      "fit=0.4965177998343395\n",
      "i=290 starts\n",
      "fit=0.4302255378277168\n",
      "i=291 starts\n",
      "fit=0.6204271375975057\n",
      "i=292 starts\n",
      "fit=-0.6725923562292884\n",
      "i=293 starts\n",
      "fit=0.3861390133399182\n",
      "i=294 starts\n",
      "fit=0.7720626583498449\n",
      "i=295 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [1270 1271 4018 4019 4020 4021 4022 4023 4024 4025 4026 4027 4028 4029\n",
      " 4030 4031 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041 4042 4043\n",
      " 4044 4045 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055 4056 4057\n",
      " 4058 4059 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069 4070 4071\n",
      " 4072 4073 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083 4084 4085\n",
      " 4086 4087 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097 4098 4099\n",
      " 4100 4101 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111 4112 4113\n",
      " 4114 4115 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125 4126 4127\n",
      " 4128 4129 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139 4140 4141\n",
      " 4142 4143 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153 4154 4155\n",
      " 4156 4157 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167 4168 4169\n",
      " 4170 4171 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181 4182 4183\n",
      " 4184 4185 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195 4196 4197\n",
      " 4198 4199 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209 4210 4211\n",
      " 4212 4213 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223 4224 4225\n",
      " 4226 4227 4228 4229 4230 4231 4232 4233 4234 4235 4236 4237 4238 4239\n",
      " 4240 4241 4242 4243 4244 4245 4246 4247 4248 4249 4250 4251 4252 4253\n",
      " 4254 4255 4256 4257 4258 4259 4260 4261 4262 4263 4264 4265 4266 4267\n",
      " 4268 4269 4270 4271 4272 4273 4274 4275 4276 4277 4278 4279 4280 4281\n",
      " 4282 4283 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293 4294 4295\n",
      " 4296 4297 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307 4308 4309\n",
      " 4310 4311 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321 4322 4323\n",
      " 4324 4325 4326 4327 4328 4329 4330 4331 4332 4333 4334 4335 4336 4337\n",
      " 4338 4339 4340 4341 4342 4343 4344 4345 4346 4347 4348 4349 4350 4351\n",
      " 4352 4353 4354 4355 4356 4357 4358 4359 4360 4361 4362 4363 4364 4365\n",
      " 4366 4367 4368 4369 4370 4371 4372 4373 4374 4375 4376 4377 4378 4379] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit=0.8448231508270307\n",
      "i=296 starts\n",
      "fit=0.4748019382226256\n",
      "i=297 starts\n",
      "fit=0.7457162323500551\n",
      "i=298 starts\n",
      "fit=0.8188015529599735\n",
      "i=299 starts\n",
      "fit=0.7068028737402647\n",
      "i=300 starts\n",
      "fit=0.7957116802957875\n",
      "i=301 starts\n",
      "fit=0.8124393649336343\n",
      "i=302 starts\n",
      "fit=0.8041567342153502\n",
      "i=303 starts\n",
      "fit=0.6267758402291652\n",
      "i=304 starts\n",
      "fit=0.7476109614303315\n",
      "i=305 starts\n",
      "fit=0.6692079972300752\n",
      "i=306 starts\n",
      "fit=0.6433101971125035\n",
      "i=307 starts\n",
      "fit=0.7180030512324629\n",
      "i=308 starts\n",
      "fit=0.6525747681395209\n",
      "i=309 starts\n",
      "fit=0.7295137657836528\n",
      "i=310 starts\n",
      "fit=0.7520575398762332\n",
      "i=311 starts\n",
      "fit=0.7825208899962208\n",
      "i=312 starts\n",
      "fit=0.8112705646235139\n",
      "i=313 starts\n",
      "fit=0.7188307979191118\n",
      "i=314 starts\n",
      "fit=0.36352053656048555\n",
      "i=315 starts\n",
      "fit=0.8083011254085957\n",
      "i=316 starts\n",
      "fit=0.7341476593622107\n",
      "i=317 starts\n",
      "fit=0.8564606797646207\n",
      "i=318 starts\n",
      "fit=0.8278901013100024\n",
      "i=319 starts\n",
      "fit=0.7316075326461497\n",
      "i=320 starts\n",
      "fit=0.8971712116047341\n",
      "i=321 starts\n",
      "fit=0.7412106733502757\n",
      "i=322 starts\n",
      "fit=0.7963041511591118\n",
      "i=323 starts\n",
      "fit=0.7668279569174223\n",
      "i=324 starts\n",
      "fit=0.7995982954428662\n",
      "i=325 starts\n",
      "fit=0.8484587344368166\n",
      "i=326 starts\n",
      "fit=0.68692720133184\n",
      "i=327 starts\n",
      "fit=0.7967016839680385\n",
      "i=328 starts\n",
      "fit=0.7401451876653113\n",
      "i=329 starts\n",
      "fit=0.7166588396144629\n",
      "i=330 starts\n",
      "fit=0.5967292038729534\n",
      "i=331 starts\n",
      "fit=0.7470713219929197\n",
      "i=332 starts\n",
      "fit=0.7267008440521827\n",
      "i=333 starts\n",
      "fit=0.6025189809580078\n",
      "i=334 starts\n",
      "fit=0.6755861190820756\n",
      "i=335 starts\n",
      "fit=0.7136798279917657\n",
      "i=336 starts\n",
      "fit=0.6231113075560494\n",
      "i=337 starts\n",
      "fit=0.7943415156311588\n",
      "i=338 starts\n",
      "fit=0.8534670014017857\n",
      "i=339 starts\n",
      "fit=0.5590500113791683\n",
      "i=340 starts\n",
      "fit=0.00020336988857749816\n",
      "i=341 starts\n",
      "fit=0.12362747233670912\n",
      "i=342 starts\n",
      "fit=0.17322207578796278\n",
      "i=343 starts\n",
      "fit=0.2530138066506874\n",
      "i=344 starts\n",
      "fit=0.26573991357903104\n",
      "i=345 starts\n",
      "fit=0.3017468895516743\n",
      "i=346 starts\n",
      "fit=0.141608732608838\n",
      "i=347 starts\n",
      "fit=0.47819213295607255\n",
      "i=348 starts\n",
      "fit=0.567918078391315\n",
      "i=349 starts\n",
      "fit=0.6670382956772789\n",
      "i=350 starts\n",
      "fit=0.3171991575869627\n",
      "i=351 starts\n",
      "fit=0.03045020380520458\n",
      "i=352 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [3926 3927 3928 3929 3930 3931 3932 3933 3934 3935 3936 3937 3938 3939\n",
      " 3940 3941 3942 3943 3944 3945 3946 3947 3948 3949 3950 3951 3952 3953\n",
      " 3954 3955 3956 3957 3958 3959 3960 3961 3962 3963 3964 3965 3966 3967\n",
      " 3968 3969 3970 3971 3972 3973 3974 3975 3976 3977 3978 3979 3980 3981\n",
      " 3982 3983 3984 3985 3986 3987 3988 3989 3990 3991 3992 3993 3994 3995\n",
      " 3996 3997 3998 3999 4000 4001 4002 4003 4004 4005 4006 4007 4008 4009\n",
      " 4010 4011 4012 4013 4014 4015 4016 4017 4018 4019 4020 4021 4022 4023\n",
      " 4024 4025 4026 4027 4028 4029 4030 4031 4032 4033 4034 4035 4036 4037\n",
      " 4038 4039 4040 4041 4042 4043 4044 4045 4046 4047 4048 4049 4050 4051\n",
      " 4052 4053 4054 4055 4056 4057 4058 4059 4060 4061 4062 4063 4064 4065\n",
      " 4066 4067 4068 4069 4070 4071 4072 4073 4074 4075 4076 4077 4078 4079\n",
      " 4080 4081 4082 4083 4084 4085 4086 4087 4088 4089 4090 4091 4092 4093\n",
      " 4094 4095 4096 4097 4098 4099 4100 4101 4102 4103 4104 4105 4106 4107\n",
      " 4108 4109 4110 4111 4112 4113 4114 4115 4116 4117 4118 4119 4120 4121\n",
      " 4122 4123 4124 4125 4126 4127 4128 4129 4130 4131 4132 4133 4134 4135\n",
      " 4136 4137 4138 4139 4140 4141 4142 4143 4144 4145 4146 4147 4148 4149\n",
      " 4150 4151 4152 4153 4154 4155 4156 4157 4158 4159 4160 4161 4162 4163\n",
      " 4164 4165 4166 4167 4168 4169 4170 4171 4172 4173 4174 4175 4176 4177\n",
      " 4178 4179 4180 4181 4182 4183 4184 4185 4186 4187 4188 4189 4190 4191\n",
      " 4192 4193 4194 4195 4196 4197 4198 4199 4200 4201 4202 4203 4204 4205\n",
      " 4206 4207 4208 4209 4210 4211 4212 4213 4214 4215 4216 4217 4218 4219\n",
      " 4220 4221 4222 4223 4224 4225 4226 4227 4228 4229 4230 4231 4232 4233\n",
      " 4234 4235 4236 4237 4238 4239 4240 4241 4242 4243 4244 4245 4246 4247\n",
      " 4248 4249 4250 4251 4252 4253 4254 4255 4256 4257 4258 4259 4260 4261\n",
      " 4262 4263 4264 4265 4266 4267 4268 4269 4270 4271 4272 4273 4274 4275\n",
      " 4276 4277 4278 4279 4280 4281 4282 4283 4284 4285 4286 4287 4288 4289\n",
      " 4290 4291 4292 4293 4294 4295 4296 4297 4298 4299 4300 4301 4302 4303\n",
      " 4304 4305 4306 4307 4308 4309 4310 4311 4312 4313 4314 4315 4316 4317\n",
      " 4318 4319 4320 4321 4322 4323 4324 4325 4326 4327 4328 4329 4330 4331\n",
      " 4332 4333 4334 4335 4336 4337 4338 4339 4340 4341 4342 4343 4344 4345\n",
      " 4346 4347 4348 4349 4350 4351 4352 4353 4354 4355 4356 4357 4358 4359\n",
      " 4360 4361 4362 4363 4364 4365 4366 4367 4368 4369 4370 4371 4372 4373\n",
      " 4374 4375 4376 4377 4378 4379] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit=0.24769508002093832\n",
      "i=353 starts\n",
      "fit=0.5044880605815392\n",
      "i=354 starts\n",
      "fit=0.43907219039076595\n",
      "i=355 starts\n",
      "fit=0.25405212405151834\n",
      "i=356 starts\n",
      "fit=0.34437190395043304\n",
      "i=357 starts\n",
      "fit=0.11774871453696589\n",
      "i=358 starts\n",
      "fit=0.365520294934244\n",
      "i=359 starts\n",
      "fit=0.3958044519579603\n",
      "i=360 starts\n",
      "fit=0.5618001598688566\n",
      "i=361 starts\n",
      "fit=0.42771237397552475\n",
      "i=362 starts\n",
      "fit=0.356050473683315\n",
      "i=363 starts\n",
      "fit=0.4987419993471406\n",
      "i=364 starts\n",
      "fit=0.609390387810058\n",
      "i=365 starts\n",
      "fit=-0.47658739256302085\n",
      "i=366 starts\n",
      "fit=-0.09624702188727818\n",
      "i=367 starts\n",
      "fit=0.05930953796940708\n",
      "i=368 starts\n",
      "fit=0.4084124968904844\n",
      "i=369 starts\n",
      "fit=0.8005674322371665\n",
      "i=370 starts\n",
      "fit=0.8074520667303193\n",
      "i=371 starts\n",
      "fit=0.73170470762681\n",
      "i=372 starts\n",
      "fit=0.8125999767991045\n",
      "i=373 starts\n",
      "fit=0.8429440292506806\n",
      "i=374 starts\n",
      "fit=-0.27237577149866876\n",
      "i=375 starts\n",
      "fit=0.8041664680732489\n",
      "i=376 starts\n",
      "fit=0.39697211395138043\n",
      "i=377 starts\n",
      "fit=0.7129583720931185\n",
      "i=378 starts\n",
      "fit=-1.4351501896955927\n",
      "i=379 starts\n",
      "fit=0.5104585697688677\n",
      "i=380 starts\n",
      "fit=0.5054252292785748\n",
      "i=381 starts\n",
      "fit=0.4485449985966583\n",
      "i=382 starts\n",
      "fit=0.16516509534179924\n",
      "i=383 starts\n",
      "fit=0.6720234008278856\n",
      "i=384 starts\n",
      "fit=0.6112043648080239\n",
      "i=385 starts\n",
      "fit=0.5688745210856292\n",
      "i=386 starts\n",
      "fit=0.7872698289863663\n",
      "i=387 starts\n",
      "fit=0.8361600100538876\n",
      "i=388 starts\n",
      "fit=0.49371398682972367\n",
      "i=389 starts\n",
      "fit=0.8661141332737023\n",
      "i=390 starts\n",
      "fit=0.8269044149327685\n",
      "i=391 starts\n",
      "fit=0.7838016479933068\n",
      "i=392 starts\n",
      "fit=0.781152484117207\n",
      "i=393 starts\n",
      "fit=0.8288864465210126\n",
      "i=394 starts\n",
      "fit=0.8379362154956493\n",
      "i=395 starts\n",
      "fit=0.5185818342242043\n",
      "i=396 starts\n",
      "fit=0.4592640242094065\n",
      "i=397 starts\n",
      "fit=0.8389080502779591\n",
      "i=398 starts\n",
      "fit=0.7001097035200022\n",
      "i=399 starts\n",
      "fit=0.8292490611115986\n",
      "i=400 starts\n",
      "fit=0.6299343738278502\n",
      "i=401 starts\n",
      "fit=0.5946625115900339\n",
      "i=402 starts\n",
      "fit=0.7013632744735108\n",
      "i=403 starts\n",
      "fit=0.3692956780583926\n",
      "i=404 starts\n",
      "fit=0.7714551338430248\n",
      "i=405 starts\n",
      "fit=0.6966613089709834\n",
      "i=406 starts\n",
      "fit=0.6685817129047565\n",
      "i=407 starts\n",
      "fit=-1.3473107426704263\n",
      "i=408 starts\n",
      "fit=0.8285184576810779\n",
      "i=409 starts\n",
      "fit=0.7061706560519286\n",
      "i=410 starts\n",
      "fit=0.7051998527739132\n",
      "i=411 starts\n",
      "fit=0.815600657684298\n",
      "i=412 starts\n",
      "fit=0.830666488797718\n",
      "i=413 starts\n",
      "fit=0.7853780253458091\n",
      "i=414 starts\n",
      "fit=0.7732860330935205\n",
      "i=415 starts\n",
      "fit=0.650756117248535\n",
      "i=416 starts\n",
      "fit=0.621947893385193\n",
      "i=417 starts\n",
      "fit=0.6964242355587218\n",
      "i=418 starts\n",
      "fit=0.6947322321691507\n",
      "i=419 starts\n",
      "fit=-2.537369973398642\n",
      "i=420 starts\n",
      "fit=0.701764510100596\n",
      "i=421 starts\n",
      "fit=0.6101047439240677\n",
      "i=422 starts\n",
      "fit=0.8141629709319604\n",
      "i=423 starts\n",
      "fit=0.6782143423771795\n",
      "i=424 starts\n",
      "fit=0.8175127432404627\n",
      "i=425 starts\n",
      "fit=0.7253686335721132\n",
      "i=426 starts\n",
      "fit=0.3540148060179996\n",
      "i=427 starts\n",
      "fit=-0.02082850381107626\n",
      "i=428 starts\n",
      "fit=0.16013446627145944\n",
      "i=429 starts\n",
      "fit=-0.11664571385293687\n",
      "i=430 starts\n",
      "fit=0.29772205266537377\n",
      "i=431 starts\n",
      "fit=0.5178463263271472\n",
      "i=432 starts\n",
      "fit=0.7983017721873168\n",
      "i=433 starts\n",
      "fit=0.53634294075653\n",
      "i=434 starts\n",
      "fit=0.8762209979142467\n",
      "i=435 starts\n",
      "fit=0.7232387757030763\n",
      "i=436 starts\n",
      "fit=0.6887712102307967\n",
      "i=437 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [3926 3927 3928 3929 3930 3931 3932 3933 3934 3935 3936 3937 3938 3941\n",
      " 3942 3943 3944 3945 3946 3947 3948 3949 3950 3951 3952 3953 3954 3955\n",
      " 3958 3959 3960 3961 3962 3963 3964 3965 3966 3967 3968 3969 3970 3971\n",
      " 3972 3973 3974 3975 3976 3977 3978 3979 3980 3981 3982 3983 3984 3985\n",
      " 3986 3987 3988 3989 3990 3991 3992 3993 3994 3996 3997 3998 3999 4000\n",
      " 4003 4004 4006 4007 4008 4009 4010 4011 4012 4013 4014 4015 4016 4017\n",
      " 4018 4019 4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030 4031\n",
      " 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041 4042 4043 4044 4045\n",
      " 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055 4056 4057 4058 4059\n",
      " 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069 4070 4071 4072 4073\n",
      " 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083 4084 4085 4086 4087\n",
      " 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097 4098 4099 4100 4101\n",
      " 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111 4112 4113 4114 4115\n",
      " 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125 4126 4127 4128 4129\n",
      " 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139 4140 4141 4142 4143\n",
      " 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153 4154 4155 4156 4157\n",
      " 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167 4168 4169 4170 4171\n",
      " 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181 4182 4183 4184 4185\n",
      " 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195 4196 4197 4198 4199\n",
      " 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209 4210 4211 4212 4213\n",
      " 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223 4224 4225 4226 4227\n",
      " 4228 4229 4230 4231 4232 4233 4234 4235 4236 4237 4238 4239 4240 4241\n",
      " 4242 4243 4244 4245 4246 4247 4248 4249 4250 4251 4252 4253 4254 4255\n",
      " 4256 4257 4258 4259 4260 4261 4262 4263 4264 4265 4266 4267 4268 4269\n",
      " 4270 4271 4272 4273 4274 4275 4276 4277 4278 4279 4280 4281 4282 4283\n",
      " 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293 4294 4295 4296 4297\n",
      " 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307 4308 4309 4310 4311\n",
      " 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321 4322 4323 4324 4325\n",
      " 4326 4327 4328 4329 4330 4331 4332 4333 4334 4335 4336 4337 4338 4339\n",
      " 4340 4341 4342 4343 4344 4345 4346 4347 4348 4349 4350 4351 4352 4353\n",
      " 4354 4355 4356 4357 4358 4359 4360 4361 4362 4363 4364 4365 4366 4367\n",
      " 4368 4369 4370 4371 4372 4373 4374 4375 4376 4377 4378 4379] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n",
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [3926 3927 3928 3929 3930 3931 3932 3933 3934 3935 3936 3937 3938 3939\n",
      " 3940 3941 3942 3943 3944 3945 3946 3947 3948 3949 3950 3951 3952 3953\n",
      " 3954 3955 3956 3957 3958 3959 3960 3961 3962 3963 3964 3965 3966 3967\n",
      " 3968 3969 3970 3971 3972 3973 3974 3975 3976 3977 3978 3979 3980 3981\n",
      " 3982 3983 3984 3985 3986 3987 3988 3989 3990 3991 3992 3993 3994 3995\n",
      " 3996 3997 3998 4000 4001 4002 4003 4004 4005 4006 4007 4008 4009 4010\n",
      " 4011 4012 4013 4014 4015 4016 4018 4019 4020 4021 4022 4023 4024 4025\n",
      " 4026 4027 4028 4029 4030 4031 4032 4033 4034 4035 4036 4037 4038 4039\n",
      " 4040 4041 4042 4043 4044 4045 4046 4047 4048 4049 4050 4051 4052 4053\n",
      " 4054 4055 4056 4057 4058 4059 4060 4061 4062 4063 4064 4065 4066 4067\n",
      " 4068 4069 4070 4071 4072 4073 4074 4075 4076 4077 4078 4079 4080 4081\n",
      " 4082 4083 4084 4085 4086 4087 4088 4089 4090 4091 4092 4093 4094 4095\n",
      " 4096 4097 4098 4099 4100 4101 4102 4103 4104 4105 4106 4107 4108 4109\n",
      " 4110 4111 4112 4113 4114 4115 4116 4117 4118 4119 4120 4121 4122 4123\n",
      " 4124 4125 4126 4127 4128 4129 4130 4131 4132 4133 4134 4135 4136 4137\n",
      " 4138 4139 4140 4141 4142 4143 4144 4145 4146 4147 4148 4149 4150 4151\n",
      " 4152 4153 4154 4155 4156 4157 4158 4159 4160 4161 4162 4163 4164 4165\n",
      " 4166 4167 4168 4169 4170 4171 4172 4173 4174 4175 4176 4177 4178 4179\n",
      " 4180 4181 4182 4183 4184 4185 4186 4187 4188 4189 4190 4191 4192 4193\n",
      " 4194 4195 4196 4197 4198 4199 4200 4201 4202 4203 4204 4205 4206 4207\n",
      " 4208 4209 4210 4211 4212 4213 4214 4215 4216 4217 4218 4219 4220 4221\n",
      " 4222 4223 4224 4225 4226 4227 4228 4229 4230 4231 4232 4233 4234 4235\n",
      " 4236 4237 4238 4239 4240 4241 4242 4243 4244 4245 4246 4247 4248 4249\n",
      " 4250 4251 4252 4253 4254 4255 4256 4257 4258 4259 4260 4261 4262 4263\n",
      " 4264 4265 4266 4267 4268 4269 4270 4271 4272 4273 4274 4275 4276 4277\n",
      " 4278 4279 4280 4281 4282 4283 4284 4285 4286 4287 4288 4289 4290 4291\n",
      " 4292 4293 4294 4295 4296 4297 4298 4299 4300 4301 4302 4303 4304 4305\n",
      " 4306 4307 4308 4309 4310 4311 4312 4313 4314 4315 4316 4317 4318 4319\n",
      " 4320 4321 4322 4323 4324 4325 4326 4327 4328 4329 4330 4331 4332 4333\n",
      " 4334 4335 4336 4337 4338 4339 4340 4341 4342 4343 4344 4345 4346 4347\n",
      " 4348 4349 4350 4351 4352 4353 4354 4355 4356 4357 4358 4359 4360 4361\n",
      " 4362 4363 4364 4365 4366 4367 4368 4369 4370 4371 4372 4373 4374 4375\n",
      " 4376 4377 4378 4379] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit=0.672870526842416\n",
      "i=438 starts\n",
      "fit=0.4665561162595303\n",
      "i=439 starts\n",
      "fit=0.8588941722466727\n",
      "i=440 starts\n",
      "fit=0.4559803263174955\n",
      "i=441 starts\n",
      "fit=0.7061904260609799\n",
      "i=442 starts\n",
      "fit=0.8596463713570124\n",
      "i=443 starts\n",
      "fit=0.7647956873806674\n",
      "i=444 starts\n",
      "fit=0.6612621558857271\n",
      "i=445 starts\n",
      "fit=-0.24457370007567425\n",
      "i=446 starts\n",
      "fit=0.6425312829618761\n",
      "i=447 starts\n",
      "fit=0.6094263094968491\n",
      "i=448 starts\n",
      "fit=0.5591834916083345\n",
      "i=449 starts\n",
      "fit=0.6634027570217218\n",
      "i=450 starts\n",
      "fit=0.38122383810586213\n",
      "i=451 starts\n",
      "fit=-0.06041808084796374\n",
      "i=452 starts\n",
      "fit=0.3378034356161237\n",
      "i=453 starts\n",
      "fit=0.7522014326636642\n",
      "i=454 starts\n",
      "fit=0.5545060746743431\n",
      "i=455 starts\n",
      "fit=0.4486069249075072\n",
      "i=456 starts\n",
      "fit=0.499966248792843\n",
      "i=457 starts\n",
      "fit=0.5369132970962321\n",
      "i=458 starts\n",
      "fit=0.6791077814854183\n",
      "i=459 starts\n",
      "fit=0.5626545065469384\n",
      "i=460 starts\n",
      "fit=0.4361272193045641\n",
      "i=461 starts\n",
      "fit=0.51413757140092\n",
      "i=462 starts\n",
      "fit=0.6396110953874361\n",
      "i=463 starts\n",
      "fit=0.7398562494014593\n",
      "i=464 starts\n",
      "fit=0.5151315843691084\n",
      "i=465 starts\n",
      "fit=0.12509939328820363\n",
      "i=466 starts\n",
      "fit=0.627623280360531\n",
      "i=467 starts\n",
      "fit=0.3441842086659229\n",
      "i=468 starts\n",
      "fit=0.634942840363862\n",
      "i=469 starts\n",
      "fit=0.22249997497080576\n",
      "i=470 starts\n",
      "fit=0.2915158369534385\n",
      "i=471 starts\n",
      "fit=0.5926404582263906\n",
      "i=472 starts\n",
      "fit=-3.1857570805954802\n",
      "i=473 starts\n",
      "fit=0.06537730529569175\n",
      "i=474 starts\n",
      "fit=0.6213233931674216\n",
      "i=475 starts\n",
      "fit=0.4846529962677688\n",
      "i=476 starts\n",
      "fit=0.05795953931755726\n",
      "i=477 starts\n",
      "fit=0.3805158933016144\n",
      "i=478 starts\n",
      "fit=-0.6807427084333284\n",
      "i=479 starts\n",
      "fit=0.7168173756327737\n",
      "i=480 starts\n",
      "fit=0.5956070377893125\n",
      "i=481 starts\n",
      "fit=0.7100094033680038\n",
      "i=482 starts\n",
      "fit=0.2714848592101775\n",
      "i=483 starts\n",
      "fit=0.6157904574661499\n",
      "i=484 starts\n",
      "fit=0.6532722545593954\n",
      "i=485 starts\n",
      "fit=0.6117047246223404\n",
      "i=486 starts\n",
      "fit=0.9005364248151717\n",
      "i=487 starts\n",
      "fit=0.8732686573503556\n",
      "i=488 starts\n",
      "fit=0.7710959732458801\n",
      "i=489 starts\n",
      "fit=0.860976507955507\n",
      "i=490 starts\n",
      "fit=0.8122603003041562\n",
      "i=491 starts\n",
      "fit=0.719360090773248\n",
      "i=492 starts\n",
      "fit=0.6888154689027398\n",
      "i=493 starts\n",
      "fit=0.6759068490866319\n",
      "i=494 starts\n",
      "fit=0.8826560942702847\n",
      "i=495 starts\n",
      "fit=0.7547943538299146\n",
      "i=496 starts\n",
      "fit=0.6063089515302763\n",
      "i=497 starts\n",
      "fit=0.7030857064664948\n",
      "i=498 starts\n",
      "fit=-1.9511968962647348\n",
      "i=499 starts\n",
      "fit=0.9018890851602007\n",
      "i=500 starts\n",
      "fit=0.7263625838317007\n",
      "i=501 starts\n",
      "fit=0.6427674015895983\n",
      "i=502 starts\n",
      "fit=0.2591974076764215\n",
      "i=503 starts\n",
      "fit=-0.23683440091445984\n",
      "i=504 starts\n",
      "fit=0.3250635158727012\n",
      "i=505 starts\n",
      "fit=0.30002545537081293\n",
      "i=506 starts\n",
      "fit=0.2419085296371829\n",
      "i=507 starts\n",
      "fit=-0.7170421672650871\n",
      "i=508 starts\n",
      "fit=0.05365672829963897\n",
      "i=509 starts\n",
      "fit=-0.036806503400880874\n",
      "i=510 starts\n",
      "fit=-1.143458301503483\n",
      "i=511 starts\n",
      "fit=0.609101243616722\n",
      "i=512 starts\n",
      "fit=0.5548411687290072\n",
      "i=513 starts\n",
      "fit=0.731787868091444\n",
      "i=514 starts\n",
      "fit=0.5184569472474578\n",
      "i=515 starts\n",
      "fit=0.516601388720795\n",
      "i=516 starts\n",
      "fit=0.5703491059983672\n",
      "i=517 starts\n",
      "fit=0.390566434909705\n",
      "i=518 starts\n",
      "fit=0.5918162379484726\n",
      "i=519 starts\n",
      "fit=0.764957100687542\n",
      "i=520 starts\n",
      "fit=0.6854100886741663\n",
      "i=521 starts\n",
      "fit=0.2241058109863644\n",
      "i=522 starts\n",
      "fit=0.46519470501341564\n",
      "i=523 starts\n",
      "fit=0.5142331553567447\n",
      "i=524 starts\n",
      "fit=0.30913831055651564\n",
      "i=525 starts\n",
      "fit=0.6831021901648244\n",
      "i=526 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [3199 4018 4019 4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030\n",
      " 4031 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041 4042 4043 4044\n",
      " 4045 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055 4056 4057 4058\n",
      " 4059 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069 4070 4071 4072\n",
      " 4073 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083 4084 4085 4086\n",
      " 4087 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097 4098 4099 4100\n",
      " 4101 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111 4112 4113 4114\n",
      " 4115 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125 4126 4127 4128\n",
      " 4129 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139 4140 4141 4142\n",
      " 4143 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153 4154 4155 4156\n",
      " 4157 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167 4168 4169 4170\n",
      " 4171 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181 4182 4183 4184\n",
      " 4185 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195 4196 4197 4198\n",
      " 4199 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209 4210 4211 4212\n",
      " 4213 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223 4224 4225 4226\n",
      " 4227 4228 4229 4230 4231 4232 4233 4234 4235 4236 4237 4238 4239 4240\n",
      " 4241 4242 4243 4244 4245 4246 4247 4248 4249 4250 4251 4252 4253 4254\n",
      " 4255 4256 4257 4258 4259 4260 4261 4262 4263 4264 4265 4266 4267 4268\n",
      " 4269 4270 4271 4272 4273 4274 4275 4276 4277 4278 4279 4280 4281 4282\n",
      " 4283 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293 4294 4295 4296\n",
      " 4297 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307 4308 4309 4310\n",
      " 4311 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321 4322 4323 4324\n",
      " 4325 4326 4327 4328 4329 4330 4331 4332 4333 4334 4335 4336 4337 4338\n",
      " 4339 4340 4341 4342 4343 4344 4345 4346 4347 4348 4349 4350 4351 4352\n",
      " 4353 4354 4355 4356 4357 4358 4359 4360 4361 4362 4363 4364 4365 4366\n",
      " 4367 4368 4369 4370 4371 4372 4373 4374 4375 4376 4377 4378 4379] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit=0.5321933934787352\n",
      "i=527 starts\n",
      "fit=0.7638713173926874\n",
      "i=528 starts\n",
      "fit=0.5899876614189474\n",
      "i=529 starts\n",
      "fit=0.5226212055417294\n",
      "i=530 starts\n",
      "fit=0.4784597961142778\n",
      "i=531 starts\n",
      "fit=0.19759810605623673\n",
      "i=532 starts\n",
      "fit=0.5892903870287717\n",
      "i=533 starts\n",
      "fit=-1.622528982756969\n",
      "i=534 starts\n",
      "fit=0.4949889841970818\n",
      "i=535 starts\n",
      "fit=0.07512264851615424\n",
      "i=536 starts\n",
      "fit=0.2898034866046407\n",
      "i=537 starts\n",
      "fit=0.5667888964831787\n",
      "i=538 starts\n",
      "fit=0.7671732757331154\n",
      "i=539 starts\n",
      "fit=0.7138832755950646\n",
      "i=540 starts\n",
      "fit=0.7062362292541183\n",
      "i=541 starts\n",
      "fit=0.7594406087940604\n",
      "i=542 starts\n",
      "fit=0.5889943081451346\n",
      "i=543 starts\n",
      "fit=0.8538196812014269\n",
      "i=544 starts\n",
      "fit=0.7572508267023105\n",
      "i=545 starts\n",
      "fit=0.8057269050145308\n",
      "i=546 starts\n",
      "fit=0.7307040418666022\n",
      "i=547 starts\n",
      "fit=0.5186253950691562\n",
      "i=548 starts\n",
      "fit=0.360452240829492\n",
      "i=549 starts\n",
      "fit=0.8124349175499284\n",
      "i=550 starts\n",
      "fit=0.7267128311305917\n",
      "i=551 starts\n",
      "fit=0.2366419277152818\n",
      "i=552 starts\n",
      "fit=0.7957416748221583\n",
      "i=553 starts\n",
      "fit=0.38482900551560606\n",
      "i=554 starts\n",
      "fit=0.7591135792256816\n",
      "i=555 starts\n",
      "fit=0.5479251363878188\n",
      "i=556 starts\n",
      "fit=-2.0559706882377085\n",
      "i=557 starts\n",
      "fit=0.8726842555101365\n",
      "i=558 starts\n",
      "fit=0.8017952028236487\n",
      "i=559 starts\n",
      "fit=-0.5032037582283917\n",
      "i=560 starts\n",
      "fit=0.7941756452705947\n",
      "i=561 starts\n",
      "fit=0.7167984772660216\n",
      "i=562 starts\n",
      "fit=-0.07191470501841013\n",
      "i=563 starts\n",
      "fit=-1.0584649989105346\n",
      "i=564 starts\n",
      "fit=0.605080086906423\n",
      "i=565 starts\n",
      "fit=0.5260083191820198\n",
      "i=566 starts\n",
      "fit=0.818447225216086\n",
      "i=567 starts\n",
      "fit=0.8799100357645326\n",
      "i=568 starts\n",
      "fit=0.7223842039498929\n",
      "i=569 starts\n",
      "fit=0.8792936633273807\n",
      "i=570 starts\n",
      "fit=0.7789102179620966\n",
      "i=571 starts\n",
      "fit=0.705948272859316\n",
      "i=572 starts\n",
      "fit=0.7574264125418101\n",
      "i=573 starts\n",
      "fit=0.5446694219863186\n",
      "i=574 starts\n",
      "fit=0.8509970073629194\n",
      "i=575 starts\n",
      "fit=0.6116245589888839\n",
      "i=576 starts\n",
      "fit=0.5456352700414189\n",
      "i=577 starts\n",
      "fit=0.6708360220924547\n",
      "i=578 starts\n",
      "fit=0.8143756722391474\n",
      "i=579 starts\n",
      "fit=0.8199311275252709\n",
      "i=580 starts\n",
      "fit=0.8055342719162639\n",
      "i=581 starts\n",
      "fit=0.8617371902869227\n",
      "i=582 starts\n",
      "fit=0.801159288323052\n",
      "i=583 starts\n",
      "fit=0.5590430914710229\n",
      "i=584 starts\n",
      "fit=0.8279727400071337\n",
      "i=585 starts\n",
      "fit=0.5302830802878846\n",
      "i=586 starts\n",
      "fit=0.8659219268228101\n",
      "i=587 starts\n",
      "fit=0.7155550460402249\n",
      "i=588 starts\n",
      "fit=0.5672206790698322\n",
      "i=589 starts\n",
      "fit=0.6009603765607519\n",
      "i=590 starts\n",
      "fit=0.6190012042164418\n",
      "i=591 starts\n",
      "fit=0.6296485986620588\n",
      "i=592 starts\n",
      "fit=0.572074347120552\n",
      "i=593 starts\n",
      "fit=0.8028460338085306\n",
      "i=594 starts\n",
      "fit=0.7348932779691391\n",
      "i=595 starts\n",
      "fit=0.6050260976448983\n",
      "i=596 starts\n",
      "fit=0.7194002968636575\n",
      "i=597 starts\n",
      "fit=0.8353104959572182\n",
      "i=598 starts\n",
      "fit=0.8122305442464857\n",
      "i=599 starts\n",
      "fit=0.765623441199007\n",
      "i=600 starts\n",
      "fit=0.8515372963161713\n",
      "i=601 starts\n",
      "fit=0.7597855501782801\n",
      "i=602 starts\n",
      "fit=0.783335901703723\n",
      "i=603 starts\n",
      "fit=0.7954259822154183\n",
      "i=604 starts\n",
      "fit=0.8976028426074509\n",
      "i=605 starts\n",
      "fit=0.8303994698198204\n",
      "i=606 starts\n",
      "fit=0.5720211944495088\n",
      "i=607 starts\n",
      "fit=0.8891840611823003\n",
      "i=608 starts\n",
      "fit=0.818336541983656\n",
      "i=609 starts\n",
      "fit=0.837409855610144\n",
      "i=610 starts\n",
      "fit=0.7420681356443247\n",
      "i=611 starts\n",
      "fit=0.8470752233258472\n",
      "i=612 starts\n",
      "fit=0.8473560586346063\n",
      "i=613 starts\n",
      "fit=0.43457696200289964\n",
      "i=614 starts\n",
      "fit=0.764854915008309\n",
      "i=615 starts\n",
      "fit=0.8078905029660057\n",
      "i=616 starts\n",
      "fit=0.4490142240403987\n",
      "i=617 starts\n",
      "fit=0.44503672949760575\n",
      "i=618 starts\n",
      "fit=0.5385357916915415\n",
      "i=619 starts\n",
      "fit=0.6385094111383987\n",
      "i=620 starts\n",
      "fit=0.6619994468451307\n",
      "i=621 starts\n",
      "fit=0.8451593877994896\n",
      "i=622 starts\n",
      "fit=0.6041487527021253\n",
      "i=623 starts\n",
      "fit=0.7624508264459778\n",
      "i=624 starts\n",
      "fit=0.7545523080866621\n",
      "i=625 starts\n",
      "fit=0.687524555463592\n",
      "i=626 starts\n",
      "fit=0.7101710650654671\n",
      "i=627 starts\n",
      "fit=0.7282297713091924\n",
      "i=628 starts\n",
      "fit=0.767669591929578\n",
      "i=629 starts\n",
      "fit=0.6686260971847721\n",
      "i=630 starts\n",
      "fit=0.7910351068538161\n",
      "i=631 starts\n",
      "fit=0.7311334930515174\n",
      "i=632 starts\n",
      "fit=0.6615912691190613\n",
      "i=633 starts\n",
      "fit=0.6436231401814981\n",
      "i=634 starts\n",
      "fit=0.6364735938466504\n",
      "i=635 starts\n",
      "fit=0.8312456863317748\n",
      "i=636 starts\n",
      "fit=0.8185381151647967\n",
      "i=637 starts\n",
      "fit=0.8337273889302932\n",
      "i=638 starts\n",
      "fit=0.7835378479559738\n",
      "i=639 starts\n",
      "fit=0.7976134060240679\n",
      "i=640 starts\n",
      "fit=0.7546974305591823\n",
      "i=641 starts\n",
      "fit=0.798853403680402\n",
      "i=642 starts\n",
      "fit=0.791389378190998\n",
      "i=643 starts\n",
      "fit=0.8622324973152107\n",
      "i=644 starts\n",
      "fit=0.8796085809561558\n",
      "i=645 starts\n",
      "fit=0.8847265380962714\n",
      "i=646 starts\n",
      "fit=0.8191486002183845\n",
      "i=647 starts\n",
      "fit=0.8984846315421643\n",
      "i=648 starts\n",
      "fit=0.920721346072218\n",
      "i=649 starts\n",
      "fit=0.9207064169122401\n",
      "i=650 starts\n",
      "fit=0.8803748192491286\n",
      "i=651 starts\n",
      "fit=0.8729851835194409\n",
      "i=652 starts\n",
      "fit=0.8728326523050969\n",
      "i=653 starts\n",
      "fit=0.8498485689142036\n",
      "i=654 starts\n",
      "fit=0.9458913889395787\n",
      "i=655 starts\n",
      "fit=0.8684504394852439\n",
      "i=656 starts\n",
      "fit=0.9460565863644281\n",
      "i=657 starts\n",
      "fit=0.8584355112671554\n",
      "i=658 starts\n",
      "fit=0.9398125699406141\n",
      "i=659 starts\n",
      "fit=0.849163397410033\n",
      "i=660 starts\n",
      "fit=0.847815470444056\n",
      "i=661 starts\n",
      "fit=0.8522288840785271\n",
      "i=662 starts\n",
      "fit=0.8977920408125198\n",
      "i=663 starts\n",
      "fit=0.8154904860455816\n",
      "i=664 starts\n",
      "fit=0.9147287326688976\n",
      "i=665 starts\n",
      "fit=0.8337679119548241\n",
      "i=666 starts\n",
      "fit=0.7367898636500354\n",
      "i=667 starts\n",
      "fit=0.8911525689353147\n",
      "i=668 starts\n",
      "fit=0.6448826982622897\n",
      "i=669 starts\n",
      "fit=0.7809618156623483\n",
      "i=670 starts\n",
      "fit=0.765371711179477\n"
     ]
    }
   ],
   "source": [
    "calibrated_KGES = np.ones(N_CATCHMENTS)\n",
    "\n",
    "for i in range(N_CATCHMENTS):\n",
    "    print(f'i={i} starts')\n",
    "    calibrated_KGES[i]  = eval_catchment(i)\n",
    "    print(f'fit={calibrated_KGES[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(calibrated_KGES[calibrated_KGES>0], bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6333906564031828"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibrated_KGES.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7323229588861392"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(calibrated_KGES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
