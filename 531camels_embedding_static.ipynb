{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 3\n",
    "\n",
    "N_CATCHMENTS = 531\n",
    "\n",
    "# training hyperparameters\n",
    "EPOCHS = 500\n",
    "TRAIN_YEAR = 6\n",
    "PATIENCE = 20\n",
    "\n",
    "use_amp = True\n",
    "compile_model = False\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = False\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_val = dataloader.Forcing_Data(\n",
    "    \"data/531_camels_train_val.csv\",\n",
    "    record_length=3653,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dtrain = dataloader.Forcing_Data(\n",
    "    \"data/531_camels_train.csv\",\n",
    "    record_length=2557,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dval = dataloader.Forcing_Data(\n",
    "    \"data/531_camels_val.csv\",\n",
    "    record_length=1461,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dtest = dataloader.Forcing_Data(\n",
    "    \"data/531_camels_test.csv\",\n",
    "    record_length=4017,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self, model_builder):\n",
    "        self.model_builder = model_builder\n",
    "\n",
    "    def objective(self, trial):\n",
    "\n",
    "        # prepare early stopper\n",
    "        early_stopper = training_fun.EarlyStopper(patience=PATIENCE, min_delta=0)\n",
    "\n",
    "        # define model\n",
    "        embedding, decoder = self.model_builder.define_model(trial)\n",
    "        embedding, decoder = embedding.to(computing_device), decoder.to(\n",
    "            computing_device\n",
    "        )\n",
    "\n",
    "        if compile_model:\n",
    "            # pytorch2.0 new feature, complile model for fast training\n",
    "            embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "        # define optimizers\n",
    "        lr_embedding = trial.suggest_float(\"lr_embedding\", 5e-5, 1e-2, log=True)\n",
    "        embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "\n",
    "        lr_decoder = trial.suggest_float(\"lr_decoder\", 5e-5, 1e-2, log=True)\n",
    "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "        # define batch size\n",
    "        batch_size_power = trial.suggest_int(\"batch_size_power\", 4, 8)\n",
    "        batch_size = 2**batch_size_power\n",
    "\n",
    "        # steps per epoch\n",
    "        steps = round(N_CATCHMENTS * TRAIN_YEAR / batch_size)\n",
    "\n",
    "        # train model\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "            # repeat TRAIN_YEAR times to finish an epoch\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            for step in range(steps):\n",
    "\n",
    "                decoder_optimizer.zero_grad()\n",
    "                embedding_optimizer.zero_grad()\n",
    "\n",
    "                # put the models into training mode\n",
    "                decoder.train()\n",
    "                embedding.train()\n",
    "\n",
    "                # get training batch and pass to device\n",
    "                invalid_batch = True\n",
    "                while invalid_batch:\n",
    "                    (x_batch, y_batch, selected_catchments) = dtrain.get_random_batch(\n",
    "                        batch_size\n",
    "                    )\n",
    "                    \n",
    "                    if len(x_batch) > 0:\n",
    "                        invalid_batch = False     \n",
    "\n",
    "                x_batch, y_batch, selected_catchments = (\n",
    "                    x_batch.to(computing_device),\n",
    "                    y_batch.to(computing_device),\n",
    "                    selected_catchments.to(computing_device),\n",
    "                )\n",
    "\n",
    "                # slice batch for training\n",
    "                with torch.autocast(\n",
    "                    device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "                ):\n",
    "                    code = embedding(selected_catchments)\n",
    "\n",
    "                    # pass through decoder\n",
    "                    out = decoder.decode(code, x_batch)\n",
    "\n",
    "                    # compute loss\n",
    "                    loss = training_fun.mse_loss_with_nans(out, y_batch)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(embedding_optimizer)\n",
    "                scaler.step(decoder_optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            # validate model after each epochs\n",
    "            decoder.eval()\n",
    "            embedding.eval()\n",
    "\n",
    "            # Handle pruning based on the intermediate value\n",
    "            if memory_saving:\n",
    "                val_loss = training_fun.val_model_mem_saving(\n",
    "                    embedding=embedding,\n",
    "                    decoder=decoder,\n",
    "                    dataset=dval,\n",
    "                    storge_device=storge_device,\n",
    "                    computing_device=computing_device,\n",
    "                    use_amp=use_amp,\n",
    "                    val_metric=training_fun.mse_loss_with_nans,\n",
    "                    return_summary=True,\n",
    "                    val_steps=VAL_STEPS,\n",
    "                )\n",
    "            else:\n",
    "                val_loss = (\n",
    "                    training_fun.val_model(\n",
    "                        embedding=embedding,\n",
    "                        decoder=decoder,\n",
    "                        dataset=dval,\n",
    "                        storge_device=storge_device,\n",
    "                        computing_device=computing_device,\n",
    "                        use_amp=use_amp,\n",
    "                        val_metric=training_fun.mse_loss_with_nans,\n",
    "                        return_summary=True,\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                torch.cuda.empty_cache()\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            # Early stop using early_stopper, break for loop\n",
    "            if early_stopper.early_stop(val_loss):\n",
    "                break\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return early_stopper.min_validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_builder = training_fun.LSTM_model_builder(\n",
    "    n_catchments=N_CATCHMENTS, base_length=BASE_LENGTH, forcing_dim=FORCING_DIM\n",
    ")\n",
    "\n",
    "LSTM_objective = Objective(LSTM_model_builder).objective\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-17 15:50:03,469]\u001b[0m A new study created in memory with name: base_model\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 15:52:14,257]\u001b[0m Trial 0 finished with value: 3.3614189624786377 and parameters: {'lstm_hidden_dim': 243, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3138585671567882, 'fc_dim0': 10, 'lr_embedding': 0.00015683595727183995, 'lr_decoder': 0.0012437709938244298, 'batch_size_power': 8}. Best is trial 0 with value: 3.3614189624786377.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:15:23,800]\u001b[0m Trial 1 finished with value: 3.452937126159668 and parameters: {'lstm_hidden_dim': 139, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.20397849119382716, 'fc_dim0': 7, 'lr_embedding': 7.19438735002872e-05, 'lr_decoder': 0.0003907761870794437, 'batch_size_power': 8}. Best is trial 0 with value: 3.3614189624786377.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:17:06,320]\u001b[0m Trial 2 finished with value: 4.470760822296143 and parameters: {'lstm_hidden_dim': 67, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 3, 'fc_dim1': 2, 'lr_embedding': 7.749206849488066e-05, 'lr_decoder': 0.0003243810567196748, 'batch_size_power': 8}. Best is trial 0 with value: 3.3614189624786377.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:17:30,334]\u001b[0m Trial 3 finished with value: 4.123073577880859 and parameters: {'lstm_hidden_dim': 18, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.43554851639572634, 'fc_dim0': 12, 'fc_dim1': 6, 'lr_embedding': 0.0022415372430901136, 'lr_decoder': 0.007501152146261475, 'batch_size_power': 7}. Best is trial 0 with value: 3.3614189624786377.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:19:19,940]\u001b[0m Trial 4 finished with value: 15.451793670654297 and parameters: {'lstm_hidden_dim': 239, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 2, 'fc_dim1': 11, 'lr_embedding': 0.00013598852877052614, 'lr_decoder': 0.007492657664623808, 'batch_size_power': 5}. Best is trial 0 with value: 3.3614189624786377.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:21:44,242]\u001b[0m Trial 5 finished with value: 5.1819257736206055 and parameters: {'lstm_hidden_dim': 12, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.3406531894571781, 'fc_dim0': 13, 'fc_dim1': 2, 'lr_embedding': 0.0009641147871702625, 'lr_decoder': 0.00011733372583147503, 'batch_size_power': 6}. Best is trial 0 with value: 3.3614189624786377.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:22:54,858]\u001b[0m Trial 6 finished with value: 3.3148105144500732 and parameters: {'lstm_hidden_dim': 43, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 12, 'fc_dim1': 15, 'fc_dim2': 14, 'lr_embedding': 0.0012532646529371735, 'lr_decoder': 0.0009966849176749376, 'batch_size_power': 6}. Best is trial 6 with value: 3.3148105144500732.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:40:00,742]\u001b[0m Trial 7 finished with value: 3.807591199874878 and parameters: {'lstm_hidden_dim': 184, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 4, 'fc_dim1': 7, 'lr_embedding': 0.0006114690165054813, 'lr_decoder': 0.002892751255041947, 'batch_size_power': 5}. Best is trial 6 with value: 3.3148105144500732.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:42:05,517]\u001b[0m Trial 8 finished with value: 15.458287239074707 and parameters: {'lstm_hidden_dim': 196, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 12, 'fc_dim1': 9, 'fc_dim2': 5, 'lr_embedding': 0.00013494306057415246, 'lr_decoder': 0.002456806155413575, 'batch_size_power': 8}. Best is trial 6 with value: 3.3148105144500732.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:47:26,879]\u001b[0m Trial 9 finished with value: 3.3942935466766357 and parameters: {'lstm_hidden_dim': 52, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 15, 'lr_embedding': 0.0002510730899548645, 'lr_decoder': 8.589597555484169e-05, 'batch_size_power': 5}. Best is trial 6 with value: 3.3148105144500732.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:50:35,162]\u001b[0m Trial 10 finished with value: 3.085055351257324 and parameters: {'lstm_hidden_dim': 106, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 16, 'fc_dim2': 16, 'lr_embedding': 0.0029152913408923543, 'lr_decoder': 0.0007565238803208725, 'batch_size_power': 4}. Best is trial 10 with value: 3.085055351257324.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:54:43,548]\u001b[0m Trial 11 finished with value: 2.864987850189209 and parameters: {'lstm_hidden_dim': 99, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 16, 'fc_dim2': 16, 'lr_embedding': 0.007956113478260644, 'lr_decoder': 0.0007891644637676279, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 16:57:38,024]\u001b[0m Trial 12 finished with value: 3.057891845703125 and parameters: {'lstm_hidden_dim': 103, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 16, 'fc_dim2': 16, 'lr_embedding': 0.009132643721514087, 'lr_decoder': 0.0003317247369685285, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 17:01:00,022]\u001b[0m Trial 13 finished with value: 2.963780164718628 and parameters: {'lstm_hidden_dim': 105, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 13, 'fc_dim2': 12, 'lr_embedding': 0.009650639703991172, 'lr_decoder': 0.00022653264375637708, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 17:12:44,036]\u001b[0m Trial 14 finished with value: 2.984710216522217 and parameters: {'lstm_hidden_dim': 147, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 13, 'fc_dim2': 10, 'lr_embedding': 0.007754793674910359, 'lr_decoder': 0.0001659221884676443, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 17:15:44,041]\u001b[0m Trial 15 finished with value: 3.0395114421844482 and parameters: {'lstm_hidden_dim': 91, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 8, 'fc_dim1': 13, 'fc_dim2': 10, 'lr_embedding': 0.004326252267008924, 'lr_decoder': 0.00020633593308045408, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 17:46:22,898]\u001b[0m Trial 16 finished with value: 3.0998775959014893 and parameters: {'lstm_hidden_dim': 169, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 10, 'fc_dim1': 13, 'fc_dim2': 12, 'lr_embedding': 0.005103509013313917, 'lr_decoder': 6.322182539852025e-05, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 17:49:32,923]\u001b[0m Trial 17 finished with value: 3.044609546661377 and parameters: {'lstm_hidden_dim': 83, 'n_lstm_layers': 1, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 6, 'fc_dim1': 11, 'fc_dim2': 5, 'lr_embedding': 0.00184824180859116, 'lr_decoder': 0.0005304658739098844, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 17:52:49,471]\u001b[0m Trial 18 finished with value: 3.8228580951690674 and parameters: {'lstm_hidden_dim': 122, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.4907606412171518, 'fc_dim0': 14, 'fc_dim1': 14, 'lr_embedding': 0.0004311842629555861, 'lr_decoder': 0.0018216297928917219, 'batch_size_power': 7}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:00:20,289]\u001b[0m Trial 19 finished with value: 3.0567445755004883 and parameters: {'lstm_hidden_dim': 153, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 3, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 11, 'fc_dim2': 13, 'lr_embedding': 0.005335591921480624, 'lr_decoder': 0.00023240880865709132, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:02:06,676]\u001b[0m Trial 20 finished with value: 3.146040678024292 and parameters: {'lstm_hidden_dim': 216, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 10, 'fc_dim1': 9, 'lr_embedding': 0.0033211392891091987, 'lr_decoder': 0.004029131734288851, 'batch_size_power': 6}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:12:52,044]\u001b[0m Trial 21 finished with value: 2.894192695617676 and parameters: {'lstm_hidden_dim': 130, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 13, 'fc_dim2': 9, 'lr_embedding': 0.009794373523334957, 'lr_decoder': 0.0001476416448991005, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:17:14,218]\u001b[0m Trial 22 finished with value: 2.9558165073394775 and parameters: {'lstm_hidden_dim': 120, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 14, 'fc_dim2': 8, 'lr_embedding': 0.008805900126054266, 'lr_decoder': 0.00012652244534025215, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:23:21,310]\u001b[0m Trial 23 finished with value: 2.9617481231689453 and parameters: {'lstm_hidden_dim': 126, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 15, 'fc_dim2': 7, 'lr_embedding': 0.006343918841724075, 'lr_decoder': 0.00010015236917779718, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:24:20,778]\u001b[0m Trial 24 finished with value: 3.0253090858459473 and parameters: {'lstm_hidden_dim': 74, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 13, 'fc_dim1': 16, 'fc_dim2': 8, 'lr_embedding': 0.009938233694503864, 'lr_decoder': 0.0006164068392052174, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:40:01,638]\u001b[0m Trial 25 finished with value: 3.0131144523620605 and parameters: {'lstm_hidden_dim': 160, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 11, 'fc_dim1': 14, 'fc_dim2': 2, 'lr_embedding': 0.004099727953681757, 'lr_decoder': 6.80897245309793e-05, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:43:33,346]\u001b[0m Trial 26 finished with value: 3.2466442584991455 and parameters: {'lstm_hidden_dim': 122, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 15, 'fc_dim1': 12, 'fc_dim2': 6, 'lr_embedding': 0.0018221629201617103, 'lr_decoder': 0.0001357424789884065, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 18:45:59,902]\u001b[0m Trial 27 finished with value: 3.0893304347991943 and parameters: {'lstm_hidden_dim': 53, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.20305830311520268, 'fc_dim0': 15, 'fc_dim1': 15, 'lr_embedding': 0.006457285142857482, 'lr_decoder': 0.0004507235740863151, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 19:21:54,229]\u001b[0m Trial 28 finished with value: 3.274033546447754 and parameters: {'lstm_hidden_dim': 175, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 13, 'fc_dim1': 10, 'fc_dim2': 10, 'lr_embedding': 0.0027979891733145032, 'lr_decoder': 5.314825451282132e-05, 'batch_size_power': 6}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 19:29:04,757]\u001b[0m Trial 29 finished with value: 3.1050353050231934 and parameters: {'lstm_hidden_dim': 137, 'n_lstm_layers': 1, 'n_fc_layers': 1, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.4091331049612477, 'fc_dim0': 11, 'lr_embedding': 0.0012614268400037336, 'lr_decoder': 0.0013207769334778892, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 19:34:45,133]\u001b[0m Trial 30 finished with value: 3.108400821685791 and parameters: {'lstm_hidden_dim': 203, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 9, 'fc_dim1': 14, 'fc_dim2': 8, 'lr_embedding': 0.003941935125300657, 'lr_decoder': 0.0009438779407268342, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 19:42:36,564]\u001b[0m Trial 31 finished with value: 2.933454990386963 and parameters: {'lstm_hidden_dim': 120, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 15, 'fc_dim2': 7, 'lr_embedding': 0.006579958256653436, 'lr_decoder': 0.00011255326571434886, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 19:48:42,500]\u001b[0m Trial 32 finished with value: 2.978336811065674 and parameters: {'lstm_hidden_dim': 115, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 15, 'fc_dim2': 9, 'lr_embedding': 0.006928821695966272, 'lr_decoder': 0.00015102629849405826, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 19:53:16,855]\u001b[0m Trial 33 finished with value: 3.050537347793579 and parameters: {'lstm_hidden_dim': 93, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 15, 'fc_dim1': 16, 'fc_dim2': 7, 'lr_embedding': 0.005638765666857737, 'lr_decoder': 8.495139013017543e-05, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:05:01,767]\u001b[0m Trial 34 finished with value: 3.1544947624206543 and parameters: {'lstm_hidden_dim': 140, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': True, 'dropout_rate': 0.2828591936378844, 'fc_dim0': 13, 'fc_dim1': 14, 'fc_dim2': 3, 'lr_embedding': 0.007848918261816818, 'lr_decoder': 0.0002754195165505326, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:06:55,188]\u001b[0m Trial 35 finished with value: 3.021976947784424 and parameters: {'lstm_hidden_dim': 68, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 15, 'fc_dim1': 12, 'lr_embedding': 0.002707065209395705, 'lr_decoder': 0.000399044491350613, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:22:24,246]\u001b[0m Trial 36 finished with value: 4.0070061683654785 and parameters: {'lstm_hidden_dim': 138, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 11, 'fc_dim1': 3, 'fc_dim2': 9, 'lr_embedding': 5.032940307921868e-05, 'lr_decoder': 0.00018274169142749497, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:25:24,257]\u001b[0m Trial 37 finished with value: 3.1225287914276123 and parameters: {'lstm_hidden_dim': 113, 'n_lstm_layers': 1, 'n_fc_layers': 2, 'LATENT_DIM_power': 3, 'drop_out_flag': True, 'dropout_rate': 0.2597296542463884, 'fc_dim0': 12, 'fc_dim1': 12, 'lr_embedding': 0.004841469471681519, 'lr_decoder': 0.00011124685233230697, 'batch_size_power': 7}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:29:01,835]\u001b[0m Trial 38 finished with value: 3.105201005935669 and parameters: {'lstm_hidden_dim': 24, 'n_lstm_layers': 2, 'n_fc_layers': 1, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 6, 'lr_embedding': 0.007346496974900413, 'lr_decoder': 0.00030013084552908985, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:30:30,474]\u001b[0m Trial 39 finished with value: 15.456804275512695 and parameters: {'lstm_hidden_dim': 89, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 13, 'fc_dim1': 7, 'fc_dim2': 5, 'lr_embedding': 0.002240359341118721, 'lr_decoder': 0.0014425165807568684, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:37:47,885]\u001b[0m Trial 40 finished with value: 3.4195854663848877 and parameters: {'lstm_hidden_dim': 127, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 15, 'lr_embedding': 0.0005069580045891811, 'lr_decoder': 7.659756536024545e-05, 'batch_size_power': 5}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 20:56:45,719]\u001b[0m Trial 41 finished with value: 3.081645965576172 and parameters: {'lstm_hidden_dim': 130, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 15, 'fc_dim2': 7, 'lr_embedding': 0.006318957865169819, 'lr_decoder': 5.3497643589887004e-05, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 21:01:25,620]\u001b[0m Trial 42 finished with value: 3.0262935161590576 and parameters: {'lstm_hidden_dim': 100, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 15, 'fc_dim1': 16, 'fc_dim2': 7, 'lr_embedding': 0.009820954402032211, 'lr_decoder': 0.00011437317175086476, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 21:13:42,071]\u001b[0m Trial 43 finished with value: 2.9381794929504395 and parameters: {'lstm_hidden_dim': 158, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 14, 'fc_dim2': 8, 'lr_embedding': 0.005874519623452166, 'lr_decoder': 0.0001010141505619031, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[32m[I 2023-04-17 21:30:51,739]\u001b[0m Trial 44 finished with value: 3.117187738418579 and parameters: {'lstm_hidden_dim': 159, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 2, 'drop_out_flag': False, 'fc_dim0': 16, 'fc_dim1': 14, 'fc_dim2': 8, 'lr_embedding': 0.003716893345193603, 'lr_decoder': 9.10003348196306e-05, 'batch_size_power': 4}. Best is trial 11 with value: 2.864987850189209.\u001b[0m\n",
      "\u001b[33m[W 2023-04-17 21:50:03,372]\u001b[0m Trial 45 failed because of the following error: KeyboardInterrupt()\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\optuna\\study\\_optimize.py\", line 196, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"C:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp\\ipykernel_19076\\2216805167.py\", line 105, in objective\n",
      "    training_fun.val_model(\n",
      "  File \"c:\\Users\\User\\Documents\\deep_lumped\\training_fun.py\", line 84, in val_model\n",
      "    out = val_metric(preds, y)\n",
      "  File \"c:\\Users\\User\\Documents\\deep_lumped\\training_fun.py\", line 37, in mse_loss_with_nans\n",
      "    out = (input[~mask] - target[~mask]) ** 2\n",
      "  File \"c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\torch\\_tensor.py\", line 37, in wrapped\n",
      "    if has_torch_function(args):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m study \u001b[39m=\u001b[39m optuna\u001b[39m.\u001b[39mcreate_study(\n\u001b[0;32m      2\u001b[0m     study_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbase_model\u001b[39m\u001b[39m\"\u001b[39m, direction\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mminimize\u001b[39m\u001b[39m\"\u001b[39m, pruner\u001b[39m=\u001b[39moptuna\u001b[39m.\u001b[39mpruners\u001b[39m.\u001b[39mNopPruner()\n\u001b[0;32m      3\u001b[0m )\n\u001b[1;32m----> 4\u001b[0m study\u001b[39m.\u001b[39;49moptimize(LSTM_objective, n_trials\u001b[39m=\u001b[39;49m\u001b[39m200\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\optuna\\study\\study.py:419\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39moptimize\u001b[39m(\n\u001b[0;32m    316\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    317\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    324\u001b[0m     show_progress_bar: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    325\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m     \u001b[39m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    327\u001b[0m \n\u001b[0;32m    328\u001b[0m \u001b[39m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 419\u001b[0m     _optimize(\n\u001b[0;32m    420\u001b[0m         study\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m    421\u001b[0m         func\u001b[39m=\u001b[39;49mfunc,\n\u001b[0;32m    422\u001b[0m         n_trials\u001b[39m=\u001b[39;49mn_trials,\n\u001b[0;32m    423\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    424\u001b[0m         n_jobs\u001b[39m=\u001b[39;49mn_jobs,\n\u001b[0;32m    425\u001b[0m         catch\u001b[39m=\u001b[39;49mcatch,\n\u001b[0;32m    426\u001b[0m         callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[0;32m    427\u001b[0m         gc_after_trial\u001b[39m=\u001b[39;49mgc_after_trial,\n\u001b[0;32m    428\u001b[0m         show_progress_bar\u001b[39m=\u001b[39;49mshow_progress_bar,\n\u001b[0;32m    429\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\optuna\\study\\_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     65\u001b[0m     \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 66\u001b[0m         _optimize_sequential(\n\u001b[0;32m     67\u001b[0m             study,\n\u001b[0;32m     68\u001b[0m             func,\n\u001b[0;32m     69\u001b[0m             n_trials,\n\u001b[0;32m     70\u001b[0m             timeout,\n\u001b[0;32m     71\u001b[0m             catch,\n\u001b[0;32m     72\u001b[0m             callbacks,\n\u001b[0;32m     73\u001b[0m             gc_after_trial,\n\u001b[0;32m     74\u001b[0m             reseed_sampler_rng\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     75\u001b[0m             time_start\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m     76\u001b[0m             progress_bar\u001b[39m=\u001b[39;49mprogress_bar,\n\u001b[0;32m     77\u001b[0m         )\n\u001b[0;32m     78\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     79\u001b[0m         \u001b[39mif\u001b[39;00m n_jobs \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial \u001b[39m=\u001b[39m _run_trial(study, func, catch)\n\u001b[0;32m    161\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[39m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[39m# environments (e.g., services that use computing containers such as CircleCI).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[39m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[39m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[39mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\optuna\\study\\_optimize.py:234\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    227\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mFalse\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mShould not reach.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    230\u001b[0m     frozen_trial\u001b[39m.\u001b[39mstate \u001b[39m==\u001b[39m TrialState\u001b[39m.\u001b[39mFAIL\n\u001b[0;32m    231\u001b[0m     \u001b[39mand\u001b[39;00m func_err \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    232\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    233\u001b[0m ):\n\u001b[1;32m--> 234\u001b[0m     \u001b[39mraise\u001b[39;00m func_err\n\u001b[0;32m    235\u001b[0m \u001b[39mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[1;32mc:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\optuna\\study\\_optimize.py:196\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[39mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[39m.\u001b[39m_trial_id, study\u001b[39m.\u001b[39m_storage):\n\u001b[0;32m    195\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 196\u001b[0m         value_or_values \u001b[39m=\u001b[39m func(trial)\n\u001b[0;32m    197\u001b[0m     \u001b[39mexcept\u001b[39;00m exceptions\u001b[39m.\u001b[39mTrialPruned \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    198\u001b[0m         \u001b[39m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    199\u001b[0m         state \u001b[39m=\u001b[39m TrialState\u001b[39m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[4], line 105\u001b[0m, in \u001b[0;36mObjective.objective\u001b[1;34m(self, trial)\u001b[0m\n\u001b[0;32m     92\u001b[0m     val_loss \u001b[39m=\u001b[39m training_fun\u001b[39m.\u001b[39mval_model_mem_saving(\n\u001b[0;32m     93\u001b[0m         embedding\u001b[39m=\u001b[39membedding,\n\u001b[0;32m     94\u001b[0m         decoder\u001b[39m=\u001b[39mdecoder,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m         val_steps\u001b[39m=\u001b[39mVAL_STEPS,\n\u001b[0;32m    102\u001b[0m     )\n\u001b[0;32m    103\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    104\u001b[0m     val_loss \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 105\u001b[0m         training_fun\u001b[39m.\u001b[39;49mval_model(\n\u001b[0;32m    106\u001b[0m             embedding\u001b[39m=\u001b[39;49membedding,\n\u001b[0;32m    107\u001b[0m             decoder\u001b[39m=\u001b[39;49mdecoder,\n\u001b[0;32m    108\u001b[0m             dataset\u001b[39m=\u001b[39;49mdval,\n\u001b[0;32m    109\u001b[0m             storge_device\u001b[39m=\u001b[39;49mstorge_device,\n\u001b[0;32m    110\u001b[0m             computing_device\u001b[39m=\u001b[39;49mcomputing_device,\n\u001b[0;32m    111\u001b[0m             use_amp\u001b[39m=\u001b[39;49muse_amp,\n\u001b[0;32m    112\u001b[0m             val_metric\u001b[39m=\u001b[39;49mtraining_fun\u001b[39m.\u001b[39;49mmse_loss_with_nans,\n\u001b[0;32m    113\u001b[0m             return_summary\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m    114\u001b[0m         )\n\u001b[0;32m    115\u001b[0m         \u001b[39m.\u001b[39mdetach()\n\u001b[0;32m    116\u001b[0m         \u001b[39m.\u001b[39mcpu()\n\u001b[0;32m    117\u001b[0m         \u001b[39m.\u001b[39mnumpy()\n\u001b[0;32m    118\u001b[0m     )\n\u001b[0;32m    120\u001b[0m trial\u001b[39m.\u001b[39mreport(val_loss, epoch)\n\u001b[0;32m    122\u001b[0m \u001b[39mif\u001b[39;00m trial\u001b[39m.\u001b[39mshould_prune():\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\deep_lumped\\training_fun.py:84\u001b[0m, in \u001b[0;36mval_model\u001b[1;34m(embedding, decoder, dataset, storge_device, computing_device, use_amp, val_metric, return_summary)\u001b[0m\n\u001b[0;32m     81\u001b[0m             preds[i, :, :] \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39mdecode(code, x_sub)\n\u001b[0;32m     83\u001b[0m \u001b[39mif\u001b[39;00m return_summary:\n\u001b[1;32m---> 84\u001b[0m     out \u001b[39m=\u001b[39m val_metric(preds, y)\n\u001b[0;32m     85\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     86\u001b[0m     out \u001b[39m=\u001b[39m preds\n",
      "File \u001b[1;32mc:\\Users\\User\\Documents\\deep_lumped\\training_fun.py:37\u001b[0m, in \u001b[0;36mmse_loss_with_nans\u001b[1;34m(input, target)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmse_loss_with_nans\u001b[39m(\u001b[39minput\u001b[39m, target):\n\u001b[0;32m     32\u001b[0m     \u001b[39m# Adapted from https://stackoverflow.com/a/59851632/3361298\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \n\u001b[0;32m     34\u001b[0m     \u001b[39m# Missing data are nans\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39misnan(target)\n\u001b[1;32m---> 37\u001b[0m     out \u001b[39m=\u001b[39m (\u001b[39minput\u001b[39;49m[\u001b[39m~\u001b[39;49mmask] \u001b[39m-\u001b[39;49m target[\u001b[39m~\u001b[39;49mmask]) \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m\n\u001b[0;32m     38\u001b[0m     loss \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mmean()\n\u001b[0;32m     40\u001b[0m     \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\torch\\_tensor.py:37\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f, assigned\u001b[39m=\u001b[39massigned)\n\u001b[0;32m     34\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     35\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     36\u001b[0m         \u001b[39m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m         \u001b[39mif\u001b[39;00m has_torch_function(args):\n\u001b[0;32m     38\u001b[0m             \u001b[39mreturn\u001b[39;00m handle_torch_function(wrapped, args, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     39\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"base_model\", direction=\"minimize\", pruner=optuna.pruners.NopPruner()\n",
    ")\n",
    "study.optimize(LSTM_objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/camels_lstm_study.pkl']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(study, \"data/531camels_lstm_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_x, out_y = dval.get_val_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 671, 730, 3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 671, 365])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ddfd6d42648f68c476c776315986cac60a18b45e56ba9b8a233e8441d39da2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
