{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 3\n",
    "\n",
    "N_CATCHMENTS = 749\n",
    "\n",
    "# training hyperparameters\n",
    "TRAIN_YEAR = 15\n",
    "\n",
    "use_amp = True\n",
    "compile_model = False\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = True\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dataloader.Forcing_Data(\n",
    "    \"./data/data3f_train.csv\",\n",
    "    record_length=5843,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dval = dataloader.Forcing_Data(\n",
    "    \"./data/data3f_val.csv\",\n",
    "    record_length=2191,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN_Model:\n",
    "    def __init__(\n",
    "        self, hidden_channel_dim=128, kernel_size=3, p=0.5, feature_dim=3, latent_dim=4\n",
    "    ):\n",
    "        # N_CATCHMENT is from global\n",
    "\n",
    "        # num_channels\n",
    "        # ref: https://unit8.com/resources/temporal-convolutional-networks-and-forecasting/\n",
    "        base = 2  # dilation factor\n",
    "        n_levels = math.log(\n",
    "            (BASE_LENGTH - 1) * (base - 1) / (kernel_size - 1) / 2 + 1\n",
    "        ) / math.log(2)\n",
    "        n_levels = math.ceil(n_levels)\n",
    "\n",
    "        num_channels = []\n",
    "        for i in range(n_levels - 1):\n",
    "            num_channels.append(hidden_channel_dim)\n",
    "\n",
    "        num_channels.append(1)  # output dim = 1\n",
    "\n",
    "        self.decoder = models.TCN_decoder(\n",
    "            latent_dim=latent_dim,\n",
    "            feature_dim=feature_dim,\n",
    "            num_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            p=p,\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Embedding(N_CATCHMENTS, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "        lstm_hidden_dim,\n",
    "        n_lstm_layers,\n",
    "        fc_hidden_dims,\n",
    "        p,\n",
    "        feature_dim=3,\n",
    "        output_dim=1,\n",
    "    ):\n",
    "        # N_CATCHMENT is from global\n",
    "        self.decoder = models.LSTM_decoder(\n",
    "            latent_dim=latent_dim,\n",
    "            feature_dim=feature_dim,\n",
    "            lstm_hidden_dim=lstm_hidden_dim,\n",
    "            fc_hidden_dims=fc_hidden_dims,\n",
    "            num_lstm_layers=n_lstm_layers,\n",
    "            output_dim=output_dim,\n",
    "            p=p,\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Embedding(N_CATCHMENTS, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_test(model, epochs=2, batch_size=64, lr_embedding=0.001, lr_decoder=0.001):\n",
    "\n",
    "    # prepare early stopper\n",
    "    early_stopper = training_fun.EarlyStopper(patience=1000, min_delta=0)\n",
    "\n",
    "    # define model\n",
    "    embedding, decoder = model.embedding.to(computing_device), model.decoder.to(\n",
    "        computing_device\n",
    "    )\n",
    "\n",
    "    if compile_model:\n",
    "        # pytorch2.0 new feature, complile model for fast training\n",
    "        embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "    # define optimizers\n",
    "    embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "        # repeat TRAIN_YEAR times to finish an epoch\n",
    "        decoder.train()\n",
    "        embedding.train()\n",
    "\n",
    "        for i in range(600):\n",
    "\n",
    "            decoder_optimizer.zero_grad()\n",
    "            embedding_optimizer.zero_grad()\n",
    "\n",
    "            # put the models into training mode\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            # get training batch and pass to device\n",
    "            (x_batch, y_batch, selected_catchments) = dtrain.get_random_batch(\n",
    "                batch_size\n",
    "            )\n",
    "\n",
    "            x_batch, y_batch, selected_catchments = (\n",
    "                x_batch.to(computing_device),\n",
    "                y_batch.to(computing_device),\n",
    "                selected_catchments.to(computing_device),\n",
    "            )\n",
    "\n",
    "            # slice batch for training\n",
    "            with torch.autocast(\n",
    "                device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "            ):\n",
    "                code = embedding(selected_catchments)\n",
    "\n",
    "                # pass through decoder\n",
    "                out = decoder.decode(code, x_batch)\n",
    "\n",
    "                # compute loss\n",
    "                loss = training_fun.mse_loss_with_nans(out, y_batch)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(embedding_optimizer)\n",
    "            scaler.step(decoder_optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        # validate model after each epochs\n",
    "        decoder.eval()\n",
    "        embedding.eval()\n",
    "\n",
    "        if memory_saving:\n",
    "            val_loss = training_fun.val_model_mem_saving(\n",
    "                embedding=embedding,\n",
    "                decoder=decoder,\n",
    "                dataset=dval,\n",
    "                storge_device=storge_device,\n",
    "                computing_device=computing_device,\n",
    "                use_amp=use_amp,\n",
    "                val_metric=training_fun.mse_loss_with_nans,\n",
    "                return_summary=True,\n",
    "                val_steps=VAL_STEPS,\n",
    "            )\n",
    "        else:\n",
    "            val_loss = (\n",
    "                training_fun.val_model(\n",
    "                    embedding=embedding,\n",
    "                    decoder=decoder,\n",
    "                    dataset=dval,\n",
    "                    storge_device=storge_device,\n",
    "                    computing_device=computing_device,\n",
    "                    use_amp=use_amp,\n",
    "                    val_metric=training_fun.mse_loss_with_nans,\n",
    "                    return_summary=True,\n",
    "                )\n",
    "                .detach()\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "            \n",
    "        print(val_loss)\n",
    "\n",
    "        # Early stop using early_stopper, break for loop\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            break\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return early_stopper.min_validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/yang/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1541)\n",
      "tensor(3.4690)\n",
      "tensor(3.2471)\n",
      "tensor(2.9328)\n",
      "tensor(2.7252)\n",
      "Process ended...\n",
      "555.704106092453\n",
      "fit=2.725173234939575\n"
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM_model(\n",
    "    latent_dim=4,\n",
    "    lstm_hidden_dim=32,\n",
    "    n_lstm_layers=1,\n",
    "    fc_hidden_dims=[8],\n",
    "    p=0.25,\n",
    "    feature_dim=3,\n",
    "    output_dim=1,\n",
    ")\n",
    "\n",
    "starting_time = time.time()\n",
    "print(\"Process started...\")\n",
    "\n",
    "fit = speed_test(lstm_model, epochs=5)\n",
    "\n",
    "print(\"Process ended...\")\n",
    "ending_time = time.time()\n",
    "print(ending_time - starting_time)\n",
    "\n",
    "print(f\"fit={fit}\")\n",
    "\n",
    "\n",
    "# tcn_model = TCN_Model(hidden_channel_dim=128, kernel_size=3, p=0.5)\n",
    "\n",
    "# starting_time = time.time()\n",
    "# print(\"Process started...\")\n",
    "\n",
    "# fit = speed_test(tcn_model, epochs=10)\n",
    "\n",
    "# print(\"Process ended...\")\n",
    "# ending_time = time.time()\n",
    "# print(ending_time - starting_time)\n",
    "\n",
    "# print(f\"fit={fit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.6356)\n",
      "tensor(2.5363)\n",
      "tensor(2.4541)\n",
      "tensor(2.4002)\n",
      "tensor(2.3553)\n",
      "tensor(2.3335)\n",
      "tensor(2.2773)\n",
      "tensor(2.2334)\n",
      "tensor(2.2323)\n",
      "tensor(2.2478)\n",
      "tensor(2.2309)\n",
      "tensor(2.2307)\n",
      "tensor(2.1736)\n",
      "tensor(2.1870)\n",
      "tensor(2.1635)\n"
     ]
    }
   ],
   "source": [
    "fit = speed_test(lstm_model, epochs=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started...\n",
      "tensor(7.5700)\n",
      "tensor(7.0758)\n",
      "tensor(6.8422)\n",
      "tensor(6.6585)\n",
      "tensor(6.4802)\n",
      "tensor(6.3472)\n",
      "tensor(6.1712)\n",
      "tensor(6.0665)\n",
      "tensor(5.8456)\n",
      "tensor(5.7155)\n",
      "Process ended...\n",
      "418.00520873069763\n",
      "fit=5.715493679046631\n"
     ]
    }
   ],
   "source": [
    "tcn_model = TCN_Model(hidden_channel_dim=6, kernel_size=2, p=0.5)\n",
    "\n",
    "starting_time = time.time()\n",
    "print(\"Process started...\")\n",
    "\n",
    "fit = speed_test(tcn_model, epochs=10)\n",
    "\n",
    "print(\"Process ended...\")\n",
    "ending_time = time.time()\n",
    "print(ending_time - starting_time)\n",
    "\n",
    "print(f\"fit={fit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4 (main, Mar 31 2022, 03:38:35) [Clang 12.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ddfd6d42648f68c476c776315986cac60a18b45e56ba9b8a233e8441d39da2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
