{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib\n",
    "\n",
    "import HydroErr\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 5\n",
    "\n",
    "N_CATCHMENTS = 671\n",
    "\n",
    "# training hyperparameters\n",
    "EPOCHS = 500\n",
    "TRAIN_YEAR = 14\n",
    "PATIENCE = 20\n",
    "\n",
    "use_amp = True\n",
    "compile_model = True\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = False\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_train_val_test_data(\n",
    "    forcing_dataset,\n",
    "    train_val_length=5478,\n",
    "    train_length=4017,\n",
    "    val_length=1826,\n",
    "    test_length=5844,\n",
    "):\n",
    "    dtrain_val = dataloader.Forcing_Data(\n",
    "        f\"data/671_{forcing_dataset}_original_camels_train_val.csv\",\n",
    "        record_length=train_val_length,\n",
    "        n_feature=FORCING_DIM,\n",
    "        storge_device=storge_device,\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        target_seq_length=TARGET_SEQ_LENGTH,\n",
    "        base_length=BASE_LENGTH,\n",
    "    )\n",
    "\n",
    "    dtrain = dataloader.Forcing_Data(\n",
    "        f\"data/671_{forcing_dataset}_original_camels_train.csv\",\n",
    "        record_length=train_length,\n",
    "        n_feature=FORCING_DIM,\n",
    "        storge_device=storge_device,\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        target_seq_length=TARGET_SEQ_LENGTH,\n",
    "        base_length=BASE_LENGTH,\n",
    "    )\n",
    "\n",
    "    dval = dataloader.Forcing_Data(\n",
    "        f\"data/671_{forcing_dataset}_original_camels_val.csv\",\n",
    "        record_length=val_length,\n",
    "        n_feature=FORCING_DIM,\n",
    "        storge_device=storge_device,\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        target_seq_length=TARGET_SEQ_LENGTH,\n",
    "        base_length=BASE_LENGTH,\n",
    "    )\n",
    "\n",
    "    dtest = dataloader.Forcing_Data(\n",
    "        f\"data/671_{forcing_dataset}_original_camels_test.csv\",\n",
    "        record_length=test_length,\n",
    "        n_feature=FORCING_DIM,\n",
    "        storge_device=storge_device,\n",
    "        seq_length=SEQ_LENGTH,\n",
    "        target_seq_length=TARGET_SEQ_LENGTH,\n",
    "        base_length=BASE_LENGTH,\n",
    "    )\n",
    "\n",
    "    return dtrain_val, dtrain, dval, dtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_study(forcing_dataset):\n",
    "    study = joblib.load(f\"data/{forcing_dataset}_671_study.pkl\")\n",
    "    \n",
    "    return study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__randomstate_ctor() takes from 0 to 1 positional arguments but 2 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/yang/Documents/projects/deep_lumped/evaluating_original_camels.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/evaluating_original_camels.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m study \u001b[39m=\u001b[39m load_study(\u001b[39m\"\u001b[39;49m\u001b[39mnldas\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/yang/Documents/projects/deep_lumped/evaluating_original_camels.ipynb Cell 4\u001b[0m in \u001b[0;36mload_study\u001b[0;34m(forcing_dataset)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/evaluating_original_camels.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload_study\u001b[39m(forcing_dataset):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/evaluating_original_camels.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     study \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdata/\u001b[39;49m\u001b[39m{\u001b[39;49;00mforcing_dataset\u001b[39m}\u001b[39;49;00m\u001b[39m_671_study.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/evaluating_original_camels.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/joblib/numpy_pickle.py:658\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    656\u001b[0m                 \u001b[39mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 658\u001b[0m             obj \u001b[39m=\u001b[39m _unpickle(fobj, filename, mmap_mode)\n\u001b[1;32m    659\u001b[0m \u001b[39mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/joblib/numpy_pickle.py:577\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    575\u001b[0m obj \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    576\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 577\u001b[0m     obj \u001b[39m=\u001b[39m unpickler\u001b[39m.\u001b[39;49mload()\n\u001b[1;32m    578\u001b[0m     \u001b[39mif\u001b[39;00m unpickler\u001b[39m.\u001b[39mcompat_mode:\n\u001b[1;32m    579\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\u001b[39m\"\u001b[39m\u001b[39mThe file \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m has been generated with a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    580\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mjoblib version less than 0.10. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    581\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mPlease regenerate this pickle file.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    582\u001b[0m                       \u001b[39m%\u001b[39m filename,\n\u001b[1;32m    583\u001b[0m                       \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/pickle.py:1213\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1211\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mEOFError\u001b[39;00m\n\u001b[1;32m   1212\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1213\u001b[0m         dispatch[key[\u001b[39m0\u001b[39;49m]](\u001b[39mself\u001b[39;49m)\n\u001b[1;32m   1214\u001b[0m \u001b[39mexcept\u001b[39;00m _Stop \u001b[39mas\u001b[39;00m stopinst:\n\u001b[1;32m   1215\u001b[0m     \u001b[39mreturn\u001b[39;00m stopinst\u001b[39m.\u001b[39mvalue\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/pickle.py:1590\u001b[0m, in \u001b[0;36m_Unpickler.load_reduce\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1588\u001b[0m args \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39mpop()\n\u001b[1;32m   1589\u001b[0m func \u001b[39m=\u001b[39m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[0;32m-> 1590\u001b[0m stack[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs)\n",
      "\u001b[0;31mTypeError\u001b[0m: __randomstate_ctor() takes from 0 to 1 positional arguments but 2 were given"
     ]
    }
   ],
   "source": [
    "study = load_study(\"nldas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self, model_builder):\n",
    "        self.model_builder = model_builder\n",
    "\n",
    "    def objective(self, trial):\n",
    "\n",
    "        # prepare early stopper\n",
    "        early_stopper = training_fun.EarlyStopper(patience=PATIENCE, min_delta=0)\n",
    "\n",
    "        # define model\n",
    "        embedding, decoder = self.model_builder.define_model(trial)\n",
    "        embedding, decoder = embedding.to(computing_device), decoder.to(\n",
    "            computing_device\n",
    "        )\n",
    "\n",
    "        if compile_model:\n",
    "            # pytorch2.0 new feature, complile model for fast training\n",
    "            embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "        # define optimizers\n",
    "        lr_embedding = trial.suggest_float(\"lr_embedding\", 5e-5, 1e-2, log=True)\n",
    "        embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "\n",
    "        lr_decoder = trial.suggest_float(\"lr_decoder\", 5e-5, 1e-2, log=True)\n",
    "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "        # define batch size\n",
    "        batch_size_power = trial.suggest_int(\"batch_size_power\", 4, 8)\n",
    "        batch_size = 2**batch_size_power\n",
    "\n",
    "        # steps per epoch\n",
    "        steps = round(N_CATCHMENTS * TRAIN_YEAR / batch_size)\n",
    "\n",
    "        # train model\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "            # repeat TRAIN_YEAR times to finish an epoch\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            for step in range(steps):\n",
    "\n",
    "                decoder_optimizer.zero_grad()\n",
    "                embedding_optimizer.zero_grad()\n",
    "\n",
    "                # put the models into training mode\n",
    "                decoder.train()\n",
    "                embedding.train()\n",
    "\n",
    "                # get training batch and pass to device\n",
    "                invalid_batch = True\n",
    "                while invalid_batch:\n",
    "                    (x_batch, y_batch, selected_catchments) = dtrain.get_random_batch(\n",
    "                        batch_size\n",
    "                    )\n",
    "\n",
    "                    if len(x_batch) > 0:\n",
    "                        invalid_batch = False\n",
    "\n",
    "                x_batch, y_batch, selected_catchments = (\n",
    "                    x_batch.to(computing_device),\n",
    "                    y_batch.to(computing_device),\n",
    "                    selected_catchments.to(computing_device),\n",
    "                )\n",
    "\n",
    "                # slice batch for training\n",
    "                with torch.autocast(\n",
    "                    device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "                ):\n",
    "                    code = embedding(selected_catchments)\n",
    "\n",
    "                    # pass through decoder\n",
    "                    out = decoder.decode(code, x_batch)\n",
    "\n",
    "                    # compute loss\n",
    "                    loss = training_fun.mse_loss_with_nans(out, y_batch)\n",
    "\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(embedding_optimizer)\n",
    "                scaler.step(decoder_optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "            # validate model after each epochs\n",
    "            decoder.eval()\n",
    "            embedding.eval()\n",
    "\n",
    "            # Handle pruning based on the intermediate value\n",
    "            if memory_saving:\n",
    "                val_loss = training_fun.val_model_mem_saving(\n",
    "                    embedding=embedding,\n",
    "                    decoder=decoder,\n",
    "                    dataset=dval,\n",
    "                    storge_device=storge_device,\n",
    "                    computing_device=computing_device,\n",
    "                    use_amp=use_amp,\n",
    "                    val_metric=training_fun.mse_loss_with_nans,\n",
    "                    return_summary=True,\n",
    "                    val_steps=VAL_STEPS,\n",
    "                )\n",
    "            else:\n",
    "                val_loss = (\n",
    "                    training_fun.val_model(\n",
    "                        embedding=embedding,\n",
    "                        decoder=decoder,\n",
    "                        dataset=dval,\n",
    "                        storge_device=storge_device,\n",
    "                        computing_device=computing_device,\n",
    "                        use_amp=use_amp,\n",
    "                        val_metric=training_fun.mse_loss_with_nans,\n",
    "                        return_summary=True,\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                torch.cuda.empty_cache()\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            # Early stop using early_stopper, break for loop\n",
    "            if early_stopper.early_stop(val_loss):\n",
    "                break\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return early_stopper.min_validation_loss\n",
    "\n",
    "\n",
    "forcing_datasets = [\"nldas\", \"daymet\", \"maurer\"]\n",
    "\n",
    "for i in range(len(forcing_datasets)):\n",
    "    forcing_dataset = forcing_datasets[i]\n",
    "\n",
    "    dtrain_val, dtrain, dval, dtest = read_train_val_test_data(forcing_dataset)\n",
    "\n",
    "    LSTM_model_builder = training_fun.LSTM_model_builder(\n",
    "        n_catchments=N_CATCHMENTS, base_length=BASE_LENGTH, forcing_dim=FORCING_DIM\n",
    "    )\n",
    "\n",
    "    LSTM_objective = Objective(LSTM_model_builder).objective\n",
    "\n",
    "    study = optuna.create_study(\n",
    "        study_name=f\"{forcing_dataset}_671_study\",\n",
    "        direction=\"minimize\",\n",
    "        pruner=optuna.pruners.NopPruner(),\n",
    "    )\n",
    "    study.optimize(LSTM_objective, n_trials=200)\n",
    "\n",
    "    joblib.dump(study, f\"data/{forcing_dataset}_671_study.pkl\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
