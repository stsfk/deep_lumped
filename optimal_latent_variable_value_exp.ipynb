{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pygad\n",
    "\n",
    "import HydroErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 3\n",
    "\n",
    "# training hyperparameters\n",
    "use_amp = True\n",
    "compile_model = False\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = False\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.load(\"data/final_models/final_lstm_embedding0.pt\", map_location=torch.device('cpu')).to(computing_device)\n",
    "decoder = torch.load(\"data/final_models/final_lstm_decoder0.pt\", map_location=torch.device('cpu')).to(computing_device)\n",
    "\n",
    "embedding.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# dimension of embedding\n",
    "catchment_embeddings=[x.data for x in embedding.parameters()][0]\n",
    "LATENT_dim = catchment_embeddings.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_val = dataloader.Forcing_Data(\n",
    "    \"data/data/CAMELS/camels_train_val.csv\",\n",
    "    record_length=3652,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "\n",
    "dtest = dataloader.Forcing_Data(\n",
    "    \"data/data/CAMELS/camels_test.csv\",\n",
    "    record_length=4383,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective_builder_batch:\n",
    "    def __init__(self, x, y, eval_fun):\n",
    "        self.eval_fun = eval_fun\n",
    "        \n",
    "        self.x = x.contiguous() \n",
    "        self.year = x.shape[0] # the long time series is split into x.shape[0] years\n",
    "        \n",
    "        self.y = y\n",
    "    \n",
    "    def eval(self, ga_instance, solutions, solution_idx):\n",
    "        \n",
    "        if len(solutions.shape)==1:\n",
    "          solutions = np.expand_dims(solutions, axis=0) \n",
    "        \n",
    "        batch_size = solutions.shape[0]\n",
    "        \n",
    "        x = self.x.repeat(batch_size, 1, 1).contiguous() # repeat batch_size times\n",
    "        y = self.y.reshape(-1).contiguous() # combine to a multiple year time series\n",
    "        \n",
    "        # numpy to torch tensor\n",
    "        solutions = torch.from_numpy(solutions).to(dtype=torch.float32).to(computing_device)\n",
    "        # repeat to match the size of x, which split a long time series into multiple years\n",
    "        solutions = solutions.repeat_interleave(self.year, dim = 0)\n",
    "        \n",
    "        pred = decoder.decode(solutions, x).reshape(batch_size, -1).detach().cpu().numpy()\n",
    "        ob = y.detach().cpu().numpy()\n",
    "\n",
    "        gofs = np.ones([batch_size])\n",
    "        for i in range(batch_size):\n",
    "          gofs[i] = self.eval_fun(simulated_array=pred[i,:], observed_array=ob)    \n",
    "        \n",
    "        return gofs.tolist()\n",
    "      \n",
    "    def predict_discharge(self, solutions):\n",
    "\n",
    "        if len(solutions.shape)==1:\n",
    "          solutions = np.expand_dims(solutions, axis=0) \n",
    "        \n",
    "        batch_size = solutions.shape[0]\n",
    "        \n",
    "        x = self.x.repeat(batch_size, 1, 1).contiguous() # repeat batch_size times\n",
    "        y = self.y.reshape(-1).contiguous() # combine to a multiple year time series\n",
    "        \n",
    "        # numpy to torch tensor\n",
    "        solutions = torch.from_numpy(solutions).to(dtype=torch.float32).to(computing_device)\n",
    "        # repeat to match the size of x, which split a long time series into multiple years\n",
    "        solutions = solutions.repeat_interleave(self.year, dim = 0)\n",
    "        \n",
    "        pred = decoder.decode(solutions, x).reshape(batch_size, -1).detach().cpu().numpy()\n",
    "        ob = y.detach().cpu().numpy()\n",
    "        \n",
    "        return pred, ob\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch_train_val, y_batch_train_val = dtrain_val.get_val_batch()\n",
    "x_batch_test, y_batch_test = dtest.get_val_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters of GA\n",
    "num_generations = 500\n",
    "num_parents_mating = 10\n",
    "\n",
    "sol_per_pop = 200\n",
    "num_genes = LATENT_dim\n",
    "\n",
    "# Calculate the minimal and maximal values for each column\n",
    "min_vals, _ = catchment_embeddings.min(dim=0)\n",
    "max_vals, _ = catchment_embeddings.max(dim=0)\n",
    "\n",
    "# Scale the values by 20%, considering the sign\n",
    "min_scaled_values = [(min_val * 1.2 if min_val < 0 else min_val * 0.8) for min_val in min_vals]\n",
    "max_scaled_values = [(max_val * 0.8 if max_val < 0 else max_val * 1.2) for max_val in max_vals]\n",
    "\n",
    "# Convert the results to lists\n",
    "init_range_low = [val.item() for val in min_scaled_values]\n",
    "init_range_high = [val.item() for val in max_scaled_values]\n",
    "\n",
    "# Print the results\n",
    "parent_selection_type = \"sss\"\n",
    "\n",
    "crossover_type = \"single_point\"\n",
    "\n",
    "mutation_type = \"random\"\n",
    "mutation_probability = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitting_wrapper(selected_catchment, batch_size=50):\n",
    "\n",
    "    # Subsetting training, validation, and test data of selected catchments\n",
    "    x_train_val = x_batch_train_val[:,selected_catchment,:,:].to(computing_device)\n",
    "    y_train_val = y_batch_train_val[:,selected_catchment,:].to(computing_device)\n",
    "\n",
    "    x_test = x_batch_test[:,selected_catchment,:,:].to(computing_device)\n",
    "    y_test = y_batch_test[:,selected_catchment,:].to(computing_device)\n",
    "\n",
    "    # Creating evaluation functions\n",
    "    fn_train_val = Objective_builder_batch(x_train_val,y_train_val,HydroErr.kge_2009)\n",
    "    fn_test = Objective_builder_batch(x_test,y_test,HydroErr.kge_2009)\n",
    "\n",
    "    # Setting up callback functions for early stop\n",
    "    # Identifying optimal number of generations\n",
    "    ga_instance = pygad.GA(num_generations=num_generations,\n",
    "                        num_parents_mating=num_parents_mating,\n",
    "                        fitness_func=fn_train_val.eval,\n",
    "                        sol_per_pop=sol_per_pop,\n",
    "                        num_genes=num_genes,\n",
    "                        init_range_low=init_range_low,\n",
    "                        init_range_high=init_range_high,\n",
    "                        parent_selection_type=parent_selection_type,\n",
    "                        fitness_batch_size = batch_size,\n",
    "                        crossover_type=crossover_type,\n",
    "                        mutation_type=mutation_type,\n",
    "                        mutation_probability = mutation_probability,\n",
    "                        stop_criteria=\"saturate_10\")\n",
    "\n",
    "    ga_instance.run()\n",
    "\n",
    "    # Evaluating best solution\n",
    "    #solution = ga_instance.best_solutions[np.argmax(val_losses),:]\n",
    "    solution, solution_fitness, solution_idx = ga_instance.best_solution()\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    return fn_test.eval(ga_instance, solution, 1), solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i=0 starts\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\pygad\\pygad.py:1139: UserWarning: The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\n",
      "  warnings.warn(\"The 'delay_after_gen' parameter is deprecated starting from PyGAD 3.3.0. To delay or pause the evolution after each generation, assign a callback function/method to the 'on_generation' parameter to adds some time delay.\")\n",
      "c:\\Users\\User\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [3287 3288 3289 3290 3291 3292 3293 3294 3295 3296 3297 3298 3299 3300\n",
      " 3301 3302 3303 3304 3305 3306 3307 3308 3309 3310 3311 3312 3313 3314\n",
      " 3315 3316 3317 3318 3319 3320 3321 3322 3323 3324 3325 3326 3327 3328\n",
      " 3329 3330 3331 3332 3333 3334 3335 3336 3337 3338 3339 3340 3341 3342\n",
      " 3343 3344 3345 3346 3347 3348 3349 3350 3351 3352 3353 3354 3355 3356\n",
      " 3357 3358 3359 3360 3361 3362 3363 3364 3365 3366 3367 3368 3369 3370\n",
      " 3371 3372 3373 3374 3375 3376 3377 3378 3379 3380 3381 3382 3383 3384\n",
      " 3385 3386 3387 3388 3389 3390 3391 3392 3393 3394 3395 3396 3397 3398\n",
      " 3399 3400 3401 3402 3403 3404 3405 3406 3407 3408 3409 3410 3411 3412\n",
      " 3413 3414 3415 3416 3417 3418 3419 3420 3421 3422 3423 3424 3425 3426\n",
      " 3427 3428 3429 3430 3431 3432 3433 3434 3435 3436 3437 3438 3439 3440\n",
      " 3441 3442 3443 3444 3445 3446 3447 3448 3449 3450 3451 3452 3453 3454\n",
      " 3455 3456 3457 3458 3459 3460 3461 3462 3463 3464 3465 3466 3467 3468\n",
      " 3469 3470 3471 3472 3473 3474 3475 3476 3477 3478 3479 3480 3481 3482\n",
      " 3483 3484 3485 3486 3487 3488 3489 3490 3491 3492 3493 3494 3495 3496\n",
      " 3497 3498 3499 3500 3501 3502 3503 3504 3505 3506 3507 3508 3509 3510\n",
      " 3511 3512 3513 3514 3515 3516 3517 3518 3519 3520 3521 3522 3523 3524\n",
      " 3525 3526 3527 3528 3529 3530 3531 3532 3533 3534 3535 3536 3537 3538\n",
      " 3539 3540 3541 3542 3543 3544 3545 3546 3547 3548 3549 3550 3551 3552\n",
      " 3553 3554 3555 3556 3557 3558 3559 3560 3561 3562 3563 3564 3565 3566\n",
      " 3567 3568 3569 3570 3571 3572 3573 3574 3575 3576 3577 3578 3579 3580\n",
      " 3581 3582 3583 3584 3585 3586 3587 3588 3589 3590 3591 3592 3593 3594\n",
      " 3595 3596 3597 3598 3599 3600 3601 3602 3603 3604 3605 3606 3607 3608\n",
      " 3609 3610 3611 3612 3613 3614 3615 3616 3617 3618 3619 3620 3621 3622\n",
      " 3623 3624 3625 3626 3627 3628 3629 3630 3631 3632 3633 3634 3635 3636\n",
      " 3637 3638 3639 3640 3641 3642 3643 3644 3645 3646 3647 3648 3649] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n",
      "c:\\Users\\User\\anaconda3\\envs\\pytorch-env\\Lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [4018 4019 4020 4021 4022 4023 4024 4025 4026 4027 4028 4029 4030 4031\n",
      " 4032 4033 4034 4035 4036 4037 4038 4039 4040 4041 4042 4043 4044 4045\n",
      " 4046 4047 4048 4049 4050 4051 4052 4053 4054 4055 4056 4057 4058 4059\n",
      " 4060 4061 4062 4063 4064 4065 4066 4067 4068 4069 4070 4071 4072 4073\n",
      " 4074 4075 4076 4077 4078 4079 4080 4081 4082 4083 4084 4085 4086 4087\n",
      " 4088 4089 4090 4091 4092 4093 4094 4095 4096 4097 4098 4099 4100 4101\n",
      " 4102 4103 4104 4105 4106 4107 4108 4109 4110 4111 4112 4113 4114 4115\n",
      " 4116 4117 4118 4119 4120 4121 4122 4123 4124 4125 4126 4127 4128 4129\n",
      " 4130 4131 4132 4133 4134 4135 4136 4137 4138 4139 4140 4141 4142 4143\n",
      " 4144 4145 4146 4147 4148 4149 4150 4151 4152 4153 4154 4155 4156 4157\n",
      " 4158 4159 4160 4161 4162 4163 4164 4165 4166 4167 4168 4169 4170 4171\n",
      " 4172 4173 4174 4175 4176 4177 4178 4179 4180 4181 4182 4183 4184 4185\n",
      " 4186 4187 4188 4189 4190 4191 4192 4193 4194 4195 4196 4197 4198 4199\n",
      " 4200 4201 4202 4203 4204 4205 4206 4207 4208 4209 4210 4211 4212 4213\n",
      " 4214 4215 4216 4217 4218 4219 4220 4221 4222 4223 4224 4225 4226 4227\n",
      " 4228 4229 4230 4231 4232 4233 4234 4235 4236 4237 4238 4239 4240 4241\n",
      " 4242 4243 4244 4245 4246 4247 4248 4249 4250 4251 4252 4253 4254 4255\n",
      " 4256 4257 4258 4259 4260 4261 4262 4263 4264 4265 4266 4267 4268 4269\n",
      " 4270 4271 4272 4273 4274 4275 4276 4277 4278 4279 4280 4281 4282 4283\n",
      " 4284 4285 4286 4287 4288 4289 4290 4291 4292 4293 4294 4295 4296 4297\n",
      " 4298 4299 4300 4301 4302 4303 4304 4305 4306 4307 4308 4309 4310 4311\n",
      " 4312 4313 4314 4315 4316 4317 4318 4319 4320 4321 4322 4323 4324 4325\n",
      " 4326 4327 4328 4329 4330 4331 4332 4333 4334 4335 4336 4337 4338 4339\n",
      " 4340 4341 4342 4343 4344 4345 4346 4347 4348 4349 4350 4351 4352 4353\n",
      " 4354 4355 4356 4357 4358 4359 4360 4361 4362 4363 4364 4365 4366 4367\n",
      " 4368 4369 4370 4371 4372 4373 4374 4375 4376 4377 4378 4379] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit=0.8950190730008679\n",
      "i=1 starts\n",
      "fit=0.9237605152830838\n",
      "i=2 starts\n",
      "fit=0.7912154840168886\n",
      "i=3 starts\n",
      "fit=0.8090339093651917\n",
      "i=4 starts\n",
      "fit=0.897060520135855\n",
      "i=5 starts\n",
      "fit=0.8504251623964988\n",
      "i=6 starts\n",
      "fit=0.8350450744720426\n",
      "i=7 starts\n",
      "fit=0.9221166213648747\n",
      "i=8 starts\n",
      "fit=0.8832417447643821\n",
      "i=9 starts\n",
      "fit=0.928395282938269\n"
     ]
    }
   ],
   "source": [
    "REPEATS = 10\n",
    "calibrated_KGES = np.ones(REPEATS)\n",
    "camels_embeddings = np.ones([REPEATS, LATENT_dim])\n",
    "preds = np.ones([REPEATS, y_batch_test.shape[0]*365])\n",
    "ob = np.ones([1, y_batch_test.shape[0]*365])\n",
    "\n",
    "for i in range(REPEATS):\n",
    "    print(f'i={i} starts')\n",
    "    calibrated_KGE, camels_embedding = fitting_wrapper(0)\n",
    "    calibrated_KGES[i], camels_embeddings[i,:]  = np.array(calibrated_KGE)[0], camels_embedding\n",
    "    \n",
    "    x_test = x_batch_test[:,0,:,:].to(computing_device)\n",
    "    y_test = y_batch_test[:,0,:].to(computing_device)\n",
    "    fn_test = Objective_builder_batch(x_test,y_test,HydroErr.kge_2009)\n",
    "\n",
    "    preds[i], ob = fn_test.predict_discharge(camels_embedding)\n",
    "    \n",
    "    print(f'fit={calibrated_KGES[i]}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrated_KGES\n",
    "\n",
    "normalized_embeddings = (camels_embeddings - np.array(init_range_low)) / (np.array(init_range_high) - np.array(init_range_low))\n",
    "\n",
    "np.savetxt(\"data/optimal_latent_variable_exp_results/KGEs.csv\", calibrated_KGES, delimiter=\",\")\n",
    "np.savetxt(\"data/optimal_latent_variable_exp_results/embeddings.csv\", camels_embeddings, delimiter=\",\")\n",
    "np.savetxt(\"data/optimal_latent_variable_exp_results/normalized_embeddings.csv\", normalized_embeddings, delimiter=\",\")\n",
    "\n",
    "np.savetxt(\"data/optimal_latent_variable_exp_results/ob.csv\", ob, delimiter=\",\")\n",
    "np.savetxt(\"data/optimal_latent_variable_exp_results/preds.csv\", preds, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
