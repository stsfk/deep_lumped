{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib\n",
    "\n",
    "import HydroErr\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import HydroErr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 5\n",
    "\n",
    "N_CATCHMENTS = 531\n",
    "\n",
    "# training hyperparameters\n",
    "EPOCHS = 500\n",
    "TRAIN_YEAR = 10\n",
    "PATIENCE = 20\n",
    "\n",
    "use_amp = True\n",
    "compile_model = False\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = False\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "study = joblib.load(\"data/531_daymet_original_lstm_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain_val = dataloader.Forcing_Data(\n",
    "    \"data/531_daymet_original_camels_train_val.csv\",\n",
    "    record_length=3653,\n",
    "    n_feature=FORCING_DIM,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dtrain = dataloader.Forcing_Data(\n",
    "    \"data/531_daymet_original_camels_train.csv\",\n",
    "    record_length=2557,\n",
    "    n_feature=FORCING_DIM,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dval = dataloader.Forcing_Data(\n",
    "    \"data/531_daymet_original_camels_val.csv\",\n",
    "    record_length=1461,\n",
    "    n_feature=FORCING_DIM,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dtest = dataloader.Forcing_Data(\n",
    "    \"data/531_daymet_original_camels_test.csv\",\n",
    "    record_length=4017,\n",
    "    n_feature=FORCING_DIM,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_optimal_epochs(study):\n",
    "    \n",
    "    stats = study.best_trials[0].intermediate_values\n",
    "    epochs = min(stats, key=lambda k: stats[k]) + 1\n",
    "    \n",
    "    return epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_model(study, dataset, n_catchments =N_CATCHMENTS, epoch_scale = 6/TRAIN_YEAR): #19/39\n",
    "\n",
    "    trial = study.best_trial\n",
    "\n",
    "    # define model\n",
    "    model_builder = training_fun.LSTM_model_builder(\n",
    "        n_catchments, base_length=365, forcing_dim=FORCING_DIM\n",
    "    )\n",
    "\n",
    "    embedding, decoder = model_builder.define_model(trial)\n",
    "\n",
    "    embedding, decoder = embedding.to(computing_device), decoder.to(\n",
    "        computing_device\n",
    "    )\n",
    "\n",
    "    if compile_model:\n",
    "        # pytorch2.0 new feature, complile model for fast training\n",
    "        embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "\n",
    "    # define model training hyperparameters\n",
    "    # define optimizers\n",
    "    lr_embedding = trial.suggest_float(\"lr_embedding\", 5e-5, 1e-2, log=True)\n",
    "    embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "\n",
    "    lr_decoder = trial.suggest_float(\"lr_decoder\", 5e-5, 1e-2, log=True)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    # define batch size\n",
    "    batch_size_power = trial.suggest_int(\"batch_size_power\", 4, 8)\n",
    "    batch_size = 2**batch_size_power\n",
    "\n",
    "    # define optimal epochs\n",
    "    epochs = round(get_optimal_epochs(study)*epoch_scale)\n",
    "\n",
    "        # steps per epoch\n",
    "    steps = round(N_CATCHMENTS * TRAIN_YEAR / batch_size)\n",
    "\n",
    "        # train model\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "        # repeat TRAIN_YEAR times to finish an epoch\n",
    "        decoder.train()\n",
    "        embedding.train()\n",
    "\n",
    "        for step in range(steps):\n",
    "\n",
    "            decoder_optimizer.zero_grad()\n",
    "            embedding_optimizer.zero_grad()\n",
    "\n",
    "            # put the models into training mode\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            # get training batch and pass to device\n",
    "            (x_batch, y_batch, selected_catchments) = dataset.get_random_batch(\n",
    "                batch_size\n",
    "            )\n",
    "\n",
    "            x_batch, y_batch, selected_catchments = (\n",
    "                x_batch.to(computing_device),\n",
    "                y_batch.to(computing_device),\n",
    "                selected_catchments.to(computing_device),\n",
    "            )\n",
    "\n",
    "            # slice batch for training\n",
    "            with torch.autocast(\n",
    "                device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "            ):\n",
    "                code = embedding(selected_catchments)\n",
    "\n",
    "                # pass through decoder\n",
    "                out = decoder.decode(code, x_batch)\n",
    "\n",
    "                # compute loss\n",
    "                loss = training_fun.mse_loss_with_nans(out, y_batch)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(embedding_optimizer)\n",
    "            scaler.step(decoder_optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "    return embedding, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding, decoder = get_final_model(study, dtrain_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embedding.cpu(), \"data/531camles_final_lstm_embedding.pt\")\n",
    "torch.save(decoder.cpu(), \"data/531camels_final_lstm_decoder.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = torch.load(\"data/531camles_final_lstm_embedding.pt\").to(computing_device)\n",
    "decoder = torch.load(\"data/531camels_final_lstm_decoder.pt\", map_location=torch.device('cpu')).to(computing_device)\n",
    "\n",
    "embedding.eval()\n",
    "decoder.eval()\n",
    "\n",
    "# dimension of embedding\n",
    "catchment_embeddings=[x.data for x in embedding.parameters()][0]\n",
    "LATENT_dim = catchment_embeddings.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective_builder:\n",
    "    def __init__(self, x, y, eval_fun):\n",
    "        self.eval_fun = eval_fun\n",
    "        self.x = x.contiguous()\n",
    "        self.y = y.contiguous()\n",
    "    \n",
    "    def eval(self, code, return_summary = True):\n",
    "        \n",
    "        # numpy to torch tensor\n",
    "        code = torch.from_numpy(code).unsqueeze(0).to(dtype=torch.float32).to(computing_device)\n",
    "        code = code.expand(self.x.shape[0], -1)\n",
    "        \n",
    "        # BASE_LENGTH is from global\n",
    "        pred = decoder.decode(code, self.x).view(-1).detach().cpu().numpy()\n",
    "\n",
    "        ob = self.y.view(-1).detach().cpu().numpy()\n",
    "        \n",
    "        if return_summary:\n",
    "          gof = self.eval_fun(simulated_array=pred, observed_array=ob)\n",
    "          return gof\n",
    "        else:\n",
    "          return pred, ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([11, 531, 730, 5]), torch.Size([11, 531, 365]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch_test, y_batch_test = dtest.get_val_batch()\n",
    "x_batch_test.shape, y_batch_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_catchment(selected_catchment):\n",
    "    \n",
    "    x = x_batch_test[:,selected_catchment,:,:]\n",
    "    y = y_batch_test[:,selected_catchment,:]\n",
    "\n",
    "    x, y = x.to(computing_device), y.to(computing_device)\n",
    "\n",
    "    fn_kge = Objective_builder(x,y,HydroErr.kge_2009)\n",
    "    fn_nse = Objective_builder(x,y,HydroErr.nse)\n",
    "    \n",
    "    kge = fn_kge.eval(catchment_embeddings[selected_catchment,:].cpu().detach().numpy())\n",
    "    nse = fn_nse.eval(catchment_embeddings[selected_catchment,:].cpu().detach().numpy())\n",
    "    \n",
    "    return  kge, nse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\Anaconda3\\envs\\pytorch1.13\\lib\\site-packages\\HydroErr\\HydroErr.py:6248: UserWarning: Row(s) [3652 3653 3654 3655 3656 3657 3658 3659 3660 3661 3662 3663 3664 3665\n",
      " 3666 3667 3668 3669 3670 3671 3672 3673 3674 3675 3676 3677 3678 3679\n",
      " 3680 3681 3682 3683 3684 3685 3686 3687 3688 3689 3690 3691 3692 3693\n",
      " 3694 3695 3696 3697 3698 3699 3700 3701 3702 3703 3704 3705 3706 3707\n",
      " 3708 3709 3710 3711 3712 3713 3714 3715 3716 3717 3718 3719 3720 3721\n",
      " 3722 3723 3724 3725 3726 3727 3728 3729 3730 3731 3732 3733 3734 3735\n",
      " 3736 3737 3738 3739 3740 3741 3742 3743 3744 3745 3746 3747 3748 3749\n",
      " 3750 3751 3752 3753 3754 3755 3756 3757 3758 3759 3760 3761 3762 3763\n",
      " 3764 3765 3766 3767 3768 3769 3770 3771 3772 3773 3774 3775 3776 3777\n",
      " 3778 3779 3780 3781 3782 3783 3784 3785 3786 3787 3788 3789 3790 3791\n",
      " 3792 3793 3794 3795 3796 3797 3798 3799 3800 3801 3802 3803 3804 3805\n",
      " 3806 3807 3808 3809 3810 3811 3812 3813 3814 3815 3816 3817 3818 3819\n",
      " 3820 3821 3822 3823 3824 3825 3826 3827 3828 3829 3830 3831 3832 3833\n",
      " 3834 3835 3836 3837 3838 3839 3840 3841 3842 3843 3844 3845 3846 3847\n",
      " 3848 3849 3850 3851 3852 3853 3854 3855 3856 3857 3858 3859 3860 3861\n",
      " 3862 3863 3864 3865 3866 3867 3868 3869 3870 3871 3872 3873 3874 3875\n",
      " 3876 3877 3878 3879 3880 3881 3882 3883 3884 3885 3886 3887 3888 3889\n",
      " 3890 3891 3892 3893 3894 3895 3896 3897 3898 3899 3900 3901 3902 3903\n",
      " 3904 3905 3906 3907 3908 3909 3910 3911 3912 3913 3914 3915 3916 3917\n",
      " 3918 3919 3920 3921 3922 3923 3924 3925 3926 3927 3928 3929 3930 3931\n",
      " 3932 3933 3934 3935 3936 3937 3938 3939 3940 3941 3942 3943 3944 3945\n",
      " 3946 3947 3948 3949 3950 3951 3952 3953 3954 3955 3956 3957 3958 3959\n",
      " 3960 3961 3962 3963 3964 3965 3966 3967 3968 3969 3970 3971 3972 3973\n",
      " 3974 3975 3976 3977 3978 3979 3980 3981 3982 3983 3984 3985 3986 3987\n",
      " 3988 3989 3990 3991 3992 3993 3994 3995 3996 3997 3998 3999 4000 4001\n",
      " 4002 4003 4004 4005 4006 4007 4008 4009 4010 4011 4012 4013 4014] contained NaN values and the row(s) have been removed (Rows are zero indexed).\n",
      "  warnings.warn(\"Row(s) {} contained NaN values and the row(s) have been \"\n"
     ]
    }
   ],
   "source": [
    "calibrated_KGES = np.ones(N_CATCHMENTS)\n",
    "calibrated_NSES = np.ones(N_CATCHMENTS)\n",
    "\n",
    "\n",
    "for i in range(N_CATCHMENTS):\n",
    "    #print(f'i={i} starts')\n",
    "    calibrated_KGES[i], calibrated_NSES[i]  = eval_catchment(i)\n",
    "    #print(f'fit={calibrated_KGES[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.hist(calibrated_NSES[calibrated_NSES>0], bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.711998773627114, 0.6427202524752138)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(calibrated_KGES),calibrated_KGES.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7238228917121887, 0.6601925447667386)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(calibrated_NSES),calibrated_NSES.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ddfd6d42648f68c476c776315986cac60a18b45e56ba9b8a233e8441d39da2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
