{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 3\n",
    "\n",
    "N_CATCHMENTS = 2346\n",
    "\n",
    "# training hyperparameters\n",
    "EPOCHS = 200\n",
    "TRAIN_YEAR = 19\n",
    "PATIENCE = 20\n",
    "\n",
    "use_amp = True\n",
    "compile_model = True\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = False\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dataloader.Forcing_Data(\n",
    "    \"data/data_train_w_missing.csv\",\n",
    "    record_length=7304,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dval = dataloader.Forcing_Data(\n",
    "    \"data/data_val_w_missing.csv\",\n",
    "    record_length=4017,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self, model_builder):\n",
    "        self.model_builder = model_builder\n",
    "\n",
    "    def objective(self, trial):\n",
    "\n",
    "        val_losses = []\n",
    "\n",
    "        # prepare early stopper\n",
    "        early_stopper = training_fun.EarlyStopper(patience=PATIENCE, min_delta=0)\n",
    "\n",
    "        # define model\n",
    "        embedding, decoder = self.model_builder.define_model(trial)\n",
    "        embedding, decoder = embedding.to(computing_device), decoder.to(\n",
    "            computing_device\n",
    "        )\n",
    "\n",
    "        if compile_model:\n",
    "            # pytorch2.0 new feature, complile model for fast training\n",
    "            embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "        # define optimizers\n",
    "        lr_embedding = trial.suggest_float(\"lr_embedding\", 5e-5, 1e-2, log=True)\n",
    "        embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "\n",
    "        lr_decoder = trial.suggest_float(\"lr_decoder\", 5e-5, 1e-2, log=True)\n",
    "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "        # define batch size\n",
    "        batch_size_power = trial.suggest_int(\"batch_size_power\", 5, 8)\n",
    "        batch_size = 2**batch_size_power\n",
    "\n",
    "        # train model\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "            # repeat TRAIN_YEAR times to finish an epoch\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            for year in range(TRAIN_YEAR):\n",
    "\n",
    "                x_batch, y_batch = dtrain.get_random_batch()\n",
    "\n",
    "                if memory_saving:\n",
    "                    x_batch, y_batch = x_batch.to(computing_device), y_batch.to(\n",
    "                        computing_device\n",
    "                    )\n",
    "\n",
    "                catchment_index = torch.randperm(\n",
    "                    N_CATCHMENTS, device=computing_device\n",
    "                )  # add randomness\n",
    "\n",
    "                # interate over catchments\n",
    "                for i in range(int(N_CATCHMENTS / batch_size)):\n",
    "\n",
    "                    # prepare data\n",
    "                    ind_s = i * batch_size\n",
    "                    ind_e = (i + 1) * batch_size\n",
    "\n",
    "                    selected_catchments = catchment_index[ind_s:ind_e]\n",
    "\n",
    "                    x_sub, y_sub = x_batch[ind_s:ind_e, :, :], y_batch[ind_s:ind_e, :]\n",
    "\n",
    "                    # prepare training, put the models into training mode\n",
    "                    decoder_optimizer.zero_grad()\n",
    "                    embedding_optimizer.zero_grad()\n",
    "\n",
    "                    # forward pass\n",
    "                    with torch.autocast(\n",
    "                        device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "                    ):\n",
    "                        code = embedding(selected_catchments)\n",
    "                        out = decoder.decode(code, x_sub)\n",
    "\n",
    "                        # backprop\n",
    "                        loss = training_fun.mse_loss_with_nans(out, y_sub)\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(embedding_optimizer)\n",
    "                    scaler.step(decoder_optimizer)\n",
    "                    scaler.update()\n",
    "\n",
    "            # validate model after each epochs\n",
    "            decoder.eval()\n",
    "            embedding.eval()\n",
    "\n",
    "            # Handle pruning based on the intermediate value\n",
    "            if memory_saving:\n",
    "                val_loss = training_fun.val_model_mem_saving(\n",
    "                    embedding=embedding,\n",
    "                    decoder=decoder,\n",
    "                    dataset=dval,\n",
    "                    storge_device=storge_device,\n",
    "                    computing_device=computing_device,\n",
    "                    use_amp=use_amp,\n",
    "                    val_metric=training_fun.mse_loss_with_nans,\n",
    "                    return_summary=True,\n",
    "                    val_steps=VAL_STEPS,\n",
    "                )\n",
    "            else:\n",
    "                val_loss = (\n",
    "                    training_fun.val_model(\n",
    "                        embedding=embedding,\n",
    "                        decoder=decoder,\n",
    "                        dataset=dval,\n",
    "                        storge_device=storge_device,\n",
    "                        computing_device=computing_device,\n",
    "                        use_amp=use_amp,\n",
    "                        val_metric=training_fun.mse_loss_with_nans,\n",
    "                        return_summary=True,\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                torch.cuda.empty_cache()\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            # Early stop using early_stopper, break for loop\n",
    "            if early_stopper.early_stop(val_loss):\n",
    "                break\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return early_stopper.min_validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_builder = training_fun.LSTM_model_builder(\n",
    "    n_catchments = N_CATCHMENTS, base_length=BASE_LENGTH, forcing_dim=FORCING_DIM\n",
    ")\n",
    "\n",
    "LSTM_objective = Objective(LSTM_model_builder).objective\n",
    "\n",
    "TCN_model_builder = training_fun.TCN_model_builder(\n",
    "    n_catchments = N_CATCHMENTS, base_length=BASE_LENGTH, forcing_dim=FORCING_DIM\n",
    ")\n",
    "TCN_objective = Objective(TCN_model_builder).objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-06 23:40:38,611]\u001b[0m A new study created in memory with name: base_model\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 23:41:16,941]\u001b[0m Trial 0 finished with value: 8.105819702148438 and parameters: {'lstm_hidden_dim': 46, 'n_lstm_layers': 2, 'n_fc_layers': 2, 'LATENT_DIM_power': 1, 'drop_out_flag': True, 'dropout_rate': 0.3073757083157444, 'fc_dim0': 15, 'fc_dim1': 9, 'lr_embedding': 0.0014018063397661, 'lr_decoder': 0.0005248822900335671, 'batch_size_power': 6}. Best is trial 0 with value: 8.105819702148438.\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 23:41:45,364]\u001b[0m Trial 1 finished with value: 8.43262004852295 and parameters: {'lstm_hidden_dim': 215, 'n_lstm_layers': 2, 'n_fc_layers': 3, 'LATENT_DIM_power': 1, 'drop_out_flag': False, 'fc_dim0': 14, 'fc_dim1': 11, 'fc_dim2': 15, 'lr_embedding': 8.046134687461299e-05, 'lr_decoder': 0.004481643847260491, 'batch_size_power': 7}. Best is trial 0 with value: 8.105819702148438.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"base_model\", direction=\"minimize\", pruner=optuna.pruners.NopPruner()\n",
    ")\n",
    "study.optimize(LSTM_objective, n_trials=10)\n",
    "\n",
    "joblib.dump(study, \"base_LSTM_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-06 23:43:00,909]\u001b[0m A new study created in memory with name: base_model\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 23:43:15,640]\u001b[0m Trial 0 finished with value: 8.626200675964355 and parameters: {'latent_dim_power': 2, 'kernel_size': 4, 'hidden_channel_dim': 1, 'drop_out_flag': True, 'dropout_rate': 0.10890623004313166, 'lr_embedding': 0.0035720874468074234, 'lr_decoder': 0.0008177612360125232, 'batch_size_power': 6}. Best is trial 0 with value: 8.626200675964355.\u001b[0m\n",
      "\u001b[32m[I 2022-12-06 23:43:55,436]\u001b[0m Trial 1 finished with value: 7.6127610206604 and parameters: {'latent_dim_power': 1, 'kernel_size': 5, 'hidden_channel_dim': 138, 'drop_out_flag': True, 'dropout_rate': 0.131800755417424, 'lr_embedding': 0.004662767612958916, 'lr_decoder': 5.420990594110336e-05, 'batch_size_power': 5}. Best is trial 1 with value: 7.6127610206604.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"base_model\", direction=\"minimize\", pruner=optuna.pruners.NopPruner()\n",
    ")\n",
    "\n",
    "study.optimize(TCN_objective, n_trials=10)\n",
    "\n",
    "joblib.dump(study, \"base_TCN_study.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "1ddfd6d42648f68c476c776315986cac60a18b45e56ba9b8a233e8441d39da2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
