{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 3\n",
    "\n",
    "N_CATCHMENTS = 2346\n",
    "\n",
    "# training hyperparameters\n",
    "TRAIN_YEAR = 19\n",
    "\n",
    "use_amp = True\n",
    "compile_model = False\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = True\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m dtrain \u001b[39m=\u001b[39m dataloader\u001b[39m.\u001b[39;49mForcing_Data(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mdata/data_train_w_missing.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     record_length\u001b[39m=\u001b[39;49m\u001b[39m7304\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     storge_device\u001b[39m=\u001b[39;49mstorge_device,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     seq_length\u001b[39m=\u001b[39;49mSEQ_LENGTH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     target_seq_length\u001b[39m=\u001b[39;49mTARGET_SEQ_LENGTH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     base_length\u001b[39m=\u001b[39;49mBASE_LENGTH,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m dval \u001b[39m=\u001b[39m dataloader\u001b[39m.\u001b[39mForcing_Data(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdata/data_val_w_missing.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     record_length\u001b[39m=\u001b[39m\u001b[39m4017\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     base_length\u001b[39m=\u001b[39mBASE_LENGTH,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W2sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/projects/deep_lumped/dataloader.py:21\u001b[0m, in \u001b[0;36mForcing_Data.__init__\u001b[0;34m(self, fpath, record_length, n_feature, storge_device, seq_length, target_seq_length, base_length)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     12\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     13\u001b[0m     fpath\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdata/data_train_w_missing.csv\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     base_length\u001b[39m=\u001b[39m\u001b[39m365\u001b[39m,\n\u001b[1;32m     20\u001b[0m ):\n\u001b[0;32m---> 21\u001b[0m     data_raw \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mgenfromtxt(fpath, delimiter\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m\"\u001b[39;49m, skip_header\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     23\u001b[0m     \u001b[39m# normalization and then reshape to catchment*record*feature\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mfrom_numpy(data_raw[:, \u001b[39m0\u001b[39m:n_feature])\u001b[39m.\u001b[39mto(dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/numpy/lib/npyio.py:2197\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[1;32m   2195\u001b[0m \u001b[39m# Parse each line\u001b[39;00m\n\u001b[1;32m   2196\u001b[0m \u001b[39mfor\u001b[39;00m (i, line) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(itertools\u001b[39m.\u001b[39mchain([first_line, ], fhd)):\n\u001b[0;32m-> 2197\u001b[0m     values \u001b[39m=\u001b[39m split_line(line)\n\u001b[1;32m   2198\u001b[0m     nbvalues \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(values)\n\u001b[1;32m   2199\u001b[0m     \u001b[39m# Skip an empty line\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/numpy/lib/_iotools.py:226\u001b[0m, in \u001b[0;36mLineSplitter.__call__\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    225\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, line):\n\u001b[0;32m--> 226\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handyman(_decode_line(line, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mencoding))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/numpy/lib/_iotools.py:202\u001b[0m, in \u001b[0;36mLineSplitter._delimited_splitter\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomments \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39msplit(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcomments)[\u001b[39m0\u001b[39m]\n\u001b[0;32m--> 202\u001b[0m line \u001b[39m=\u001b[39m line\u001b[39m.\u001b[39;49mstrip(\u001b[39m\"\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m\\r\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[1;32m    204\u001b[0m     \u001b[39mreturn\u001b[39;00m []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dtrain = dataloader.Forcing_Data(\n",
    "    \"data/data_train_w_missing.csv\",\n",
    "    record_length=7304,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dval = dataloader.Forcing_Data(\n",
    "    \"data/data_val_w_missing.csv\",\n",
    "    record_length=4017,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TCN_Model:\n",
    "    def __init__(\n",
    "        self, hidden_channel_dim=128, kernel_size=3, p=0.5, feature_dim=3, latent_dim=4\n",
    "    ):\n",
    "        # N_CATCHMENT is from global\n",
    "\n",
    "        # num_channels\n",
    "        # ref: https://unit8.com/resources/temporal-convolutional-networks-and-forecasting/\n",
    "        base = 2  # dilation factor\n",
    "        n_levels = math.log(\n",
    "            (BASE_LENGTH - 1) * (base - 1) / (kernel_size - 1) / 2 + 1\n",
    "        ) / math.log(2)\n",
    "        n_levels = math.ceil(n_levels)\n",
    "\n",
    "        num_channels = []\n",
    "        for i in range(n_levels - 1):\n",
    "            num_channels.append(hidden_channel_dim)\n",
    "\n",
    "        num_channels.append(1)  # output dim = 1\n",
    "\n",
    "        self.decoder = models.TCN_decoder(\n",
    "            latent_dim=latent_dim,\n",
    "            feature_dim=feature_dim,\n",
    "            num_channels=num_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            p=p,\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Embedding(N_CATCHMENTS, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_model:\n",
    "    def __init__(\n",
    "        self,\n",
    "        latent_dim,\n",
    "        lstm_hidden_dim,\n",
    "        n_lstm_layers,\n",
    "        fc_hidden_dims,\n",
    "        p,\n",
    "        feature_dim=3,\n",
    "        output_dim=1,\n",
    "    ):\n",
    "        # N_CATCHMENT is from global\n",
    "        self.decoder = models.LSTM_decoder(\n",
    "            latent_dim=latent_dim,\n",
    "            feature_dim=feature_dim,\n",
    "            lstm_hidden_dim=lstm_hidden_dim,\n",
    "            fc_hidden_dims=fc_hidden_dims,\n",
    "            num_lstm_layers=n_lstm_layers,\n",
    "            output_dim=output_dim,\n",
    "            p=p,\n",
    "        )\n",
    "\n",
    "        self.embedding = nn.Embedding(N_CATCHMENTS, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speed_test(model, epochs=2, batch_size=64, lr_embedding=0.001, lr_decoder=0.001):\n",
    "\n",
    "    # prepare early stopper\n",
    "    early_stopper = training_fun.EarlyStopper(patience=1000, min_delta=0)\n",
    "\n",
    "    # define model\n",
    "    embedding, decoder = model.embedding.to(computing_device), model.decoder.to(\n",
    "        computing_device\n",
    "    )\n",
    "\n",
    "    if compile_model:\n",
    "        # pytorch2.0 new feature, complile model for fast training\n",
    "        embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "    # define optimizers\n",
    "    embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "    # train model\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "        # repeat TRAIN_YEAR times to finish an epoch\n",
    "        decoder.train()\n",
    "        embedding.train()\n",
    "\n",
    "        for i in range(600):\n",
    "\n",
    "            decoder_optimizer.zero_grad()\n",
    "            embedding_optimizer.zero_grad()\n",
    "\n",
    "            # put the models into training mode\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            # get training batch and pass to device\n",
    "            (x_batch, y_batch, selected_catchments) = dtrain.get_random_batch(\n",
    "                batch_size\n",
    "            )\n",
    "\n",
    "            x_batch, y_batch, selected_catchments = (\n",
    "                x_batch.to(computing_device),\n",
    "                y_batch.to(computing_device),\n",
    "                selected_catchments.to(computing_device),\n",
    "            )\n",
    "\n",
    "            # slice batch for training\n",
    "            with torch.autocast(\n",
    "                device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "            ):\n",
    "                code = embedding(selected_catchments)\n",
    "\n",
    "                # pass through decoder\n",
    "                out = decoder.decode(code, x_batch)\n",
    "\n",
    "                # compute loss\n",
    "                loss = training_fun.mse_loss_with_nans(out, y_batch)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(embedding_optimizer)\n",
    "            scaler.step(decoder_optimizer)\n",
    "            scaler.update()\n",
    "\n",
    "        # validate model after each epochs\n",
    "        decoder.eval()\n",
    "        embedding.eval()\n",
    "\n",
    "        if memory_saving:\n",
    "            val_loss = training_fun.val_model_mem_saving(\n",
    "                embedding=embedding,\n",
    "                decoder=decoder,\n",
    "                dataset=dval,\n",
    "                storge_device=storge_device,\n",
    "                computing_device=computing_device,\n",
    "                use_amp=use_amp,\n",
    "                val_metric=training_fun.mse_loss_with_nans,\n",
    "                return_summary=True,\n",
    "                val_steps=VAL_STEPS,\n",
    "            )\n",
    "        else:\n",
    "            val_loss = (\n",
    "                training_fun.val_model(\n",
    "                    embedding=embedding,\n",
    "                    decoder=decoder,\n",
    "                    dataset=dval,\n",
    "                    storge_device=storge_device,\n",
    "                    computing_device=computing_device,\n",
    "                    use_amp=use_amp,\n",
    "                    val_metric=training_fun.mse_loss_with_nans,\n",
    "                    return_summary=True,\n",
    "                )\n",
    "                .detach()\n",
    "                .cpu()\n",
    "                .numpy()\n",
    "            )\n",
    "            \n",
    "        print(val_loss)\n",
    "\n",
    "        # Early stop using early_stopper, break for loop\n",
    "        if early_stopper.early_stop(val_loss):\n",
    "            break\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return early_stopper.min_validation_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/yang/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.2000)\n",
      "tensor(4.6551)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb Cell 7\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m starting_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProcess started...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m fit \u001b[39m=\u001b[39m speed_test(lstm_model, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProcess ended...\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m ending_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n",
      "\u001b[1;32m/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb Cell 7\u001b[0m in \u001b[0;36mspeed_test\u001b[0;34m(model, epochs, batch_size, lr_embedding, lr_decoder)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m code \u001b[39m=\u001b[39m embedding(selected_catchments)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m \u001b[39m# pass through decoder\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m out \u001b[39m=\u001b[39m decoder\u001b[39m.\u001b[39;49mdecode(code, x_batch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39m# compute loss\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/yang/Documents/projects/deep_lumped/speed_test.ipynb#W6sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m loss \u001b[39m=\u001b[39m training_fun\u001b[39m.\u001b[39mmse_loss_with_nans(out, y_batch)\n",
      "File \u001b[0;32m~/Documents/projects/deep_lumped/models.py:92\u001b[0m, in \u001b[0;36mLSTM_decoder.decode\u001b[0;34m(self, code, x)\u001b[0m\n\u001b[1;32m     89\u001b[0m code \u001b[39m=\u001b[39m code\u001b[39m.\u001b[39mexpand(x\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mtranspose(\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     91\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((code, x), \u001b[39m2\u001b[39m)\n\u001b[0;32m---> 92\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(x)\u001b[39m.\u001b[39msqueeze()\n\u001b[1;32m     94\u001b[0m \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/Documents/projects/deep_lumped/models.py:83\u001b[0m, in \u001b[0;36mLSTM_decoder.forward\u001b[0;34m(self, inputs, base_length)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, inputs, base_length\u001b[39m=\u001b[39m\u001b[39m365\u001b[39m):\n\u001b[1;32m     82\u001b[0m     out, (_, _) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(inputs)\n\u001b[0;32m---> 83\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfc_layers(out[:, base_length:, :])\n\u001b[1;32m     85\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/pytorch-env/lib/python3.10/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1131\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/projects/deep_lumped/models.py:28\u001b[0m, in \u001b[0;36mTimeDistributed.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39m# We have to reshape Y\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_first:\n\u001b[0;32m---> 28\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39;49mcontiguous()\u001b[39m.\u001b[39mview(\n\u001b[1;32m     29\u001b[0m         x\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, y\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m     30\u001b[0m     )  \u001b[39m# (samples, timesteps, output_size)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     y \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, x\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m), y\u001b[39m.\u001b[39msize(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))  \u001b[39m# (timesteps, samples, output_size)\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lstm_model = LSTM_model(\n",
    "    latent_dim=4,\n",
    "    lstm_hidden_dim=32,\n",
    "    n_lstm_layers=1,\n",
    "    fc_hidden_dims=[8],\n",
    "    p=0.25,\n",
    "    feature_dim=3,\n",
    "    output_dim=1,\n",
    ")\n",
    "\n",
    "starting_time = time.time()\n",
    "print(\"Process started...\")\n",
    "\n",
    "fit = speed_test(lstm_model, epochs=5)\n",
    "\n",
    "print(\"Process ended...\")\n",
    "ending_time = time.time()\n",
    "print(ending_time - starting_time)\n",
    "\n",
    "print(f\"fit={fit}\")\n",
    "\n",
    "\n",
    "# tcn_model = TCN_Model(hidden_channel_dim=128, kernel_size=3, p=0.5)\n",
    "\n",
    "# starting_time = time.time()\n",
    "# print(\"Process started...\")\n",
    "\n",
    "# fit = speed_test(tcn_model, epochs=10)\n",
    "\n",
    "# print(\"Process ended...\")\n",
    "# ending_time = time.time()\n",
    "# print(ending_time - starting_time)\n",
    "\n",
    "# print(f\"fit={fit}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process started...\n",
      "tensor(7.5700)\n",
      "tensor(7.0758)\n",
      "tensor(6.8422)\n",
      "tensor(6.6585)\n",
      "tensor(6.4802)\n",
      "tensor(6.3472)\n",
      "tensor(6.1712)\n",
      "tensor(6.0665)\n",
      "tensor(5.8456)\n",
      "tensor(5.7155)\n",
      "Process ended...\n",
      "418.00520873069763\n",
      "fit=5.715493679046631\n"
     ]
    }
   ],
   "source": [
    "tcn_model = TCN_Model(hidden_channel_dim=6, kernel_size=2, p=0.5)\n",
    "\n",
    "starting_time = time.time()\n",
    "print(\"Process started...\")\n",
    "\n",
    "fit = speed_test(tcn_model, epochs=10)\n",
    "\n",
    "print(\"Process ended...\")\n",
    "ending_time = time.time()\n",
    "print(ending_time - starting_time)\n",
    "\n",
    "print(f\"fit={fit}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1ddfd6d42648f68c476c776315986cac60a18b45e56ba9b8a233e8441d39da2b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
