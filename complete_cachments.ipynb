{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yang/opt/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "import time\n",
    "\n",
    "import dataloader\n",
    "import models\n",
    "import training_fun\n",
    "\n",
    "import optuna\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "SEQ_LENGTH = 365 * 2\n",
    "TARGET_SEQ_LENGTH = 365\n",
    "BASE_LENGTH = SEQ_LENGTH - TARGET_SEQ_LENGTH\n",
    "\n",
    "FORCING_DIM = 3\n",
    "\n",
    "N_CATCHMENTS = 749\n",
    "\n",
    "# training hyperparameters\n",
    "EPOCHS = 500\n",
    "TRAIN_YEAR = 19\n",
    "PATIENCE = 20\n",
    "\n",
    "use_amp = True\n",
    "compile_model = False\n",
    "\n",
    "if compile_model:\n",
    "    torch.set_float32_matmul_precision(\"high\")\n",
    "\n",
    "memory_saving = False\n",
    "if memory_saving:\n",
    "    storge_device = \"cpu\"\n",
    "    computing_device = DEVICE\n",
    "    VAL_STEPS = 500\n",
    "else:\n",
    "    storge_device = DEVICE\n",
    "    computing_device = DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = dataloader.Forcing_Data(\n",
    "    \"data/data3f_train.csv\",\n",
    "    record_length=5843,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n",
    "\n",
    "dval = dataloader.Forcing_Data(\n",
    "    \"data/data3f_val.csv\",\n",
    "    record_length=2191,\n",
    "    storge_device=storge_device,\n",
    "    seq_length=SEQ_LENGTH,\n",
    "    target_seq_length=TARGET_SEQ_LENGTH,\n",
    "    base_length=BASE_LENGTH,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Objective:\n",
    "    def __init__(self, model_builder):\n",
    "        self.model_builder = model_builder\n",
    "\n",
    "    def objective(self, trial):\n",
    "\n",
    "        # prepare early stopper\n",
    "        early_stopper = training_fun.EarlyStopper(patience=PATIENCE, min_delta=0)\n",
    "\n",
    "        # define model\n",
    "        embedding, decoder = self.model_builder.define_model(trial)\n",
    "        embedding, decoder = embedding.to(computing_device), decoder.to(\n",
    "            computing_device\n",
    "        )\n",
    "\n",
    "        if compile_model:\n",
    "            # pytorch2.0 new feature, complile model for fast training\n",
    "            embedding, decoder = torch.compile(embedding), torch.compile(decoder)\n",
    "\n",
    "        # define optimizers\n",
    "        lr_embedding = trial.suggest_float(\"lr_embedding\", 5e-5, 1e-2, log=True)\n",
    "        embedding_optimizer = optim.Adam(embedding.parameters(), lr=lr_embedding)\n",
    "\n",
    "        lr_decoder = trial.suggest_float(\"lr_decoder\", 5e-5, 1e-2, log=True)\n",
    "        decoder_optimizer = optim.Adam(decoder.parameters(), lr=lr_decoder)\n",
    "\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
    "\n",
    "        # define batch size\n",
    "        batch_size_power = trial.suggest_int(\"batch_size_power\", 4, 8)\n",
    "        batch_size = 2**batch_size_power\n",
    "\n",
    "        # train model\n",
    "        for epoch in range(EPOCHS):\n",
    "\n",
    "            # for each epoch get_random_batch method generates a batch that contains one year data for each catchment\n",
    "            # repeat TRAIN_YEAR times to finish an epoch\n",
    "            decoder.train()\n",
    "            embedding.train()\n",
    "\n",
    "            for year in range(TRAIN_YEAR):\n",
    "\n",
    "                x_batch, y_batch = dtrain.get_random_batch()\n",
    "\n",
    "                if memory_saving:\n",
    "                    x_batch, y_batch = x_batch.to(computing_device), y_batch.to(\n",
    "                        computing_device\n",
    "                    )\n",
    "\n",
    "                catchment_index = torch.randperm(\n",
    "                    N_CATCHMENTS, device=computing_device\n",
    "                )  # add randomness\n",
    "\n",
    "                # interate over catchments\n",
    "                for i in range(int(N_CATCHMENTS / batch_size)):\n",
    "\n",
    "                    # prepare data\n",
    "                    ind_s = i * batch_size\n",
    "                    ind_e = (i + 1) * batch_size\n",
    "\n",
    "                    selected_catchments = catchment_index[ind_s:ind_e]\n",
    "\n",
    "                    x_sub, y_sub = x_batch[ind_s:ind_e, :, :], y_batch[ind_s:ind_e, :]\n",
    "\n",
    "                    # prepare training, put the models into training mode\n",
    "                    decoder_optimizer.zero_grad()\n",
    "                    embedding_optimizer.zero_grad()\n",
    "\n",
    "                    # forward pass\n",
    "                    with torch.autocast(\n",
    "                        device_type=\"cuda\", dtype=torch.float16, enabled=use_amp\n",
    "                    ):\n",
    "                        code = embedding(selected_catchments)\n",
    "                        out = decoder.decode(code, x_sub)\n",
    "\n",
    "                        # backprop\n",
    "                        loss = training_fun.mse_loss_with_nans(out, y_sub)\n",
    "\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(embedding_optimizer)\n",
    "                    scaler.step(decoder_optimizer)\n",
    "                    scaler.update()\n",
    "\n",
    "            # validate model after each epochs\n",
    "            decoder.eval()\n",
    "            embedding.eval()\n",
    "\n",
    "            # Handle pruning based on the intermediate value\n",
    "            if memory_saving:\n",
    "                val_loss = training_fun.val_model_mem_saving(\n",
    "                    embedding=embedding,\n",
    "                    decoder=decoder,\n",
    "                    dataset=dval,\n",
    "                    storge_device=storge_device,\n",
    "                    computing_device=computing_device,\n",
    "                    use_amp=use_amp,\n",
    "                    val_metric=training_fun.mse_loss_with_nans,\n",
    "                    return_summary=True,\n",
    "                    val_steps=VAL_STEPS,\n",
    "                )\n",
    "            else:\n",
    "                val_loss = (\n",
    "                    training_fun.val_model(\n",
    "                        embedding=embedding,\n",
    "                        decoder=decoder,\n",
    "                        dataset=dval,\n",
    "                        storge_device=storge_device,\n",
    "                        computing_device=computing_device,\n",
    "                        use_amp=use_amp,\n",
    "                        val_metric=training_fun.mse_loss_with_nans,\n",
    "                        return_summary=True,\n",
    "                    )\n",
    "                    .detach()\n",
    "                    .cpu()\n",
    "                    .numpy()\n",
    "                )\n",
    "\n",
    "            trial.report(val_loss, epoch)\n",
    "\n",
    "            if trial.should_prune():\n",
    "                torch.cuda.empty_cache()\n",
    "                raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "            # Early stop using early_stopper, break for loop\n",
    "            if early_stopper.early_stop(val_loss):\n",
    "                break\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        return early_stopper.min_validation_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM_model_builder = training_fun.LSTM_model_builder(\n",
    "    n_catchments=N_CATCHMENTS, base_length=BASE_LENGTH, forcing_dim=FORCING_DIM\n",
    ")\n",
    "\n",
    "LSTM_objective = Objective(LSTM_model_builder).objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-12-16 14:33:27,525]\u001b[0m A new study created in memory with name: base_model\u001b[0m\n",
      "/Users/yang/opt/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages/torch/cuda/amp/grad_scaler.py:118: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/yang/opt/anaconda3/envs/pytorch1.13/lib/python3.10/site-packages/torch/amp/autocast_mode.py:202: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(\n",
    "    study_name=\"base_model\", direction=\"minimize\", pruner=optuna.pruners.NopPruner()\n",
    ")\n",
    "study.optimize(LSTM_objective, n_trials=10)\n",
    "\n",
    "joblib.dump(study, \"complete_LSTM_study.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch1.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8dd27b6c340292cc2ab881a3173a041a95a8319cf9ea1e7ef1dda772fab4656e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
